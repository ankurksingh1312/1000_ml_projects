{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/train.csv')\n",
    "df_train_demographics = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/train_demographics.csv')\n",
    "df_test = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/test.csv')\n",
    "df_test_demographics = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/test_demographics.csv')\n",
    "df_merged_train  = pd.merge(df_train, df_train_demographics, on='subject', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['row_id',\n",
       " 'sequence_type',\n",
       " 'sequence_id',\n",
       " 'sequence_counter',\n",
       " 'subject',\n",
       " 'orientation',\n",
       " 'behavior',\n",
       " 'phase',\n",
       " 'gesture',\n",
       " 'acc_x',\n",
       " 'acc_y',\n",
       " 'acc_z',\n",
       " 'rot_w',\n",
       " 'rot_x',\n",
       " 'rot_y',\n",
       " 'rot_z',\n",
       " 'thm_1',\n",
       " 'thm_2',\n",
       " 'thm_3',\n",
       " 'thm_4',\n",
       " 'thm_5',\n",
       " 'tof_1_v0',\n",
       " 'tof_1_v1',\n",
       " 'tof_1_v2',\n",
       " 'tof_1_v3',\n",
       " 'tof_1_v4',\n",
       " 'tof_1_v5',\n",
       " 'tof_1_v6',\n",
       " 'tof_1_v7',\n",
       " 'tof_1_v8',\n",
       " 'tof_1_v9',\n",
       " 'tof_1_v10',\n",
       " 'tof_1_v11',\n",
       " 'tof_1_v12',\n",
       " 'tof_1_v13',\n",
       " 'tof_1_v14',\n",
       " 'tof_1_v15',\n",
       " 'tof_1_v16',\n",
       " 'tof_1_v17',\n",
       " 'tof_1_v18',\n",
       " 'tof_1_v19',\n",
       " 'tof_1_v20',\n",
       " 'tof_1_v21',\n",
       " 'tof_1_v22',\n",
       " 'tof_1_v23',\n",
       " 'tof_1_v24',\n",
       " 'tof_1_v25',\n",
       " 'tof_1_v26',\n",
       " 'tof_1_v27',\n",
       " 'tof_1_v28',\n",
       " 'tof_1_v29',\n",
       " 'tof_1_v30',\n",
       " 'tof_1_v31',\n",
       " 'tof_1_v32',\n",
       " 'tof_1_v33',\n",
       " 'tof_1_v34',\n",
       " 'tof_1_v35',\n",
       " 'tof_1_v36',\n",
       " 'tof_1_v37',\n",
       " 'tof_1_v38',\n",
       " 'tof_1_v39',\n",
       " 'tof_1_v40',\n",
       " 'tof_1_v41',\n",
       " 'tof_1_v42',\n",
       " 'tof_1_v43',\n",
       " 'tof_1_v44',\n",
       " 'tof_1_v45',\n",
       " 'tof_1_v46',\n",
       " 'tof_1_v47',\n",
       " 'tof_1_v48',\n",
       " 'tof_1_v49',\n",
       " 'tof_1_v50',\n",
       " 'tof_1_v51',\n",
       " 'tof_1_v52',\n",
       " 'tof_1_v53',\n",
       " 'tof_1_v54',\n",
       " 'tof_1_v55',\n",
       " 'tof_1_v56',\n",
       " 'tof_1_v57',\n",
       " 'tof_1_v58',\n",
       " 'tof_1_v59',\n",
       " 'tof_1_v60',\n",
       " 'tof_1_v61',\n",
       " 'tof_1_v62',\n",
       " 'tof_1_v63',\n",
       " 'tof_2_v0',\n",
       " 'tof_2_v1',\n",
       " 'tof_2_v2',\n",
       " 'tof_2_v3',\n",
       " 'tof_2_v4',\n",
       " 'tof_2_v5',\n",
       " 'tof_2_v6',\n",
       " 'tof_2_v7',\n",
       " 'tof_2_v8',\n",
       " 'tof_2_v9',\n",
       " 'tof_2_v10',\n",
       " 'tof_2_v11',\n",
       " 'tof_2_v12',\n",
       " 'tof_2_v13',\n",
       " 'tof_2_v14',\n",
       " 'tof_2_v15',\n",
       " 'tof_2_v16',\n",
       " 'tof_2_v17',\n",
       " 'tof_2_v18',\n",
       " 'tof_2_v19',\n",
       " 'tof_2_v20',\n",
       " 'tof_2_v21',\n",
       " 'tof_2_v22',\n",
       " 'tof_2_v23',\n",
       " 'tof_2_v24',\n",
       " 'tof_2_v25',\n",
       " 'tof_2_v26',\n",
       " 'tof_2_v27',\n",
       " 'tof_2_v28',\n",
       " 'tof_2_v29',\n",
       " 'tof_2_v30',\n",
       " 'tof_2_v31',\n",
       " 'tof_2_v32',\n",
       " 'tof_2_v33',\n",
       " 'tof_2_v34',\n",
       " 'tof_2_v35',\n",
       " 'tof_2_v36',\n",
       " 'tof_2_v37',\n",
       " 'tof_2_v38',\n",
       " 'tof_2_v39',\n",
       " 'tof_2_v40',\n",
       " 'tof_2_v41',\n",
       " 'tof_2_v42',\n",
       " 'tof_2_v43',\n",
       " 'tof_2_v44',\n",
       " 'tof_2_v45',\n",
       " 'tof_2_v46',\n",
       " 'tof_2_v47',\n",
       " 'tof_2_v48',\n",
       " 'tof_2_v49',\n",
       " 'tof_2_v50',\n",
       " 'tof_2_v51',\n",
       " 'tof_2_v52',\n",
       " 'tof_2_v53',\n",
       " 'tof_2_v54',\n",
       " 'tof_2_v55',\n",
       " 'tof_2_v56',\n",
       " 'tof_2_v57',\n",
       " 'tof_2_v58',\n",
       " 'tof_2_v59',\n",
       " 'tof_2_v60',\n",
       " 'tof_2_v61',\n",
       " 'tof_2_v62',\n",
       " 'tof_2_v63',\n",
       " 'tof_3_v0',\n",
       " 'tof_3_v1',\n",
       " 'tof_3_v2',\n",
       " 'tof_3_v3',\n",
       " 'tof_3_v4',\n",
       " 'tof_3_v5',\n",
       " 'tof_3_v6',\n",
       " 'tof_3_v7',\n",
       " 'tof_3_v8',\n",
       " 'tof_3_v9',\n",
       " 'tof_3_v10',\n",
       " 'tof_3_v11',\n",
       " 'tof_3_v12',\n",
       " 'tof_3_v13',\n",
       " 'tof_3_v14',\n",
       " 'tof_3_v15',\n",
       " 'tof_3_v16',\n",
       " 'tof_3_v17',\n",
       " 'tof_3_v18',\n",
       " 'tof_3_v19',\n",
       " 'tof_3_v20',\n",
       " 'tof_3_v21',\n",
       " 'tof_3_v22',\n",
       " 'tof_3_v23',\n",
       " 'tof_3_v24',\n",
       " 'tof_3_v25',\n",
       " 'tof_3_v26',\n",
       " 'tof_3_v27',\n",
       " 'tof_3_v28',\n",
       " 'tof_3_v29',\n",
       " 'tof_3_v30',\n",
       " 'tof_3_v31',\n",
       " 'tof_3_v32',\n",
       " 'tof_3_v33',\n",
       " 'tof_3_v34',\n",
       " 'tof_3_v35',\n",
       " 'tof_3_v36',\n",
       " 'tof_3_v37',\n",
       " 'tof_3_v38',\n",
       " 'tof_3_v39',\n",
       " 'tof_3_v40',\n",
       " 'tof_3_v41',\n",
       " 'tof_3_v42',\n",
       " 'tof_3_v43',\n",
       " 'tof_3_v44',\n",
       " 'tof_3_v45',\n",
       " 'tof_3_v46',\n",
       " 'tof_3_v47',\n",
       " 'tof_3_v48',\n",
       " 'tof_3_v49',\n",
       " 'tof_3_v50',\n",
       " 'tof_3_v51',\n",
       " 'tof_3_v52',\n",
       " 'tof_3_v53',\n",
       " 'tof_3_v54',\n",
       " 'tof_3_v55',\n",
       " 'tof_3_v56',\n",
       " 'tof_3_v57',\n",
       " 'tof_3_v58',\n",
       " 'tof_3_v59',\n",
       " 'tof_3_v60',\n",
       " 'tof_3_v61',\n",
       " 'tof_3_v62',\n",
       " 'tof_3_v63',\n",
       " 'tof_4_v0',\n",
       " 'tof_4_v1',\n",
       " 'tof_4_v2',\n",
       " 'tof_4_v3',\n",
       " 'tof_4_v4',\n",
       " 'tof_4_v5',\n",
       " 'tof_4_v6',\n",
       " 'tof_4_v7',\n",
       " 'tof_4_v8',\n",
       " 'tof_4_v9',\n",
       " 'tof_4_v10',\n",
       " 'tof_4_v11',\n",
       " 'tof_4_v12',\n",
       " 'tof_4_v13',\n",
       " 'tof_4_v14',\n",
       " 'tof_4_v15',\n",
       " 'tof_4_v16',\n",
       " 'tof_4_v17',\n",
       " 'tof_4_v18',\n",
       " 'tof_4_v19',\n",
       " 'tof_4_v20',\n",
       " 'tof_4_v21',\n",
       " 'tof_4_v22',\n",
       " 'tof_4_v23',\n",
       " 'tof_4_v24',\n",
       " 'tof_4_v25',\n",
       " 'tof_4_v26',\n",
       " 'tof_4_v27',\n",
       " 'tof_4_v28',\n",
       " 'tof_4_v29',\n",
       " 'tof_4_v30',\n",
       " 'tof_4_v31',\n",
       " 'tof_4_v32',\n",
       " 'tof_4_v33',\n",
       " 'tof_4_v34',\n",
       " 'tof_4_v35',\n",
       " 'tof_4_v36',\n",
       " 'tof_4_v37',\n",
       " 'tof_4_v38',\n",
       " 'tof_4_v39',\n",
       " 'tof_4_v40',\n",
       " 'tof_4_v41',\n",
       " 'tof_4_v42',\n",
       " 'tof_4_v43',\n",
       " 'tof_4_v44',\n",
       " 'tof_4_v45',\n",
       " 'tof_4_v46',\n",
       " 'tof_4_v47',\n",
       " 'tof_4_v48',\n",
       " 'tof_4_v49',\n",
       " 'tof_4_v50',\n",
       " 'tof_4_v51',\n",
       " 'tof_4_v52',\n",
       " 'tof_4_v53',\n",
       " 'tof_4_v54',\n",
       " 'tof_4_v55',\n",
       " 'tof_4_v56',\n",
       " 'tof_4_v57',\n",
       " 'tof_4_v58',\n",
       " 'tof_4_v59',\n",
       " 'tof_4_v60',\n",
       " 'tof_4_v61',\n",
       " 'tof_4_v62',\n",
       " 'tof_4_v63',\n",
       " 'tof_5_v0',\n",
       " 'tof_5_v1',\n",
       " 'tof_5_v2',\n",
       " 'tof_5_v3',\n",
       " 'tof_5_v4',\n",
       " 'tof_5_v5',\n",
       " 'tof_5_v6',\n",
       " 'tof_5_v7',\n",
       " 'tof_5_v8',\n",
       " 'tof_5_v9',\n",
       " 'tof_5_v10',\n",
       " 'tof_5_v11',\n",
       " 'tof_5_v12',\n",
       " 'tof_5_v13',\n",
       " 'tof_5_v14',\n",
       " 'tof_5_v15',\n",
       " 'tof_5_v16',\n",
       " 'tof_5_v17',\n",
       " 'tof_5_v18',\n",
       " 'tof_5_v19',\n",
       " 'tof_5_v20',\n",
       " 'tof_5_v21',\n",
       " 'tof_5_v22',\n",
       " 'tof_5_v23',\n",
       " 'tof_5_v24',\n",
       " 'tof_5_v25',\n",
       " 'tof_5_v26',\n",
       " 'tof_5_v27',\n",
       " 'tof_5_v28',\n",
       " 'tof_5_v29',\n",
       " 'tof_5_v30',\n",
       " 'tof_5_v31',\n",
       " 'tof_5_v32',\n",
       " 'tof_5_v33',\n",
       " 'tof_5_v34',\n",
       " 'tof_5_v35',\n",
       " 'tof_5_v36',\n",
       " 'tof_5_v37',\n",
       " 'tof_5_v38',\n",
       " 'tof_5_v39',\n",
       " 'tof_5_v40',\n",
       " 'tof_5_v41',\n",
       " 'tof_5_v42',\n",
       " 'tof_5_v43',\n",
       " 'tof_5_v44',\n",
       " 'tof_5_v45',\n",
       " 'tof_5_v46',\n",
       " 'tof_5_v47',\n",
       " 'tof_5_v48',\n",
       " 'tof_5_v49',\n",
       " 'tof_5_v50',\n",
       " 'tof_5_v51',\n",
       " 'tof_5_v52',\n",
       " 'tof_5_v53',\n",
       " 'tof_5_v54',\n",
       " 'tof_5_v55',\n",
       " 'tof_5_v56',\n",
       " 'tof_5_v57',\n",
       " 'tof_5_v58',\n",
       " 'tof_5_v59',\n",
       " 'tof_5_v60',\n",
       " 'tof_5_v61',\n",
       " 'tof_5_v62',\n",
       " 'tof_5_v63',\n",
       " 'adult_child',\n",
       " 'age',\n",
       " 'sex',\n",
       " 'handedness',\n",
       " 'height_cm',\n",
       " 'shoulder_to_wrist_cm',\n",
       " 'elbow_to_wrist_cm']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged_train = df_merged_train.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "#                     ascending=[True, True]).reset_index(drop=True)\n",
    "# df_merged_train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train['sequence_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train[df_merged_train['sequence_type']=='Non-Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train['gesture'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFRB = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "# total count of values in df_merged_train['gesture']\n",
    "print(\"Value counts:\\n\", df_merged_train['gesture'].value_counts())\n",
    "\n",
    "# count where gesture is in BFRB\n",
    "count_in_BFRB = df_merged_train['gesture'].isin(BFRB).sum()\n",
    "print(\"\\nRows in BFRB:\", count_in_BFRB)\n",
    "\n",
    "# count where gesture is NOT in BFRB\n",
    "count_not_in_BFRB = (~df_merged_train['gesture'].isin(BFRB)).sum()\n",
    "print(\"Rows NOT in BFRB:\", count_not_in_BFRB)\n",
    "\n",
    "# sanity check: should equal total row count\n",
    "print(\"\\nTotal rows:\", len(df_merged_train))\n",
    "print(\"Check:\", count_in_BFRB + count_not_in_BFRB == len(df_merged_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in BFRB:\n",
    "    df_merged_train[g] = (df_merged_train['gesture'] == g).astype(int)\n",
    "\n",
    "df_merged_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train[\"Non-Target\"] = (\n",
    "    df_merged_train[\"sequence_type\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    "    .map({\"Target\": 0, \"Non-Target\": 1})\n",
    ")\n",
    "\n",
    "df_merged_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train[df_merged_train['sequence_type']=='Non-Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.drop(['sequence_type', 'gesture'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.drop(['row_id'], axis=1, inplace=True)\n",
    "\n",
    "df_merged_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged_train = df_merged_train.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "#                     ascending=[True, True]).reset_index(drop=True)\n",
    "# df_merged_train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.drop(['subject',\n",
    " 'orientation',\n",
    " 'behavior',\n",
    " 'phase'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_numeric_cols = df_merged_train.select_dtypes(exclude='number').columns\n",
    "# print(\"Non-numeric columns:\", non_numeric_cols)\n",
    "# corr_matrix = df_merged_train.corr(numeric_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns_X = df_merged_train.columns[df_merged_train.isnull().any()].tolist()\n",
    "print(\"Columns in X with NaNs:\\n\", nan_columns_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train = df_merged_train.interpolate(method=\"linear\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns_X = df_merged_train.columns[df_merged_train.isnull().any()].tolist()\n",
    "print(\"Columns in X with NaNs:\\n\", nan_columns_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# plt.title(\"Correlation Matrix\")\n",
    "# plt.show()\n",
    "\n",
    "# # 3. Drop highly positively correlated features only\n",
    "# threshold = 0.9\n",
    "# to_drop = set()\n",
    "\n",
    "# for i in range(len(corr_matrix.columns)):\n",
    "#     for j in range(i):\n",
    "#         if abs(corr_matrix.iloc[i, j]) > threshold:  # <-- only positive check\n",
    "#             colname = corr_matrix.columns[i]\n",
    "#             to_drop.add(colname)\n",
    "\n",
    "# print(\"Columns to drop:\", to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.to_pickle(\"df_merged_train_all_classes_labels_non-taregt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.pkl' with your pickle file path\n",
    "import pandas as pd\n",
    "df_merged_train = pd.read_pickle(\"df_merged_train_all_classes_labels_non-taregt.pkl\")\n",
    "\n",
    "# Show first few rows\n",
    "print(df_merged_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train = df_merged_train.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "                    ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imu_columns = [\n",
    "#  'sequence_id',\n",
    "#  'sequence_counter',\n",
    "#  'acc_x',\n",
    "#  'acc_y',\n",
    "#  'acc_z',\n",
    "#  'rot_w',\n",
    "#  'rot_x',\n",
    "#  'rot_y',\n",
    "#  'rot_z',\n",
    "#  'adult_child',\n",
    "#  'age',\n",
    "#  'sex',\n",
    "#  'handedness',\n",
    "#  'height_cm',\n",
    "#  'shoulder_to_wrist_cm',\n",
    "#  'elbow_to_wrist_cm',\n",
    "#  'Above ear - pull hair',\n",
    "#  'Forehead - pull hairline',\n",
    "#  'Forehead - scratch',\n",
    "#  'Eyebrow - pull hair',\n",
    "#  'Eyelash - pull hair',\n",
    "#  'Neck - pinch skin',\n",
    "#  'Neck - scratch',\n",
    "#  'Cheek - pinch skin',\n",
    "#  'Non-Target']\n",
    "\n",
    "# df_imu_all = df_merged_train[imu_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imu_labels_col =['sequence_id',\n",
    "#  'Above ear - pull hair',\n",
    "#  'Forehead - pull hairline',\n",
    "#  'Forehead - scratch',\n",
    "#  'Eyebrow - pull hair',\n",
    "#  'Eyelash - pull hair',\n",
    "#  'Neck - pinch skin',\n",
    "#  'Neck - scratch',\n",
    "#  'Cheek - pinch skin',\n",
    "#  'Non-Target']\n",
    "\n",
    "# df_imu_labels = df_imu_all[df_imu_labels_col]\n",
    "# df_imu_labels.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imu_train_col  = ['sequence_id',\n",
    "#  'sequence_counter',\n",
    "#  'acc_x',\n",
    "#  'acc_y',\n",
    "#  'acc_z',\n",
    "#  'rot_w',\n",
    "#  'rot_x',\n",
    "#  'rot_y',\n",
    "#  'rot_z',\n",
    "#  'adult_child',\n",
    "#  'age',\n",
    "#  'sex',\n",
    "#  'handedness',\n",
    "#  'height_cm',\n",
    "#  'shoulder_to_wrist_cm',\n",
    "#  'elbow_to_wrist_cm']\n",
    "# df_imu_train = df_imu_all[df_imu_train_col]\n",
    "# df_imu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imu_train = df_imu_train.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "#                     ascending=[True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def prepare_sequences(df_x, df_y, max_steps=700):\n",
    "#     # Drop unnecessary columns early\n",
    "#     df_x = df_x.drop(columns=[\"sequence_counter\"])  \n",
    "    \n",
    "#     # Get number of features (exclude seq_id)\n",
    "#     feature_cols = [c for c in df_x.columns if c != \"sequence_id\"]\n",
    "#     n_features = len(feature_cols)\n",
    "    \n",
    "#     # Find number of unique sequences\n",
    "#     sequence_ids = df_x[\"sequence_id\"].unique()\n",
    "#     n_sequences = len(sequence_ids)\n",
    "\n",
    "#     # Preallocate final arrays\n",
    "#     X = np.zeros((n_sequences, max_steps, n_features), dtype=np.float32)\n",
    "#     Y = np.zeros((n_sequences, 9), dtype=np.float32)  # 9 classes, already multi-hot\n",
    "    \n",
    "#     for i, seq_id in enumerate(sequence_ids):\n",
    "#         if i % 100 == 0:\n",
    "#             print(f\"Processing {i}/{n_sequences}\")\n",
    "\n",
    "#         # Extract sensor data for this sequence\n",
    "#         seq = df_x[df_x[\"sequence_id\"] == seq_id][feature_cols].values.astype(np.float32)\n",
    "        \n",
    "#         # Truncate if longer than max_steps\n",
    "#         seq = seq[:max_steps]\n",
    "        \n",
    "#         # Fill into preallocated array\n",
    "#         X[i, :len(seq), :] = seq\n",
    "        \n",
    "#         # Extract label row (drop sequence_id col, keep only class columns)\n",
    "#         label_row = df_y[df_y[\"sequence_id\"] == seq_id].drop(columns=[\"sequence_id\"]).iloc[0].values\n",
    "#         Y[i] = label_row\n",
    "    \n",
    "#     return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imu_x,imu_y, = prepare_sequences(df_imu_train,df_imu_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imu_x.shape,imu_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imu_y[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # X = input data, y = labels\n",
    "# imu_X_train, imu_X_test, imu_Y_train, imu_Y_test = train_test_split(\n",
    "#     imu_x, imu_y, test_size=0.2, random_state=42, stratify=imu_y\n",
    "# )\n",
    "# imu_X_train.shape,imu_X_test.shape, imu_Y_train.shape, imu_Y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, Dense, Dropout, Masking, GRU,MaxPooling1D\n",
    "# from tensorflow.keras import backend as K\n",
    "# import tensorflow as tf\n",
    "\n",
    "# num_classes = 9  # your 9 gesture classes\n",
    "\n",
    "# # Custom macro F1 score metric for multiclass\n",
    "# def f1_score(y_true, y_pred):\n",
    "#     y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes)   # convert to one-hot\n",
    "#     y_true = K.cast(y_true, \"float32\")\n",
    "\n",
    "#     tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)\n",
    "#     fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
    "\n",
    "#     precision = tp / (tp + fp + K.epsilon())\n",
    "#     recall = tp / (tp + fn + K.epsilon())\n",
    "#     f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "\n",
    "#     return K.mean(f1)   # macro F1\n",
    "\n",
    "# # Define model\n",
    "\n",
    "# model = Sequential([\n",
    "#     Masking(mask_value=0.0, input_shape=(700, 14)),   # Ignore padded timesteps\n",
    "#     Conv1D(filters=96, kernel_size=5, activation='relu'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=256, kernel_size=5, activation='relu'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     GRU(64, return_sequences=False),   # Handles masking automatically\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')      # Binary classification\n",
    "# ])\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',   # one-hot labels\n",
    "#     metrics=[\n",
    "#         'accuracy',\n",
    "#         tf.keras.metrics.Precision(name='precision'),\n",
    "#         tf.keras.metrics.Recall(name='recall'),\n",
    "#         f1_score\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# history = model.fit(\n",
    "#     imu_X_train, \n",
    "#     imu_Y_train,\n",
    "#     epochs=20,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,   # 10% of training data will be used for validation\n",
    "#     verbose=1\n",
    "# )\n",
    "# history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_whole_label =['sequence_id',\n",
    " 'Above ear - pull hair',\n",
    " 'Forehead - pull hairline',\n",
    " 'Forehead - scratch',\n",
    " 'Eyebrow - pull hair',\n",
    " 'Eyelash - pull hair',\n",
    " 'Neck - pinch skin',\n",
    " 'Neck - scratch',\n",
    " 'Cheek - pinch skin',\n",
    " 'Non-Target']\n",
    "\n",
    "df_whole_labels = df_merged_train[df_train_whole_label]\n",
    "df_whole_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.drop([ 'Above ear - pull hair',\n",
    " 'Forehead - pull hairline',\n",
    " 'Forehead - scratch',\n",
    " 'Eyebrow - pull hair',\n",
    " 'Eyelash - pull hair',\n",
    " 'Neck - pinch skin',\n",
    " 'Neck - scratch',\n",
    " 'Cheek - pinch skin',\n",
    " 'Non-Target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_whole_sequences(df_x, df_y, max_steps=700):\n",
    "    # Drop unnecessary columns early\n",
    "    df_x = df_x.drop(columns=[\"sequence_counter\"])  \n",
    "    \n",
    "    # Get number of features (exclude seq_id)\n",
    "    feature_cols = [c for c in df_x.columns if c != \"sequence_id\"]\n",
    "    n_features = len(feature_cols)\n",
    "    \n",
    "    # Find number of unique sequences\n",
    "    sequence_ids = df_x[\"sequence_id\"].unique()\n",
    "    n_sequences = len(sequence_ids)\n",
    "\n",
    "    # Preallocate final arrays\n",
    "    X = np.zeros((n_sequences, max_steps, n_features), dtype=np.float32)\n",
    "    Y = np.zeros((n_sequences, 9), dtype=np.float32)  # 9 classes, already multi-hot\n",
    "    \n",
    "    for i, seq_id in enumerate(sequence_ids):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing {i}/{n_sequences}\")\n",
    "\n",
    "        # Extract sensor data for this sequence\n",
    "        seq = df_x[df_x[\"sequence_id\"] == seq_id][feature_cols].values.astype(np.float32)\n",
    "        \n",
    "        # Truncate if longer than max_steps\n",
    "        seq = seq[:max_steps]\n",
    "        \n",
    "        # Fill into preallocated array\n",
    "        X[i, :len(seq), :] = seq\n",
    "        \n",
    "        # Extract label row (drop sequence_id col, keep only class columns)\n",
    "        label_row = df_y[df_y[\"sequence_id\"] == seq_id].drop(columns=[\"sequence_id\"]).iloc[0].values\n",
    "        Y[i] = label_row\n",
    "    \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_whole,y_train_whole = prepare_whole_sequences(df_merged_train,df_whole_labels)\n",
    "x_train_whole.shape,y_train_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"x_train_whole_y_train_whole.npz\", x_train_whole=x_train_whole, y_train_whole=y_train_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all_sensors, x_test_all_sensors, y_train_all_sensors, y_test_all_sensors = train_test_split(\n",
    "    x_train_whole, y_train_whole, test_size=0.1, random_state=42, stratify=y_train_whole\n",
    ")\n",
    "x_train_all_sensors.shape,x_test_all_sensors.shape, y_train_all_sensors.shape, y_test_all_sensors.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all_sensors\n",
    "y_train_all_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train_whole\n",
    "del y_train_whole\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"x_train_all_sensors_y_train_all_sensors.npz\", x_train_all_sensors=x_train_all_sensors, y_train_all_sensors=y_train_all_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train_all_sensors\n",
    "del y_train_all_sensors\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"x_train_all_sensors_y_train_all_sensors.npz\")\n",
    "\n",
    "# Access arrays by their key names\n",
    "x_train_whole = data[\"x_train_all_sensors\"]\n",
    "y_train_whole = data[\"y_train_all_sensors\"]\n",
    "\n",
    "print(\"x_train_whole shape:\", x_train_whole.shape)\n",
    "print(\"y_train_whole shape:\", y_train_whole.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all_sensors=x_train_whole\n",
    "y_train_all_sensors=y_train_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler_X = StandardScaler()\n",
    "\n",
    "# # Fit only on training data\n",
    "# x_train_all_sensors = scaler_X.fit_transform(x_train_all_sensors)\n",
    "\n",
    "# # Use same transformation on validation/test\n",
    "# x_test_all_sensors   = scaler_X.transform(x_test_all_sensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, GRU, MaxPooling1D, Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Ensure TensorFlow uses GPU if available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth to prevent TensorFlow from allocating all GPU memory\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Using GPU:\", gpus)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "num_classes = 9  # your 9 gesture classes\n",
    "\n",
    "# Custom macro F1 score metric for multiclass\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes)  # convert to one-hot\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "\n",
    "    return K.mean(f1)  # macro F1\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Input(shape=(700, 339)),\n",
    "    Conv1D(filters=96, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=256, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=256, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    GRU(32, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax',dtype='float32')  # multiclass classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # one-hot labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_all_sensors, \n",
    "    y_train_all_sensors,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,   # 10% of training data will be used for validation\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, GRU, MaxPooling1D,Input\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "num_classes = 9  # your 9 gesture classes\n",
    "\n",
    "# Custom macro F1 score metric for multiclass\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes)   # convert to one-hot\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "\n",
    "    return K.mean(f1)   # macro F1\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Input(shape=(700, 339)), \n",
    "    Conv1D(filters=96, kernel_size=5, activation='relu', input_shape=(700, 339)),  # <-- added input shape\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=256, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    GRU(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')   # multiclass classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',   # one-hot labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train_all_sensors, \n",
    "    y_train_all_sensors,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,   # 10% of training data will be used for validation\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "num_classes = 9  # gesture classes\n",
    "\n",
    "# Custom macro F1 score metric for multiclass\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes)   # predicted class â†’ one-hot\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "\n",
    "    return K.mean(f1)   # macro F1\n",
    "\n",
    "# Define WaveNet-style model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(700, 339)))   # sequence length 700, features 339\n",
    "\n",
    "# Stack of dilated causal convolutions\n",
    "for rate in (1, 2, 4, 8, 16, 32, 64, 128):\n",
    "    model.add(Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=2,\n",
    "        padding=\"causal\",\n",
    "        activation=\"relu\",\n",
    "        dilation_rate=rate\n",
    "    ))\n",
    "\n",
    "# Global pooling instead of GRU (to reduce parameters)\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))   # multiclass output\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',   # one-hot labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    x_train_all_sensors, \n",
    "    y_train_all_sensors,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,   # 10% of training data will be used for validation\n",
    "    verbose=1\n",
    ")\n",
    "history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs detected:\", gpus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
