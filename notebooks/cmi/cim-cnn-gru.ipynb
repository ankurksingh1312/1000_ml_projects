{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load back the pickled DataFrames\n",
    "X = pd.read_pickle(\"df_X.pkl\")\n",
    "Y = pd.read_pickle(\"df_Y.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((574945, 341), (574945, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id  sequence_type_encoded\n",
       "56  SEQ_000007                      1\n",
       "55  SEQ_000007                      1\n",
       "54  SEQ_000007                      1\n",
       "53  SEQ_000007                      1\n",
       "52  SEQ_000007                      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "      <th>adult_child</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>shoulder_to_wrist_cm</th>\n",
       "      <th>elbow_to_wrist_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>56</td>\n",
       "      <td>7.171875</td>\n",
       "      <td>5.984375</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>0.243164</td>\n",
       "      <td>-0.264587</td>\n",
       "      <td>-0.413574</td>\n",
       "      <td>-0.836548</td>\n",
       "      <td>28.793257</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>55</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>5.640625</td>\n",
       "      <td>4.964844</td>\n",
       "      <td>0.224060</td>\n",
       "      <td>-0.288330</td>\n",
       "      <td>-0.440308</td>\n",
       "      <td>-0.820251</td>\n",
       "      <td>28.817827</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>54</td>\n",
       "      <td>5.566406</td>\n",
       "      <td>5.523438</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>0.219788</td>\n",
       "      <td>-0.296387</td>\n",
       "      <td>-0.446655</td>\n",
       "      <td>-0.815063</td>\n",
       "      <td>28.769115</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>53</td>\n",
       "      <td>6.144531</td>\n",
       "      <td>5.601562</td>\n",
       "      <td>5.843750</td>\n",
       "      <td>0.232361</td>\n",
       "      <td>-0.278015</td>\n",
       "      <td>-0.426758</td>\n",
       "      <td>-0.828613</td>\n",
       "      <td>29.033009</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>52</td>\n",
       "      <td>6.140625</td>\n",
       "      <td>5.488281</td>\n",
       "      <td>5.195312</td>\n",
       "      <td>0.258118</td>\n",
       "      <td>-0.230469</td>\n",
       "      <td>-0.401001</td>\n",
       "      <td>-0.848206</td>\n",
       "      <td>28.951780</td>\n",
       "      <td>...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id  sequence_counter     acc_x     acc_y     acc_z     rot_w  \\\n",
       "56  SEQ_000007                56  7.171875  5.984375  4.082031  0.243164   \n",
       "55  SEQ_000007                55  6.101562  5.640625  4.964844  0.224060   \n",
       "54  SEQ_000007                54  5.566406  5.523438  5.769531  0.219788   \n",
       "53  SEQ_000007                53  6.144531  5.601562  5.843750  0.232361   \n",
       "52  SEQ_000007                52  6.140625  5.488281  5.195312  0.258118   \n",
       "\n",
       "       rot_x     rot_y     rot_z      thm_1  ...  tof_5_v61  tof_5_v62  \\\n",
       "56 -0.264587 -0.413574 -0.836548  28.793257  ...       98.0       96.0   \n",
       "55 -0.288330 -0.440308 -0.820251  28.817827  ...      102.0       96.0   \n",
       "54 -0.296387 -0.446655 -0.815063  28.769115  ...      105.0       98.0   \n",
       "53 -0.278015 -0.426758 -0.828613  29.033009  ...       -1.0      106.0   \n",
       "52 -0.230469 -0.401001 -0.848206  28.951780  ...      111.0      101.0   \n",
       "\n",
       "    tof_5_v63  adult_child  age  sex  handedness  height_cm  \\\n",
       "56       94.0            0   12    1           1      163.0   \n",
       "55       94.0            0   12    1           1      163.0   \n",
       "54       95.0            0   12    1           1      163.0   \n",
       "53       99.0            0   12    1           1      163.0   \n",
       "52       93.0            0   12    1           1      163.0   \n",
       "\n",
       "    shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
       "56                    52               24.0  \n",
       "55                    52               24.0  \n",
       "54                    52               24.0  \n",
       "53                    52               24.0  \n",
       "52                    52               24.0  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequence_id',\n",
       " 'sequence_counter',\n",
       " 'acc_x',\n",
       " 'acc_y',\n",
       " 'acc_z',\n",
       " 'rot_w',\n",
       " 'rot_x',\n",
       " 'rot_y',\n",
       " 'rot_z',\n",
       " 'thm_1',\n",
       " 'thm_2',\n",
       " 'thm_3',\n",
       " 'thm_4',\n",
       " 'thm_5',\n",
       " 'tof_1_v0',\n",
       " 'tof_1_v1',\n",
       " 'tof_1_v2',\n",
       " 'tof_1_v3',\n",
       " 'tof_1_v4',\n",
       " 'tof_1_v5',\n",
       " 'tof_1_v6',\n",
       " 'tof_1_v7',\n",
       " 'tof_1_v8',\n",
       " 'tof_1_v9',\n",
       " 'tof_1_v10',\n",
       " 'tof_1_v11',\n",
       " 'tof_1_v12',\n",
       " 'tof_1_v13',\n",
       " 'tof_1_v14',\n",
       " 'tof_1_v15',\n",
       " 'tof_1_v16',\n",
       " 'tof_1_v17',\n",
       " 'tof_1_v18',\n",
       " 'tof_1_v19',\n",
       " 'tof_1_v20',\n",
       " 'tof_1_v21',\n",
       " 'tof_1_v22',\n",
       " 'tof_1_v23',\n",
       " 'tof_1_v24',\n",
       " 'tof_1_v25',\n",
       " 'tof_1_v26',\n",
       " 'tof_1_v27',\n",
       " 'tof_1_v28',\n",
       " 'tof_1_v29',\n",
       " 'tof_1_v30',\n",
       " 'tof_1_v31',\n",
       " 'tof_1_v32',\n",
       " 'tof_1_v33',\n",
       " 'tof_1_v34',\n",
       " 'tof_1_v35',\n",
       " 'tof_1_v36',\n",
       " 'tof_1_v37',\n",
       " 'tof_1_v38',\n",
       " 'tof_1_v39',\n",
       " 'tof_1_v40',\n",
       " 'tof_1_v41',\n",
       " 'tof_1_v42',\n",
       " 'tof_1_v43',\n",
       " 'tof_1_v44',\n",
       " 'tof_1_v45',\n",
       " 'tof_1_v46',\n",
       " 'tof_1_v47',\n",
       " 'tof_1_v48',\n",
       " 'tof_1_v49',\n",
       " 'tof_1_v50',\n",
       " 'tof_1_v51',\n",
       " 'tof_1_v52',\n",
       " 'tof_1_v53',\n",
       " 'tof_1_v54',\n",
       " 'tof_1_v55',\n",
       " 'tof_1_v56',\n",
       " 'tof_1_v57',\n",
       " 'tof_1_v58',\n",
       " 'tof_1_v59',\n",
       " 'tof_1_v60',\n",
       " 'tof_1_v61',\n",
       " 'tof_1_v62',\n",
       " 'tof_1_v63',\n",
       " 'tof_2_v0',\n",
       " 'tof_2_v1',\n",
       " 'tof_2_v2',\n",
       " 'tof_2_v3',\n",
       " 'tof_2_v4',\n",
       " 'tof_2_v5',\n",
       " 'tof_2_v6',\n",
       " 'tof_2_v7',\n",
       " 'tof_2_v8',\n",
       " 'tof_2_v9',\n",
       " 'tof_2_v10',\n",
       " 'tof_2_v11',\n",
       " 'tof_2_v12',\n",
       " 'tof_2_v13',\n",
       " 'tof_2_v14',\n",
       " 'tof_2_v15',\n",
       " 'tof_2_v16',\n",
       " 'tof_2_v17',\n",
       " 'tof_2_v18',\n",
       " 'tof_2_v19',\n",
       " 'tof_2_v20',\n",
       " 'tof_2_v21',\n",
       " 'tof_2_v22',\n",
       " 'tof_2_v23',\n",
       " 'tof_2_v24',\n",
       " 'tof_2_v25',\n",
       " 'tof_2_v26',\n",
       " 'tof_2_v27',\n",
       " 'tof_2_v28',\n",
       " 'tof_2_v29',\n",
       " 'tof_2_v30',\n",
       " 'tof_2_v31',\n",
       " 'tof_2_v32',\n",
       " 'tof_2_v33',\n",
       " 'tof_2_v34',\n",
       " 'tof_2_v35',\n",
       " 'tof_2_v36',\n",
       " 'tof_2_v37',\n",
       " 'tof_2_v38',\n",
       " 'tof_2_v39',\n",
       " 'tof_2_v40',\n",
       " 'tof_2_v41',\n",
       " 'tof_2_v42',\n",
       " 'tof_2_v43',\n",
       " 'tof_2_v44',\n",
       " 'tof_2_v45',\n",
       " 'tof_2_v46',\n",
       " 'tof_2_v47',\n",
       " 'tof_2_v48',\n",
       " 'tof_2_v49',\n",
       " 'tof_2_v50',\n",
       " 'tof_2_v51',\n",
       " 'tof_2_v52',\n",
       " 'tof_2_v53',\n",
       " 'tof_2_v54',\n",
       " 'tof_2_v55',\n",
       " 'tof_2_v56',\n",
       " 'tof_2_v57',\n",
       " 'tof_2_v58',\n",
       " 'tof_2_v59',\n",
       " 'tof_2_v60',\n",
       " 'tof_2_v61',\n",
       " 'tof_2_v62',\n",
       " 'tof_2_v63',\n",
       " 'tof_3_v0',\n",
       " 'tof_3_v1',\n",
       " 'tof_3_v2',\n",
       " 'tof_3_v3',\n",
       " 'tof_3_v4',\n",
       " 'tof_3_v5',\n",
       " 'tof_3_v6',\n",
       " 'tof_3_v7',\n",
       " 'tof_3_v8',\n",
       " 'tof_3_v9',\n",
       " 'tof_3_v10',\n",
       " 'tof_3_v11',\n",
       " 'tof_3_v12',\n",
       " 'tof_3_v13',\n",
       " 'tof_3_v14',\n",
       " 'tof_3_v15',\n",
       " 'tof_3_v16',\n",
       " 'tof_3_v17',\n",
       " 'tof_3_v18',\n",
       " 'tof_3_v19',\n",
       " 'tof_3_v20',\n",
       " 'tof_3_v21',\n",
       " 'tof_3_v22',\n",
       " 'tof_3_v23',\n",
       " 'tof_3_v24',\n",
       " 'tof_3_v25',\n",
       " 'tof_3_v26',\n",
       " 'tof_3_v27',\n",
       " 'tof_3_v28',\n",
       " 'tof_3_v29',\n",
       " 'tof_3_v30',\n",
       " 'tof_3_v31',\n",
       " 'tof_3_v32',\n",
       " 'tof_3_v33',\n",
       " 'tof_3_v34',\n",
       " 'tof_3_v35',\n",
       " 'tof_3_v36',\n",
       " 'tof_3_v37',\n",
       " 'tof_3_v38',\n",
       " 'tof_3_v39',\n",
       " 'tof_3_v40',\n",
       " 'tof_3_v41',\n",
       " 'tof_3_v42',\n",
       " 'tof_3_v43',\n",
       " 'tof_3_v44',\n",
       " 'tof_3_v45',\n",
       " 'tof_3_v46',\n",
       " 'tof_3_v47',\n",
       " 'tof_3_v48',\n",
       " 'tof_3_v49',\n",
       " 'tof_3_v50',\n",
       " 'tof_3_v51',\n",
       " 'tof_3_v52',\n",
       " 'tof_3_v53',\n",
       " 'tof_3_v54',\n",
       " 'tof_3_v55',\n",
       " 'tof_3_v56',\n",
       " 'tof_3_v57',\n",
       " 'tof_3_v58',\n",
       " 'tof_3_v59',\n",
       " 'tof_3_v60',\n",
       " 'tof_3_v61',\n",
       " 'tof_3_v62',\n",
       " 'tof_3_v63',\n",
       " 'tof_4_v0',\n",
       " 'tof_4_v1',\n",
       " 'tof_4_v2',\n",
       " 'tof_4_v3',\n",
       " 'tof_4_v4',\n",
       " 'tof_4_v5',\n",
       " 'tof_4_v6',\n",
       " 'tof_4_v7',\n",
       " 'tof_4_v8',\n",
       " 'tof_4_v9',\n",
       " 'tof_4_v10',\n",
       " 'tof_4_v11',\n",
       " 'tof_4_v12',\n",
       " 'tof_4_v13',\n",
       " 'tof_4_v14',\n",
       " 'tof_4_v15',\n",
       " 'tof_4_v16',\n",
       " 'tof_4_v17',\n",
       " 'tof_4_v18',\n",
       " 'tof_4_v19',\n",
       " 'tof_4_v20',\n",
       " 'tof_4_v21',\n",
       " 'tof_4_v22',\n",
       " 'tof_4_v23',\n",
       " 'tof_4_v24',\n",
       " 'tof_4_v25',\n",
       " 'tof_4_v26',\n",
       " 'tof_4_v27',\n",
       " 'tof_4_v28',\n",
       " 'tof_4_v29',\n",
       " 'tof_4_v30',\n",
       " 'tof_4_v31',\n",
       " 'tof_4_v32',\n",
       " 'tof_4_v33',\n",
       " 'tof_4_v34',\n",
       " 'tof_4_v35',\n",
       " 'tof_4_v36',\n",
       " 'tof_4_v37',\n",
       " 'tof_4_v38',\n",
       " 'tof_4_v39',\n",
       " 'tof_4_v40',\n",
       " 'tof_4_v41',\n",
       " 'tof_4_v42',\n",
       " 'tof_4_v43',\n",
       " 'tof_4_v44',\n",
       " 'tof_4_v45',\n",
       " 'tof_4_v46',\n",
       " 'tof_4_v47',\n",
       " 'tof_4_v48',\n",
       " 'tof_4_v49',\n",
       " 'tof_4_v50',\n",
       " 'tof_4_v51',\n",
       " 'tof_4_v52',\n",
       " 'tof_4_v53',\n",
       " 'tof_4_v54',\n",
       " 'tof_4_v55',\n",
       " 'tof_4_v56',\n",
       " 'tof_4_v57',\n",
       " 'tof_4_v58',\n",
       " 'tof_4_v59',\n",
       " 'tof_4_v60',\n",
       " 'tof_4_v61',\n",
       " 'tof_4_v62',\n",
       " 'tof_4_v63',\n",
       " 'tof_5_v0',\n",
       " 'tof_5_v1',\n",
       " 'tof_5_v2',\n",
       " 'tof_5_v3',\n",
       " 'tof_5_v4',\n",
       " 'tof_5_v5',\n",
       " 'tof_5_v6',\n",
       " 'tof_5_v7',\n",
       " 'tof_5_v8',\n",
       " 'tof_5_v9',\n",
       " 'tof_5_v10',\n",
       " 'tof_5_v11',\n",
       " 'tof_5_v12',\n",
       " 'tof_5_v13',\n",
       " 'tof_5_v14',\n",
       " 'tof_5_v15',\n",
       " 'tof_5_v16',\n",
       " 'tof_5_v17',\n",
       " 'tof_5_v18',\n",
       " 'tof_5_v19',\n",
       " 'tof_5_v20',\n",
       " 'tof_5_v21',\n",
       " 'tof_5_v22',\n",
       " 'tof_5_v23',\n",
       " 'tof_5_v24',\n",
       " 'tof_5_v25',\n",
       " 'tof_5_v26',\n",
       " 'tof_5_v27',\n",
       " 'tof_5_v28',\n",
       " 'tof_5_v29',\n",
       " 'tof_5_v30',\n",
       " 'tof_5_v31',\n",
       " 'tof_5_v32',\n",
       " 'tof_5_v33',\n",
       " 'tof_5_v34',\n",
       " 'tof_5_v35',\n",
       " 'tof_5_v36',\n",
       " 'tof_5_v37',\n",
       " 'tof_5_v38',\n",
       " 'tof_5_v39',\n",
       " 'tof_5_v40',\n",
       " 'tof_5_v41',\n",
       " 'tof_5_v42',\n",
       " 'tof_5_v43',\n",
       " 'tof_5_v44',\n",
       " 'tof_5_v45',\n",
       " 'tof_5_v46',\n",
       " 'tof_5_v47',\n",
       " 'tof_5_v48',\n",
       " 'tof_5_v49',\n",
       " 'tof_5_v50',\n",
       " 'tof_5_v51',\n",
       " 'tof_5_v52',\n",
       " 'tof_5_v53',\n",
       " 'tof_5_v54',\n",
       " 'tof_5_v55',\n",
       " 'tof_5_v56',\n",
       " 'tof_5_v57',\n",
       " 'tof_5_v58',\n",
       " 'tof_5_v59',\n",
       " 'tof_5_v60',\n",
       " 'tof_5_v61',\n",
       " 'tof_5_v62',\n",
       " 'tof_5_v63',\n",
       " 'adult_child',\n",
       " 'age',\n",
       " 'sex',\n",
       " 'handedness',\n",
       " 'height_cm',\n",
       " 'shoulder_to_wrist_cm',\n",
       " 'elbow_to_wrist_cm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id             0\n",
      "sequence_counter        0\n",
      "acc_x                   0\n",
      "acc_y                   0\n",
      "acc_z                   0\n",
      "                       ..\n",
      "sex                     0\n",
      "handedness              0\n",
      "height_cm               0\n",
      "shoulder_to_wrist_cm    0\n",
      "elbow_to_wrist_cm       0\n",
      "Length: 341, dtype: int64\n",
      "sequence_id              0\n",
      "sequence_type_encoded    0\n",
      "dtype: int64\n",
      "Total NaNs in X: 3597807\n",
      "Total NaNs in Y: 0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Count NaN / null values column-wise\n",
    "print(X.isnull().sum())\n",
    "print(Y.isnull().sum())\n",
    "\n",
    "# Count total NaN values\n",
    "print(\"Total NaNs in X:\", X.isnull().sum().sum())\n",
    "print(\"Total NaNs in Y:\", Y.isnull().sum().sum())\n",
    "\n",
    "# Count empty strings (\"\")\n",
    "print((X == \"\").sum().sum())\n",
    "print((Y == \"\").sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in X with NaNs:\n",
      "        sequence_id  sequence_counter     acc_x     acc_y     acc_z     rot_w  \\\n",
      "1736    SEQ_000174               233 -9.144531 -2.921875  3.082031  0.510864   \n",
      "1735    SEQ_000174               232 -8.917969 -0.050781  2.316406  0.507690   \n",
      "1734    SEQ_000174               231 -8.914062 -2.769531  3.199219  0.491760   \n",
      "1733    SEQ_000174               230 -8.988281  0.410156  2.738281  0.495667   \n",
      "1732    SEQ_000174               229 -8.957031 -2.082031  2.816406  0.484863   \n",
      "...            ...               ...       ...       ...       ...       ...   \n",
      "573933  SEQ_065452                 4  6.882812 -0.289062  7.296875  0.891846   \n",
      "573932  SEQ_065452                 3  6.691406 -0.367188  7.375000  0.891602   \n",
      "573931  SEQ_065452                 2  6.765625 -0.328125  7.300781  0.893250   \n",
      "573930  SEQ_065452                 1  6.691406 -0.136719  7.261719  0.891663   \n",
      "573929  SEQ_065452                 0  7.074219 -0.328125  7.183594  0.893799   \n",
      "\n",
      "           rot_x     rot_y     rot_z      thm_1  ...  tof_5_v61  tof_5_v62  \\\n",
      "1736   -0.459839  0.277344  0.671265  24.543879  ...        NaN        NaN   \n",
      "1735   -0.499817  0.292786  0.637756  24.650898  ...        NaN        NaN   \n",
      "1734   -0.509094  0.304993  0.637207  24.672289  ...        NaN        NaN   \n",
      "1733   -0.512268  0.298584  0.634583  24.603546  ...        NaN        NaN   \n",
      "1732   -0.501099  0.313660  0.644531  24.611969  ...        NaN        NaN   \n",
      "...          ...       ...       ...        ...  ...        ...        ...   \n",
      "573933  0.092102 -0.352051  0.268677  25.232374  ...        NaN        NaN   \n",
      "573932  0.094177 -0.353699  0.266541  25.219490  ...        NaN        NaN   \n",
      "573931  0.092224 -0.351440  0.264648  25.274935  ...        NaN        NaN   \n",
      "573930  0.096008 -0.355713  0.263000  25.360008  ...        NaN        NaN   \n",
      "573929  0.093811 -0.352600  0.260742  25.407270  ...        NaN        NaN   \n",
      "\n",
      "        tof_5_v63  adult_child  age  sex  handedness  height_cm  \\\n",
      "1736          NaN            0   12    0           1      153.0   \n",
      "1735          NaN            0   12    0           1      153.0   \n",
      "1734          NaN            0   12    0           1      153.0   \n",
      "1733          NaN            0   12    0           1      153.0   \n",
      "1732          NaN            0   12    0           1      153.0   \n",
      "...           ...          ...  ...  ...         ...        ...   \n",
      "573933        NaN            0   14    1           1      166.0   \n",
      "573932        NaN            0   14    1           1      166.0   \n",
      "573931        NaN            0   14    1           1      166.0   \n",
      "573930        NaN            0   14    1           1      166.0   \n",
      "573929        NaN            0   14    1           1      166.0   \n",
      "\n",
      "        shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
      "1736                      47               24.0  \n",
      "1735                      47               24.0  \n",
      "1734                      47               24.0  \n",
      "1733                      47               24.0  \n",
      "1732                      47               24.0  \n",
      "...                      ...                ...  \n",
      "573933                    47               27.0  \n",
      "573932                    47               27.0  \n",
      "573931                    47               27.0  \n",
      "573930                    47               27.0  \n",
      "573929                    47               27.0  \n",
      "\n",
      "[38640 rows x 341 columns]\n"
     ]
    }
   ],
   "source": [
    "nan_rows_X = X[X.isnull().any(axis=1)]\n",
    "print(\"Rows in X with NaNs:\\n\", nan_rows_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sequence_id', 'sequence_counter', 'acc_x', 'acc_y', 'acc_z', 'rot_w',\n",
       "       'rot_x', 'rot_y', 'rot_z', 'thm_1',\n",
       "       ...\n",
       "       'tof_5_v61', 'tof_5_v62', 'tof_5_v63', 'adult_child', 'age', 'sex',\n",
       "       'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm'],\n",
       "      dtype='object', length=341)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X with NaNs:\n",
      " ['rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n"
     ]
    }
   ],
   "source": [
    "nan_columns_X = X.columns[X.isnull().any()].tolist()\n",
    "print(\"Columns in X with NaNs:\\n\", nan_columns_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "      <th>adult_child</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>shoulder_to_wrist_cm</th>\n",
       "      <th>elbow_to_wrist_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574892</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574945 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence_id  sequence_counter  acc_x  acc_y  acc_z  rot_w  rot_x  \\\n",
       "56            False             False  False  False  False  False  False   \n",
       "55            False             False  False  False  False  False  False   \n",
       "54            False             False  False  False  False  False  False   \n",
       "53            False             False  False  False  False  False  False   \n",
       "52            False             False  False  False  False  False  False   \n",
       "...             ...               ...    ...    ...    ...    ...    ...   \n",
       "574896        False             False  False  False  False  False  False   \n",
       "574895        False             False  False  False  False  False  False   \n",
       "574894        False             False  False  False  False  False  False   \n",
       "574893        False             False  False  False  False  False  False   \n",
       "574892        False             False  False  False  False  False  False   \n",
       "\n",
       "        rot_y  rot_z  thm_1  ...  tof_5_v61  tof_5_v62  tof_5_v63  \\\n",
       "56      False  False  False  ...      False      False      False   \n",
       "55      False  False  False  ...      False      False      False   \n",
       "54      False  False  False  ...      False      False      False   \n",
       "53      False  False  False  ...      False      False      False   \n",
       "52      False  False  False  ...      False      False      False   \n",
       "...       ...    ...    ...  ...        ...        ...        ...   \n",
       "574896  False  False  False  ...      False      False      False   \n",
       "574895  False  False  False  ...      False      False      False   \n",
       "574894  False  False  False  ...      False      False      False   \n",
       "574893  False  False  False  ...      False      False      False   \n",
       "574892  False  False  False  ...      False      False      False   \n",
       "\n",
       "        adult_child    age    sex  handedness  height_cm  \\\n",
       "56            False  False  False       False      False   \n",
       "55            False  False  False       False      False   \n",
       "54            False  False  False       False      False   \n",
       "53            False  False  False       False      False   \n",
       "52            False  False  False       False      False   \n",
       "...             ...    ...    ...         ...        ...   \n",
       "574896        False  False  False       False      False   \n",
       "574895        False  False  False       False      False   \n",
       "574894        False  False  False       False      False   \n",
       "574893        False  False  False       False      False   \n",
       "574892        False  False  False       False      False   \n",
       "\n",
       "        shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
       "56                     False              False  \n",
       "55                     False              False  \n",
       "54                     False              False  \n",
       "53                     False              False  \n",
       "52                     False              False  \n",
       "...                      ...                ...  \n",
       "574896                 False              False  \n",
       "574895                 False              False  \n",
       "574894                 False              False  \n",
       "574893                 False              False  \n",
       "574892                 False              False  \n",
       "\n",
       "[574945 rows x 341 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index positions with NaNs in X: Index([  1736,   1735,   1734,   1733,   1732,   1731,   1730,   1729,   1728,\n",
      "         1727,\n",
      "       ...\n",
      "       573938, 573937, 573936, 573935, 573934, 573933, 573932, 573931, 573930,\n",
      "       573929],\n",
      "      dtype='int64', length=38640)\n"
     ]
    }
   ],
   "source": [
    "nan_positions_X = X[X.isnull().any(axis=1)].index\n",
    "print(\"Index positions with NaNs in X:\", nan_positions_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEQ_000174', np.int64(232), np.float64(-8.91796875), np.float64(-0.05078125), np.float64(2.31640625), np.float64(0.5076904296875), np.float64(-0.49981689453125), np.float64(0.29278564453125), np.float64(0.63775634765625), np.float64(24.650897979736328), np.float64(24.662254333496094), np.float64(26.26479721069336), np.float64(25.03215217590332), np.float64(nan), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(202.0), np.float64(122.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(196.0), np.float64(132.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(227.0), np.float64(152.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(213.0), np.float64(166.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(217.0), np.float64(140.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(151.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(133.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(134.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(165.0), np.float64(164.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(147.0), np.float64(122.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(105.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(138.0), np.float64(117.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(154.0), np.float64(119.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(128.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(192.0), np.float64(122.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(196.0), np.float64(175.0), np.float64(32.0), np.float64(37.0), np.float64(37.0), np.float64(41.0), np.float64(48.0), np.float64(59.0), np.float64(65.0), np.float64(66.0), np.float64(56.0), np.float64(64.0), np.float64(61.0), np.float64(57.0), np.float64(56.0), np.float64(69.0), np.float64(83.0), np.float64(90.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(239.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(141.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(128.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(128.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(132.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(137.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(153.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(-1.0), np.float64(165.0), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.int64(0), np.int64(12), np.int64(0), np.int64(1), np.float64(153.0), np.int64(47), np.float64(24.0)]\n"
     ]
    }
   ],
   "source": [
    "row_with_nan = X[X.isna().any(axis=1)].iloc[1]\n",
    "print(row_with_nan.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sequence_id  sequence_counter     acc_x     acc_y     acc_z     rot_w  \\\n",
      "0   SEQ_000007                 0  6.683594  6.214844  3.355469  0.134399   \n",
      "1   SEQ_000007                 1  6.949219  6.214844  3.125000  0.143494   \n",
      "2   SEQ_000007                 2  5.722656  5.410156  5.421875  0.219055   \n",
      "3   SEQ_000007                 3  6.601562  3.531250  6.457031  0.297546   \n",
      "4   SEQ_000007                 4  5.566406  0.277344  9.632812  0.333557   \n",
      "5   SEQ_000007                 5  3.996094 -0.640625  9.714844  0.359436   \n",
      "6   SEQ_000007                 6  4.035156 -2.019531  9.253906  0.379272   \n",
      "7   SEQ_000007                 7  3.730469 -1.828125  9.105469  0.378174   \n",
      "8   SEQ_000007                 8  4.535156 -1.867188  8.871094  0.371887   \n",
      "9   SEQ_000007                 9  3.921875 -1.601562  9.062500  0.369751   \n",
      "10  SEQ_000007                10  4.304688 -1.792969  8.871094  0.368225   \n",
      "11  SEQ_000007                11  4.226562 -1.945312  8.828125  0.369385   \n",
      "12  SEQ_000007                12  3.730469 -1.523438  9.140625  0.374390   \n",
      "13  SEQ_000007                13  3.804688 -1.410156  9.101562  0.372620   \n",
      "14  SEQ_000007                14  3.730469 -1.484375  9.105469  0.371643   \n",
      "15  SEQ_000007                15  3.613281 -1.484375  9.214844  0.368225   \n",
      "16  SEQ_000007                16  3.804688 -1.484375  9.367188  0.342285   \n",
      "17  SEQ_000007                17  5.070312  1.578125  9.792969  0.296814   \n",
      "18  SEQ_000007                18  6.484375  5.601562  4.886719  0.251709   \n",
      "19  SEQ_000007                19  6.445312  5.488281  5.078125  0.254211   \n",
      "\n",
      "       rot_x     rot_y     rot_z      thm_1  ...  tof_5_v61  tof_5_v62  \\\n",
      "0  -0.355164 -0.447327 -0.809753  28.943842  ...       -1.0       -1.0   \n",
      "1  -0.340271 -0.428650 -0.824524  29.340816  ...       -1.0       -1.0   \n",
      "2  -0.274231 -0.356934 -0.865662  30.339359  ...       -1.0       -1.0   \n",
      "3  -0.264160 -0.238159 -0.885986  30.543730  ...       -1.0       -1.0   \n",
      "4  -0.218628 -0.063538 -0.914856  29.317265  ...       -1.0       -1.0   \n",
      "5  -0.209351 -0.002808 -0.909363  28.408092  ...       -1.0       -1.0   \n",
      "6  -0.223267  0.004578 -0.897888  27.921841  ...       -1.0       -1.0   \n",
      "7  -0.229614  0.001648 -0.896790  27.819473  ...       -1.0       -1.0   \n",
      "8  -0.233521  0.000916 -0.898438  27.798990  ...       -1.0       -1.0   \n",
      "9  -0.231567  0.004639 -0.899780  27.696510  ...       -1.0       -1.0   \n",
      "10 -0.231567  0.005066 -0.900452  27.729525  ...       -1.0       -1.0   \n",
      "11 -0.215820  0.002136 -0.903870  27.946617  ...       -1.0       -1.0   \n",
      "12 -0.210632 -0.003479 -0.903015  28.191868  ...       -1.0      226.0   \n",
      "13 -0.206787 -0.002258 -0.904663  28.146727  ...       -1.0       -1.0   \n",
      "14 -0.204163 -0.001526 -0.905640  28.114025  ...       -1.0       -1.0   \n",
      "15 -0.227966 -0.037903 -0.900574  29.341267  ...       -1.0       -1.0   \n",
      "16 -0.282532 -0.224304 -0.867615  29.620077  ...       -1.0       -1.0   \n",
      "17 -0.228210 -0.360474 -0.854309  29.155569  ...       89.0       -1.0   \n",
      "18 -0.268860 -0.414978 -0.831970  28.790943  ...       93.0       86.0   \n",
      "19 -0.274475 -0.414734 -0.829468  28.636465  ...       91.0       87.0   \n",
      "\n",
      "    tof_5_v63  adult_child  age  sex  handedness  height_cm  \\\n",
      "0        -1.0            0   12    1           1      163.0   \n",
      "1        -1.0            0   12    1           1      163.0   \n",
      "2        -1.0            0   12    1           1      163.0   \n",
      "3        -1.0            0   12    1           1      163.0   \n",
      "4        -1.0            0   12    1           1      163.0   \n",
      "5        -1.0            0   12    1           1      163.0   \n",
      "6        -1.0            0   12    1           1      163.0   \n",
      "7        -1.0            0   12    1           1      163.0   \n",
      "8        -1.0            0   12    1           1      163.0   \n",
      "9        -1.0            0   12    1           1      163.0   \n",
      "10       -1.0            0   12    1           1      163.0   \n",
      "11       -1.0            0   12    1           1      163.0   \n",
      "12       -1.0            0   12    1           1      163.0   \n",
      "13       -1.0            0   12    1           1      163.0   \n",
      "14       -1.0            0   12    1           1      163.0   \n",
      "15       -1.0            0   12    1           1      163.0   \n",
      "16       -1.0            0   12    1           1      163.0   \n",
      "17       -1.0            0   12    1           1      163.0   \n",
      "18       88.0            0   12    1           1      163.0   \n",
      "19       84.0            0   12    1           1      163.0   \n",
      "\n",
      "    shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
      "0                     52               24.0  \n",
      "1                     52               24.0  \n",
      "2                     52               24.0  \n",
      "3                     52               24.0  \n",
      "4                     52               24.0  \n",
      "5                     52               24.0  \n",
      "6                     52               24.0  \n",
      "7                     52               24.0  \n",
      "8                     52               24.0  \n",
      "9                     52               24.0  \n",
      "10                    52               24.0  \n",
      "11                    52               24.0  \n",
      "12                    52               24.0  \n",
      "13                    52               24.0  \n",
      "14                    52               24.0  \n",
      "15                    52               24.0  \n",
      "16                    52               24.0  \n",
      "17                    52               24.0  \n",
      "18                    52               24.0  \n",
      "19                    52               24.0  \n",
      "\n",
      "[20 rows x 341 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort DataFrame\n",
    "X = X.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "                    ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "print(X.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imu_columns = [\n",
    " 'sequence_id',\n",
    " 'sequence_counter',\n",
    " 'sequence_type',\n",
    " 'gesture',\n",
    " 'acc_x',\n",
    " 'acc_y',\n",
    " 'acc_z',\n",
    " 'rot_w',\n",
    " 'rot_x',\n",
    " 'rot_y',\n",
    " 'rot_z',\n",
    " 'adult_child',\n",
    " 'age',\n",
    " 'sex',\n",
    " 'handedness',\n",
    " 'height_cm',\n",
    " 'shoulder_to_wrist_cm',\n",
    " 'elbow_to_wrist_cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "     A    B     C     D\n",
      "0  1.0  5.0   9.0   NaN\n",
      "1  NaN  6.0  10.0  10.0\n",
      "2  3.0  NaN  11.0  11.0\n",
      "3  4.0  8.0   NaN  12.0\n",
      "\n",
      "After:\n",
      "     A    B     C     D\n",
      "0  1.0  5.0   9.0  10.0\n",
      "1  2.0  6.0  10.0  10.0\n",
      "2  3.0  7.0  11.0  11.0\n",
      "3  4.0  8.0  11.0  12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [1, None, 3, 4],\n",
    "    \"B\": [5, 6, None, 8],\n",
    "    \"C\": [9, 10, 11, None],\n",
    "    \"D\": [None, 10, 11, 12],\n",
    "\n",
    "})\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df)\n",
    "\n",
    "# Fill NaNs with mean of previous and next row values\n",
    "def fill_with_mean(series):\n",
    "    for i in range(len(series)):\n",
    "        if pd.isna(series[i]):\n",
    "            prev_val = series[i-1] if i > 0 else None\n",
    "            next_val = series[i+1] if i < len(series)-1 else None\n",
    "            \n",
    "            if prev_val is not None and next_val is not None:\n",
    "                series[i] = (prev_val + next_val) / 2\n",
    "            elif prev_val is not None:\n",
    "                series[i] = prev_val\n",
    "            elif next_val is not None:\n",
    "                series[i] = next_val\n",
    "    return series\n",
    "\n",
    "df = df.apply(fill_with_mean)\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_with_mean\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/frame.py:10381\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10367\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10369\u001b[39m op = frame_apply(\n\u001b[32m  10370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10371\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10379\u001b[39m     kwargs=kwargs,\n\u001b[32m  10380\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mfill_with_mean\u001b[39m\u001b[34m(series)\u001b[39m\n\u001b[32m     20\u001b[39m next_val = series[i+\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[38;5;28mlen\u001b[39m(series)-\u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prev_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m next_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mseries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m = (prev_val + next_val) / \u001b[32m2\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m prev_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     25\u001b[39m     series[i] = prev_val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/series.py:1376\u001b[39m, in \u001b[36mSeries.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   1373\u001b[39m         \u001b[38;5;28mself\u001b[39m._set_with(key, value, warn=warn)\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cacher_needs_updating:\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_update_cacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/series.py:1526\u001b[39m, in \u001b[36mSeries._maybe_update_cacher\u001b[39m\u001b[34m(self, clear, verify_is_copy, inplace)\u001b[39m\n\u001b[32m   1521\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cacher\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) == \u001b[38;5;28mlen\u001b[39m(ref) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01min\u001b[39;00m ref.columns:\n\u001b[32m   1523\u001b[39m     \u001b[38;5;66;03m# GH#42530 self.name must be in ref.columns\u001b[39;00m\n\u001b[32m   1524\u001b[39m     \u001b[38;5;66;03m# to ensure column still in dataframe\u001b[39;00m\n\u001b[32m   1525\u001b[39m     \u001b[38;5;66;03m# otherwise, either self or ref has swapped in new arrays\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m     \u001b[43mref\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_maybe_cache_changed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcacher\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1528\u001b[39m     \u001b[38;5;66;03m# GH#33675 we have swapped in a new array, so parent\u001b[39;00m\n\u001b[32m   1529\u001b[39m     \u001b[38;5;66;03m#  reference to self is now invalid\u001b[39;00m\n\u001b[32m   1530\u001b[39m     ref._item_cache.pop(cacher[\u001b[32m0\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/frame.py:4668\u001b[39m, in \u001b[36mDataFrame._maybe_cache_changed\u001b[39m\u001b[34m(self, item, value, inplace)\u001b[39m\n\u001b[32m   4664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m old._values \u001b[38;5;129;01mis\u001b[39;00m value._values \u001b[38;5;129;01mand\u001b[39;00m inplace:\n\u001b[32m   4665\u001b[39m     \u001b[38;5;66;03m# GH#46149 avoid making unnecessary copies/block-splitting\u001b[39;00m\n\u001b[32m   4666\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4668\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marraylike\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:1149\u001b[39m, in \u001b[36mBlockManager.iset\u001b[39m\u001b[34m(self, loc, value, inplace, refs)\u001b[39m\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1148\u001b[39m         blk.set_inplace(blk_locs, value_getitem(val_locs))\n\u001b[32m-> \u001b[39m\u001b[32m1149\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1151\u001b[39m     unfit_mgr_locs.append(blk.mgr_locs.as_array[blk_locs])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "X = X.apply(fill_with_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_309412/1911005012.py:1: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  X = X.interpolate(method=\"linear\", axis=0)\n"
     ]
    }
   ],
   "source": [
    "X = X.interpolate(method=\"linear\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaNs in X: 0\n",
      "Total NaNs in Y: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total NaNs in X:\", X.isnull().sum().sum())\n",
    "print(\"Total NaNs in Y:\", Y.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequence_id',\n",
       " 'sequence_counter',\n",
       " 'acc_x',\n",
       " 'acc_y',\n",
       " 'acc_z',\n",
       " 'rot_w',\n",
       " 'rot_x',\n",
       " 'rot_y',\n",
       " 'rot_z',\n",
       " 'thm_1',\n",
       " 'thm_2',\n",
       " 'thm_3',\n",
       " 'thm_4',\n",
       " 'thm_5',\n",
       " 'tof_1_v0',\n",
       " 'tof_1_v1',\n",
       " 'tof_1_v2',\n",
       " 'tof_1_v3',\n",
       " 'tof_1_v4',\n",
       " 'tof_1_v5',\n",
       " 'tof_1_v6',\n",
       " 'tof_1_v7',\n",
       " 'tof_1_v8',\n",
       " 'tof_1_v9',\n",
       " 'tof_1_v10',\n",
       " 'tof_1_v11',\n",
       " 'tof_1_v12',\n",
       " 'tof_1_v13',\n",
       " 'tof_1_v14',\n",
       " 'tof_1_v15',\n",
       " 'tof_1_v16',\n",
       " 'tof_1_v17',\n",
       " 'tof_1_v18',\n",
       " 'tof_1_v19',\n",
       " 'tof_1_v20',\n",
       " 'tof_1_v21',\n",
       " 'tof_1_v22',\n",
       " 'tof_1_v23',\n",
       " 'tof_1_v24',\n",
       " 'tof_1_v25',\n",
       " 'tof_1_v26',\n",
       " 'tof_1_v27',\n",
       " 'tof_1_v28',\n",
       " 'tof_1_v29',\n",
       " 'tof_1_v30',\n",
       " 'tof_1_v31',\n",
       " 'tof_1_v32',\n",
       " 'tof_1_v33',\n",
       " 'tof_1_v34',\n",
       " 'tof_1_v35',\n",
       " 'tof_1_v36',\n",
       " 'tof_1_v37',\n",
       " 'tof_1_v38',\n",
       " 'tof_1_v39',\n",
       " 'tof_1_v40',\n",
       " 'tof_1_v41',\n",
       " 'tof_1_v42',\n",
       " 'tof_1_v43',\n",
       " 'tof_1_v44',\n",
       " 'tof_1_v45',\n",
       " 'tof_1_v46',\n",
       " 'tof_1_v47',\n",
       " 'tof_1_v48',\n",
       " 'tof_1_v49',\n",
       " 'tof_1_v50',\n",
       " 'tof_1_v51',\n",
       " 'tof_1_v52',\n",
       " 'tof_1_v53',\n",
       " 'tof_1_v54',\n",
       " 'tof_1_v55',\n",
       " 'tof_1_v56',\n",
       " 'tof_1_v57',\n",
       " 'tof_1_v58',\n",
       " 'tof_1_v59',\n",
       " 'tof_1_v60',\n",
       " 'tof_1_v61',\n",
       " 'tof_1_v62',\n",
       " 'tof_1_v63',\n",
       " 'tof_2_v0',\n",
       " 'tof_2_v1',\n",
       " 'tof_2_v2',\n",
       " 'tof_2_v3',\n",
       " 'tof_2_v4',\n",
       " 'tof_2_v5',\n",
       " 'tof_2_v6',\n",
       " 'tof_2_v7',\n",
       " 'tof_2_v8',\n",
       " 'tof_2_v9',\n",
       " 'tof_2_v10',\n",
       " 'tof_2_v11',\n",
       " 'tof_2_v12',\n",
       " 'tof_2_v13',\n",
       " 'tof_2_v14',\n",
       " 'tof_2_v15',\n",
       " 'tof_2_v16',\n",
       " 'tof_2_v17',\n",
       " 'tof_2_v18',\n",
       " 'tof_2_v19',\n",
       " 'tof_2_v20',\n",
       " 'tof_2_v21',\n",
       " 'tof_2_v22',\n",
       " 'tof_2_v23',\n",
       " 'tof_2_v24',\n",
       " 'tof_2_v25',\n",
       " 'tof_2_v26',\n",
       " 'tof_2_v27',\n",
       " 'tof_2_v28',\n",
       " 'tof_2_v29',\n",
       " 'tof_2_v30',\n",
       " 'tof_2_v31',\n",
       " 'tof_2_v32',\n",
       " 'tof_2_v33',\n",
       " 'tof_2_v34',\n",
       " 'tof_2_v35',\n",
       " 'tof_2_v36',\n",
       " 'tof_2_v37',\n",
       " 'tof_2_v38',\n",
       " 'tof_2_v39',\n",
       " 'tof_2_v40',\n",
       " 'tof_2_v41',\n",
       " 'tof_2_v42',\n",
       " 'tof_2_v43',\n",
       " 'tof_2_v44',\n",
       " 'tof_2_v45',\n",
       " 'tof_2_v46',\n",
       " 'tof_2_v47',\n",
       " 'tof_2_v48',\n",
       " 'tof_2_v49',\n",
       " 'tof_2_v50',\n",
       " 'tof_2_v51',\n",
       " 'tof_2_v52',\n",
       " 'tof_2_v53',\n",
       " 'tof_2_v54',\n",
       " 'tof_2_v55',\n",
       " 'tof_2_v56',\n",
       " 'tof_2_v57',\n",
       " 'tof_2_v58',\n",
       " 'tof_2_v59',\n",
       " 'tof_2_v60',\n",
       " 'tof_2_v61',\n",
       " 'tof_2_v62',\n",
       " 'tof_2_v63',\n",
       " 'tof_3_v0',\n",
       " 'tof_3_v1',\n",
       " 'tof_3_v2',\n",
       " 'tof_3_v3',\n",
       " 'tof_3_v4',\n",
       " 'tof_3_v5',\n",
       " 'tof_3_v6',\n",
       " 'tof_3_v7',\n",
       " 'tof_3_v8',\n",
       " 'tof_3_v9',\n",
       " 'tof_3_v10',\n",
       " 'tof_3_v11',\n",
       " 'tof_3_v12',\n",
       " 'tof_3_v13',\n",
       " 'tof_3_v14',\n",
       " 'tof_3_v15',\n",
       " 'tof_3_v16',\n",
       " 'tof_3_v17',\n",
       " 'tof_3_v18',\n",
       " 'tof_3_v19',\n",
       " 'tof_3_v20',\n",
       " 'tof_3_v21',\n",
       " 'tof_3_v22',\n",
       " 'tof_3_v23',\n",
       " 'tof_3_v24',\n",
       " 'tof_3_v25',\n",
       " 'tof_3_v26',\n",
       " 'tof_3_v27',\n",
       " 'tof_3_v28',\n",
       " 'tof_3_v29',\n",
       " 'tof_3_v30',\n",
       " 'tof_3_v31',\n",
       " 'tof_3_v32',\n",
       " 'tof_3_v33',\n",
       " 'tof_3_v34',\n",
       " 'tof_3_v35',\n",
       " 'tof_3_v36',\n",
       " 'tof_3_v37',\n",
       " 'tof_3_v38',\n",
       " 'tof_3_v39',\n",
       " 'tof_3_v40',\n",
       " 'tof_3_v41',\n",
       " 'tof_3_v42',\n",
       " 'tof_3_v43',\n",
       " 'tof_3_v44',\n",
       " 'tof_3_v45',\n",
       " 'tof_3_v46',\n",
       " 'tof_3_v47',\n",
       " 'tof_3_v48',\n",
       " 'tof_3_v49',\n",
       " 'tof_3_v50',\n",
       " 'tof_3_v51',\n",
       " 'tof_3_v52',\n",
       " 'tof_3_v53',\n",
       " 'tof_3_v54',\n",
       " 'tof_3_v55',\n",
       " 'tof_3_v56',\n",
       " 'tof_3_v57',\n",
       " 'tof_3_v58',\n",
       " 'tof_3_v59',\n",
       " 'tof_3_v60',\n",
       " 'tof_3_v61',\n",
       " 'tof_3_v62',\n",
       " 'tof_3_v63',\n",
       " 'tof_4_v0',\n",
       " 'tof_4_v1',\n",
       " 'tof_4_v2',\n",
       " 'tof_4_v3',\n",
       " 'tof_4_v4',\n",
       " 'tof_4_v5',\n",
       " 'tof_4_v6',\n",
       " 'tof_4_v7',\n",
       " 'tof_4_v8',\n",
       " 'tof_4_v9',\n",
       " 'tof_4_v10',\n",
       " 'tof_4_v11',\n",
       " 'tof_4_v12',\n",
       " 'tof_4_v13',\n",
       " 'tof_4_v14',\n",
       " 'tof_4_v15',\n",
       " 'tof_4_v16',\n",
       " 'tof_4_v17',\n",
       " 'tof_4_v18',\n",
       " 'tof_4_v19',\n",
       " 'tof_4_v20',\n",
       " 'tof_4_v21',\n",
       " 'tof_4_v22',\n",
       " 'tof_4_v23',\n",
       " 'tof_4_v24',\n",
       " 'tof_4_v25',\n",
       " 'tof_4_v26',\n",
       " 'tof_4_v27',\n",
       " 'tof_4_v28',\n",
       " 'tof_4_v29',\n",
       " 'tof_4_v30',\n",
       " 'tof_4_v31',\n",
       " 'tof_4_v32',\n",
       " 'tof_4_v33',\n",
       " 'tof_4_v34',\n",
       " 'tof_4_v35',\n",
       " 'tof_4_v36',\n",
       " 'tof_4_v37',\n",
       " 'tof_4_v38',\n",
       " 'tof_4_v39',\n",
       " 'tof_4_v40',\n",
       " 'tof_4_v41',\n",
       " 'tof_4_v42',\n",
       " 'tof_4_v43',\n",
       " 'tof_4_v44',\n",
       " 'tof_4_v45',\n",
       " 'tof_4_v46',\n",
       " 'tof_4_v47',\n",
       " 'tof_4_v48',\n",
       " 'tof_4_v49',\n",
       " 'tof_4_v50',\n",
       " 'tof_4_v51',\n",
       " 'tof_4_v52',\n",
       " 'tof_4_v53',\n",
       " 'tof_4_v54',\n",
       " 'tof_4_v55',\n",
       " 'tof_4_v56',\n",
       " 'tof_4_v57',\n",
       " 'tof_4_v58',\n",
       " 'tof_4_v59',\n",
       " 'tof_4_v60',\n",
       " 'tof_4_v61',\n",
       " 'tof_4_v62',\n",
       " 'tof_4_v63',\n",
       " 'tof_5_v0',\n",
       " 'tof_5_v1',\n",
       " 'tof_5_v2',\n",
       " 'tof_5_v3',\n",
       " 'tof_5_v4',\n",
       " 'tof_5_v5',\n",
       " 'tof_5_v6',\n",
       " 'tof_5_v7',\n",
       " 'tof_5_v8',\n",
       " 'tof_5_v9',\n",
       " 'tof_5_v10',\n",
       " 'tof_5_v11',\n",
       " 'tof_5_v12',\n",
       " 'tof_5_v13',\n",
       " 'tof_5_v14',\n",
       " 'tof_5_v15',\n",
       " 'tof_5_v16',\n",
       " 'tof_5_v17',\n",
       " 'tof_5_v18',\n",
       " 'tof_5_v19',\n",
       " 'tof_5_v20',\n",
       " 'tof_5_v21',\n",
       " 'tof_5_v22',\n",
       " 'tof_5_v23',\n",
       " 'tof_5_v24',\n",
       " 'tof_5_v25',\n",
       " 'tof_5_v26',\n",
       " 'tof_5_v27',\n",
       " 'tof_5_v28',\n",
       " 'tof_5_v29',\n",
       " 'tof_5_v30',\n",
       " 'tof_5_v31',\n",
       " 'tof_5_v32',\n",
       " 'tof_5_v33',\n",
       " 'tof_5_v34',\n",
       " 'tof_5_v35',\n",
       " 'tof_5_v36',\n",
       " 'tof_5_v37',\n",
       " 'tof_5_v38',\n",
       " 'tof_5_v39',\n",
       " 'tof_5_v40',\n",
       " 'tof_5_v41',\n",
       " 'tof_5_v42',\n",
       " 'tof_5_v43',\n",
       " 'tof_5_v44',\n",
       " 'tof_5_v45',\n",
       " 'tof_5_v46',\n",
       " 'tof_5_v47',\n",
       " 'tof_5_v48',\n",
       " 'tof_5_v49',\n",
       " 'tof_5_v50',\n",
       " 'tof_5_v51',\n",
       " 'tof_5_v52',\n",
       " 'tof_5_v53',\n",
       " 'tof_5_v54',\n",
       " 'tof_5_v55',\n",
       " 'tof_5_v56',\n",
       " 'tof_5_v57',\n",
       " 'tof_5_v58',\n",
       " 'tof_5_v59',\n",
       " 'tof_5_v60',\n",
       " 'tof_5_v61',\n",
       " 'tof_5_v62',\n",
       " 'tof_5_v63',\n",
       " 'adult_child',\n",
       " 'age',\n",
       " 'sex',\n",
       " 'handedness',\n",
       " 'height_cm',\n",
       " 'shoulder_to_wrist_cm',\n",
       " 'elbow_to_wrist_cm']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>adult_child</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>shoulder_to_wrist_cm</th>\n",
       "      <th>elbow_to_wrist_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>0</td>\n",
       "      <td>6.683594</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>-0.355164</td>\n",
       "      <td>-0.447327</td>\n",
       "      <td>-0.809753</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>6.949219</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>-0.340271</td>\n",
       "      <td>-0.428650</td>\n",
       "      <td>-0.824524</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>2</td>\n",
       "      <td>5.722656</td>\n",
       "      <td>5.410156</td>\n",
       "      <td>5.421875</td>\n",
       "      <td>0.219055</td>\n",
       "      <td>-0.274231</td>\n",
       "      <td>-0.356934</td>\n",
       "      <td>-0.865662</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>3</td>\n",
       "      <td>6.601562</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>6.457031</td>\n",
       "      <td>0.297546</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.238159</td>\n",
       "      <td>-0.885986</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>4</td>\n",
       "      <td>5.566406</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>9.632812</td>\n",
       "      <td>0.333557</td>\n",
       "      <td>-0.218628</td>\n",
       "      <td>-0.063538</td>\n",
       "      <td>-0.914856</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>52</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id  sequence_counter     acc_x     acc_y     acc_z     rot_w  \\\n",
       "0  SEQ_000007                 0  6.683594  6.214844  3.355469  0.134399   \n",
       "1  SEQ_000007                 1  6.949219  6.214844  3.125000  0.143494   \n",
       "2  SEQ_000007                 2  5.722656  5.410156  5.421875  0.219055   \n",
       "3  SEQ_000007                 3  6.601562  3.531250  6.457031  0.297546   \n",
       "4  SEQ_000007                 4  5.566406  0.277344  9.632812  0.333557   \n",
       "\n",
       "      rot_x     rot_y     rot_z  adult_child  age  sex  handedness  height_cm  \\\n",
       "0 -0.355164 -0.447327 -0.809753            0   12    1           1      163.0   \n",
       "1 -0.340271 -0.428650 -0.824524            0   12    1           1      163.0   \n",
       "2 -0.274231 -0.356934 -0.865662            0   12    1           1      163.0   \n",
       "3 -0.264160 -0.238159 -0.885986            0   12    1           1      163.0   \n",
       "4 -0.218628 -0.063538 -0.914856            0   12    1           1      163.0   \n",
       "\n",
       "   shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
       "0                    52               24.0  \n",
       "1                    52               24.0  \n",
       "2                    52               24.0  \n",
       "3                    52               24.0  \n",
       "4                    52               24.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imu_columns = [\n",
    " 'sequence_id',\n",
    " 'sequence_counter',\n",
    " 'acc_x',\n",
    " 'acc_y',\n",
    " 'acc_z',\n",
    " 'rot_w',\n",
    " 'rot_x',\n",
    " 'rot_y',\n",
    " 'rot_z',\n",
    " 'adult_child',\n",
    " 'age',\n",
    " 'sex',\n",
    " 'handedness',\n",
    " 'height_cm',\n",
    " 'shoulder_to_wrist_cm',\n",
    " 'elbow_to_wrist_cm']\n",
    "df_imu = X[imu_columns]\n",
    "df_imu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574945, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8151"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count rows per sequence_id\n",
    "df_imu['sequence_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((574945, 16), (574945, 2))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imu.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574896</th>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574895</th>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574894</th>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574893</th>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574892</th>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574945 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_id  sequence_type_encoded\n",
       "56      SEQ_000007                      1\n",
       "55      SEQ_000007                      1\n",
       "54      SEQ_000007                      1\n",
       "53      SEQ_000007                      1\n",
       "52      SEQ_000007                      1\n",
       "...            ...                    ...\n",
       "574896  SEQ_065531                      0\n",
       "574895  SEQ_065531                      0\n",
       "574894  SEQ_065531                      0\n",
       "574893  SEQ_065531                      0\n",
       "574892  SEQ_065531                      0\n",
       "\n",
       "[574945 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence_id\n",
       "SEQ_015261    700\n",
       "SEQ_014205    671\n",
       "SEQ_028188    647\n",
       "SEQ_060593    630\n",
       "SEQ_016031    567\n",
       "             ... \n",
       "SEQ_011271     34\n",
       "SEQ_032114     34\n",
       "SEQ_022667     34\n",
       "SEQ_059162     34\n",
       "SEQ_009199     29\n",
       "Name: count, Length: 8151, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imu['sequence_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_sequences(df_x,df_y ,max_steps=700):\n",
    "    # Drop unnecessary columns early\n",
    "  \n",
    "    df_x = df_x.drop(columns=[\"sequence_counter\"])  \n",
    "    \n",
    "    # Get number of features (exclude seq_id)\n",
    "    feature_cols = [c for c in df_x.columns if c != \"sequence_id\"]\n",
    "    print(feature_cols)\n",
    "    n_features = len(feature_cols)\n",
    "    \n",
    "    # Find number of unique sequences\n",
    "    sequence_ids = df_x[\"sequence_id\"].unique()\n",
    "    n_sequences = len(sequence_ids)\n",
    "\n",
    "    # Preallocate final array (float32 to save memory)\n",
    "    X = np.zeros((n_sequences, max_steps, n_features), dtype=np.float32)\n",
    "    Y = np.zeros(n_sequences,)\n",
    "    \n",
    "    for i, seq_id in enumerate(sequence_ids):\n",
    "        if(i%100==0):\n",
    "            print(i)\n",
    "        seq = df_x[df_x[\"sequence_id\"] == seq_id][feature_cols].values.astype(np.float32)\n",
    "        \n",
    "        # Truncate if longer than max_steps, keep first 700\n",
    "        if len(seq) > max_steps:\n",
    "            seq = seq[:max_steps]\n",
    "        \n",
    "        # Pad if shorter\n",
    "        X[i, :len(seq), :] = seq\n",
    "        Y[i] = df_y.loc[df_y[\"sequence_id\"] == seq_id, \"sequence_type_encoded\"].iloc[0]\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n"
     ]
    }
   ],
   "source": [
    "imu_x,imu_y, = prepare_sequences(df_imu,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8151, 700, 14), (8151,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imu_x.shape,imu_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"imu_X_Y_np.npz\", imu_x=imu_x, imu_y=imu_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = input data, y = labels\n",
    "imu_X_train, imu_X_test, imu_Y_train, imu_Y_test = train_test_split(\n",
    "    imu_x, imu_y, test_size=0.2, random_state=42, stratify=imu_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6520, 700, 14), (1631, 700, 14), (6520,), (1631,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imu_X_train.shape, imu_X_test.shape, imu_Y_train.shape, imu_Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6520, 700, 14), (6520,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imu_X_train.shape,imu_Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 17:13:23.863433: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-22 17:13:23.877388: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-22 17:13:23.995650: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-22 17:13:24.082510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755863004.163886  309412 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755863004.191020  309412 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755863004.397526  309412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755863004.397552  309412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755863004.397553  309412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755863004.397554  309412 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-22 17:13:24.418834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ankur/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/layers/core/masking.py:48: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-08-22 17:13:25.824983: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/ankur/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">696</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">692</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m696\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m4,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m692\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,361</span> (372.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m95,361\u001b[0m (372.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,361</span> (372.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m95,361\u001b[0m (372.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Masking, GRU\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom F1 score metric\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return K.mean(f1)\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0.0, input_shape=(700, 14)),   # Ignore padded timesteps\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GRU(64, return_sequences=False),   # Handles masking automatically\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')     # Binary classification\n",
    "])\n",
    "\n",
    "# Compile model with precision, recall, f1\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - accuracy: 0.6259 - f1_score: 0.6175 - loss: 0.6803 - precision: 0.6311 - recall: 0.9789 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6741 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 116ms/step - accuracy: 0.6305 - f1_score: 0.6309 - loss: 0.6596 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6814 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - accuracy: 0.6305 - f1_score: 0.6304 - loss: 0.6595 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6773 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6595 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6741 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6304 - loss: 0.6594 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6757 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6309 - loss: 0.6592 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6746 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 126ms/step - accuracy: 0.6305 - f1_score: 0.6312 - loss: 0.6588 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6760 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 125ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6593 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6786 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6597 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6762 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 123ms/step - accuracy: 0.6305 - f1_score: 0.6307 - loss: 0.6591 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6751 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6307 - loss: 0.6589 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6746 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6312 - loss: 0.6590 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6749 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6309 - loss: 0.6588 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6745 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6589 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6763 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - accuracy: 0.6305 - f1_score: 0.6307 - loss: 0.6590 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6741 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 133ms/step - accuracy: 0.6305 - f1_score: 0.6304 - loss: 0.6592 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6766 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.6305 - f1_score: 0.6304 - loss: 0.6590 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6753 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 131ms/step - accuracy: 0.6305 - f1_score: 0.6312 - loss: 0.6586 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6745 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 125ms/step - accuracy: 0.6305 - f1_score: 0.6309 - loss: 0.6592 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6747 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 126ms/step - accuracy: 0.6305 - f1_score: 0.6309 - loss: 0.6593 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6754 - val_precision: 0.5982 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7265b4723a40>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    imu_X_train, \n",
    "    imu_Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,   # 10% of training data will be used for validation\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_10' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"gru_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m K.mean(f1)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Define model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m model = \u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMasking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_value\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m14\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Ignore padded timesteps\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Handles masking automatically\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Handles masking automatically\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msigmoid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Binary classification\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Compile model with precision, recall, f1\u001b[39;00m\n\u001b[32m     41\u001b[39m model.compile(\n\u001b[32m     42\u001b[39m     optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     43\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     ]\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/models/sequential.py:76\u001b[39m, in \u001b[36mSequential.__init__\u001b[39m\u001b[34m(self, layers, trainable, name)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.add(layer, rebuild=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/models/sequential.py:149\u001b[39m, in \u001b[36mSequential._maybe_rebuild\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    148\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].batch_shape\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[32m    154\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].input_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/layers/layer.py:231\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    230\u001b[39m     obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[32m    233\u001b[39m signature = inspect.signature(original_build_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/models/sequential.py:195\u001b[39m, in \u001b[36mSequential.build\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m1\u001b[39m:]:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML_DL_Projects/ml_projects_venv/lib/python3.12/site-packages/keras/src/layers/input_spec.py:186\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec.allow_last_axis_squeeze:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim != spec.ndim:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    188\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis incompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m         )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.max_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim > spec.max_ndim:\n",
      "\u001b[31mValueError\u001b[39m: Input 0 of layer \"gru_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Masking, GRU\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom F1 score metric\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return K.mean(f1)\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0.0, input_shape=(700, 14)),   # Ignore padded timesteps\n",
    "    Conv1D(filters=96, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=256, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=384, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    GRU(64, return_sequences=False),   # Handles masking automatically\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')     # Binary classification\n",
    "])\n",
    "\n",
    "# Compile model with precision, recall, f1\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    imu_X_train, \n",
    "    imu_Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,   # 10% of training data will be used for validation\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_model(input_shape):\n",
    "    input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # --- Convolutional Feature Extraction ---\n",
    "    conv1 = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding=\"same\")(input_layer)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding=\"same\")(conv1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.ReLU()(conv3)\n",
    "\n",
    "    # Optional downsampling (reduces sequence length and adds robustness)\n",
    "    conv3 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv3)\n",
    "    conv3 = tf.keras.layers.Dropout(0.3)(conv3)\n",
    "\n",
    "    # --- LSTM Layers for Sequence Modeling ---\n",
    "    lstm1 = tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(conv3)\n",
    "    lstm2 = tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(lstm1)\n",
    "    lstm3 = tf.keras.layers.LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.2)(lstm2)\n",
    "\n",
    "    # --- Dense Layers ---\n",
    "    d1 = tf.keras.layers.Dense(128)(lstm3)\n",
    "    d1 = tf.keras.layers.BatchNormalization()(d1)\n",
    "    d1 = tf.keras.layers.ReLU()(d1)\n",
    "    d1 = tf.keras.layers.Dropout(0.4)(d1)\n",
    "\n",
    "    d2 = tf.keras.layers.Dense(64)(d1)\n",
    "    d2 = tf.keras.layers.BatchNormalization()(d2)\n",
    "    d2 = tf.keras.layers.ReLU()(d2)\n",
    "    d2 = tf.keras.layers.Dropout(0.3)(d2)\n",
    "\n",
    "    # --- Output Layer ---\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(d2)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "model = make_model(input_shape=(700, 14))\n",
    "tf.keras.utils.plot_model(model, show_shapes = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,409</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m329,409\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,385</span> (1.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,385\u001b[0m (1.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 328ms/step - accuracy: 0.5573 - f1_score: 0.5145 - loss: 0.7422 - precision: 0.6344 - recall: 0.7030 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6896 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 322ms/step - accuracy: 0.5850 - f1_score: 0.5695 - loss: 0.7085 - precision: 0.6304 - recall: 0.8262 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6756 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 330ms/step - accuracy: 0.5961 - f1_score: 0.5878 - loss: 0.6878 - precision: 0.6295 - recall: 0.8738 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6738 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 326ms/step - accuracy: 0.6017 - f1_score: 0.5909 - loss: 0.6795 - precision: 0.6316 - recall: 0.8841 - val_accuracy: 0.4018 - val_f1_score: 0.0000e+00 - val_loss: 0.7219 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 322ms/step - accuracy: 0.6109 - f1_score: 0.6072 - loss: 0.6773 - precision: 0.6298 - recall: 0.9292 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6740 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 322ms/step - accuracy: 0.6128 - f1_score: 0.6091 - loss: 0.6708 - precision: 0.6299 - recall: 0.9359 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6738 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 312ms/step - accuracy: 0.6213 - f1_score: 0.6186 - loss: 0.6702 - precision: 0.6309 - recall: 0.9624 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6924 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 300ms/step - accuracy: 0.6266 - f1_score: 0.6256 - loss: 0.6670 - precision: 0.6307 - recall: 0.9838 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6741 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 306ms/step - accuracy: 0.6287 - f1_score: 0.6279 - loss: 0.6660 - precision: 0.6304 - recall: 0.9938 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6771 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 296ms/step - accuracy: 0.6302 - f1_score: 0.6289 - loss: 0.6634 - precision: 0.6309 - recall: 0.9962 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6738 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 302ms/step - accuracy: 0.6302 - f1_score: 0.6301 - loss: 0.6634 - precision: 0.6306 - recall: 0.9981 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6739 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 306ms/step - accuracy: 0.6307 - f1_score: 0.6306 - loss: 0.6632 - precision: 0.6308 - recall: 0.9992 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6739 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 302ms/step - accuracy: 0.6307 - f1_score: 0.6298 - loss: 0.6606 - precision: 0.6306 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6738 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 303ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6613 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6743 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 298ms/step - accuracy: 0.6307 - f1_score: 0.6295 - loss: 0.6618 - precision: 0.6306 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6741 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 302ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6612 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6741 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 316ms/step - accuracy: 0.6302 - f1_score: 0.6308 - loss: 0.6610 - precision: 0.6304 - recall: 0.9995 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6738 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 328ms/step - accuracy: 0.6305 - f1_score: 0.6304 - loss: 0.6611 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6759 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 310ms/step - accuracy: 0.6305 - f1_score: 0.6309 - loss: 0.6602 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6747 - val_precision: 0.5982 - val_recall: 1.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 294ms/step - accuracy: 0.6305 - f1_score: 0.6301 - loss: 0.6611 - precision: 0.6305 - recall: 1.0000 - val_accuracy: 0.5982 - val_f1_score: 0.6027 - val_loss: 0.6740 - val_precision: 0.5982 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7266f3d39bb0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        f1_score\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    imu_X_train, \n",
    "    imu_Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,   # 10% of training data will be used for validation\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
