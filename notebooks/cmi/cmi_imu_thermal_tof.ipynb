{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/train.csv')\n",
    "df_test = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 5 320 2\n"
     ]
    }
   ],
   "source": [
    "df_imu_columns= [\n",
    " 'acc_x',\n",
    " 'acc_y',\n",
    " 'acc_z',\n",
    " 'rot_w',\n",
    " 'rot_x',\n",
    " 'rot_y',\n",
    " 'rot_z']\n",
    "\n",
    "df_thermal_columns= [\n",
    " 'thm_1',\n",
    " 'thm_2',\n",
    " 'thm_3',\n",
    " 'thm_4',\n",
    " 'thm_5'\n",
    "]\n",
    "\n",
    "df_tof_columns = [   \n",
    " 'tof_1_v0',\n",
    " 'tof_1_v1',\n",
    " 'tof_1_v2',\n",
    " 'tof_1_v3',\n",
    " 'tof_1_v4',\n",
    " 'tof_1_v5',\n",
    " 'tof_1_v6',\n",
    " 'tof_1_v7',\n",
    " 'tof_1_v8',\n",
    " 'tof_1_v9',\n",
    " 'tof_1_v10',\n",
    " 'tof_1_v11',\n",
    " 'tof_1_v12',\n",
    " 'tof_1_v13',\n",
    " 'tof_1_v14',\n",
    " 'tof_1_v15',\n",
    " 'tof_1_v16',\n",
    " 'tof_1_v17',\n",
    " 'tof_1_v18',\n",
    " 'tof_1_v19',\n",
    " 'tof_1_v20',\n",
    " 'tof_1_v21',\n",
    " 'tof_1_v22',\n",
    " 'tof_1_v23',\n",
    " 'tof_1_v24',\n",
    " 'tof_1_v25',\n",
    " 'tof_1_v26',\n",
    " 'tof_1_v27',\n",
    " 'tof_1_v28',\n",
    " 'tof_1_v29',\n",
    " 'tof_1_v30',\n",
    " 'tof_1_v31',\n",
    " 'tof_1_v32',\n",
    " 'tof_1_v33',\n",
    " 'tof_1_v34',\n",
    " 'tof_1_v35',\n",
    " 'tof_1_v36',\n",
    " 'tof_1_v37',\n",
    " 'tof_1_v38',\n",
    " 'tof_1_v39',\n",
    " 'tof_1_v40',\n",
    " 'tof_1_v41',\n",
    " 'tof_1_v42',\n",
    " 'tof_1_v43',\n",
    " 'tof_1_v44',\n",
    " 'tof_1_v45',\n",
    " 'tof_1_v46',\n",
    " 'tof_1_v47',\n",
    " 'tof_1_v48',\n",
    " 'tof_1_v49',\n",
    " 'tof_1_v50',\n",
    " 'tof_1_v51',\n",
    " 'tof_1_v52',\n",
    " 'tof_1_v53',\n",
    " 'tof_1_v54',\n",
    " 'tof_1_v55',\n",
    " 'tof_1_v56',\n",
    " 'tof_1_v57',\n",
    " 'tof_1_v58',\n",
    " 'tof_1_v59',\n",
    " 'tof_1_v60',\n",
    " 'tof_1_v61',\n",
    " 'tof_1_v62',\n",
    " 'tof_1_v63',\n",
    " 'tof_2_v0',\n",
    " 'tof_2_v1',\n",
    " 'tof_2_v2',\n",
    " 'tof_2_v3',\n",
    " 'tof_2_v4',\n",
    " 'tof_2_v5',\n",
    " 'tof_2_v6',\n",
    " 'tof_2_v7',\n",
    " 'tof_2_v8',\n",
    " 'tof_2_v9',\n",
    " 'tof_2_v10',\n",
    " 'tof_2_v11',\n",
    " 'tof_2_v12',\n",
    " 'tof_2_v13',\n",
    " 'tof_2_v14',\n",
    " 'tof_2_v15',\n",
    " 'tof_2_v16',\n",
    " 'tof_2_v17',\n",
    " 'tof_2_v18',\n",
    " 'tof_2_v19',\n",
    " 'tof_2_v20',\n",
    " 'tof_2_v21',\n",
    " 'tof_2_v22',\n",
    " 'tof_2_v23',\n",
    " 'tof_2_v24',\n",
    " 'tof_2_v25',\n",
    " 'tof_2_v26',\n",
    " 'tof_2_v27',\n",
    " 'tof_2_v28',\n",
    " 'tof_2_v29',\n",
    " 'tof_2_v30',\n",
    " 'tof_2_v31',\n",
    " 'tof_2_v32',\n",
    " 'tof_2_v33',\n",
    " 'tof_2_v34',\n",
    " 'tof_2_v35',\n",
    " 'tof_2_v36',\n",
    " 'tof_2_v37',\n",
    " 'tof_2_v38',\n",
    " 'tof_2_v39',\n",
    " 'tof_2_v40',\n",
    " 'tof_2_v41',\n",
    " 'tof_2_v42',\n",
    " 'tof_2_v43',\n",
    " 'tof_2_v44',\n",
    " 'tof_2_v45',\n",
    " 'tof_2_v46',\n",
    " 'tof_2_v47',\n",
    " 'tof_2_v48',\n",
    " 'tof_2_v49',\n",
    " 'tof_2_v50',\n",
    " 'tof_2_v51',\n",
    " 'tof_2_v52',\n",
    " 'tof_2_v53',\n",
    " 'tof_2_v54',\n",
    " 'tof_2_v55',\n",
    " 'tof_2_v56',\n",
    " 'tof_2_v57',\n",
    " 'tof_2_v58',\n",
    " 'tof_2_v59',\n",
    " 'tof_2_v60',\n",
    " 'tof_2_v61',\n",
    " 'tof_2_v62',\n",
    " 'tof_2_v63',\n",
    " 'tof_3_v0',\n",
    " 'tof_3_v1',\n",
    " 'tof_3_v2',\n",
    " 'tof_3_v3',\n",
    " 'tof_3_v4',\n",
    " 'tof_3_v5',\n",
    " 'tof_3_v6',\n",
    " 'tof_3_v7',\n",
    " 'tof_3_v8',\n",
    " 'tof_3_v9',\n",
    " 'tof_3_v10',\n",
    " 'tof_3_v11',\n",
    " 'tof_3_v12',\n",
    " 'tof_3_v13',\n",
    " 'tof_3_v14',\n",
    " 'tof_3_v15',\n",
    " 'tof_3_v16',\n",
    " 'tof_3_v17',\n",
    " 'tof_3_v18',\n",
    " 'tof_3_v19',\n",
    " 'tof_3_v20',\n",
    " 'tof_3_v21',\n",
    " 'tof_3_v22',\n",
    " 'tof_3_v23',\n",
    " 'tof_3_v24',\n",
    " 'tof_3_v25',\n",
    " 'tof_3_v26',\n",
    " 'tof_3_v27',\n",
    " 'tof_3_v28',\n",
    " 'tof_3_v29',\n",
    " 'tof_3_v30',\n",
    " 'tof_3_v31',\n",
    " 'tof_3_v32',\n",
    " 'tof_3_v33',\n",
    " 'tof_3_v34',\n",
    " 'tof_3_v35',\n",
    " 'tof_3_v36',\n",
    " 'tof_3_v37',\n",
    " 'tof_3_v38',\n",
    " 'tof_3_v39',\n",
    " 'tof_3_v40',\n",
    " 'tof_3_v41',\n",
    " 'tof_3_v42',\n",
    " 'tof_3_v43',\n",
    " 'tof_3_v44',\n",
    " 'tof_3_v45',\n",
    " 'tof_3_v46',\n",
    " 'tof_3_v47',\n",
    " 'tof_3_v48',\n",
    " 'tof_3_v49',\n",
    " 'tof_3_v50',\n",
    " 'tof_3_v51',\n",
    " 'tof_3_v52',\n",
    " 'tof_3_v53',\n",
    " 'tof_3_v54',\n",
    " 'tof_3_v55',\n",
    " 'tof_3_v56',\n",
    " 'tof_3_v57',\n",
    " 'tof_3_v58',\n",
    " 'tof_3_v59',\n",
    " 'tof_3_v60',\n",
    " 'tof_3_v61',\n",
    " 'tof_3_v62',\n",
    " 'tof_3_v63',\n",
    " 'tof_4_v0',\n",
    " 'tof_4_v1',\n",
    " 'tof_4_v2',\n",
    " 'tof_4_v3',\n",
    " 'tof_4_v4',\n",
    " 'tof_4_v5',\n",
    " 'tof_4_v6',\n",
    " 'tof_4_v7',\n",
    " 'tof_4_v8',\n",
    " 'tof_4_v9',\n",
    " 'tof_4_v10',\n",
    " 'tof_4_v11',\n",
    " 'tof_4_v12',\n",
    " 'tof_4_v13',\n",
    " 'tof_4_v14',\n",
    " 'tof_4_v15',\n",
    " 'tof_4_v16',\n",
    " 'tof_4_v17',\n",
    " 'tof_4_v18',\n",
    " 'tof_4_v19',\n",
    " 'tof_4_v20',\n",
    " 'tof_4_v21',\n",
    " 'tof_4_v22',\n",
    " 'tof_4_v23',\n",
    " 'tof_4_v24',\n",
    " 'tof_4_v25',\n",
    " 'tof_4_v26',\n",
    " 'tof_4_v27',\n",
    " 'tof_4_v28',\n",
    " 'tof_4_v29',\n",
    " 'tof_4_v30',\n",
    " 'tof_4_v31',\n",
    " 'tof_4_v32',\n",
    " 'tof_4_v33',\n",
    " 'tof_4_v34',\n",
    " 'tof_4_v35',\n",
    " 'tof_4_v36',\n",
    " 'tof_4_v37',\n",
    " 'tof_4_v38',\n",
    " 'tof_4_v39',\n",
    " 'tof_4_v40',\n",
    " 'tof_4_v41',\n",
    " 'tof_4_v42',\n",
    " 'tof_4_v43',\n",
    " 'tof_4_v44',\n",
    " 'tof_4_v45',\n",
    " 'tof_4_v46',\n",
    " 'tof_4_v47',\n",
    " 'tof_4_v48',\n",
    " 'tof_4_v49',\n",
    " 'tof_4_v50',\n",
    " 'tof_4_v51',\n",
    " 'tof_4_v52',\n",
    " 'tof_4_v53',\n",
    " 'tof_4_v54',\n",
    " 'tof_4_v55',\n",
    " 'tof_4_v56',\n",
    " 'tof_4_v57',\n",
    " 'tof_4_v58',\n",
    " 'tof_4_v59',\n",
    " 'tof_4_v60',\n",
    " 'tof_4_v61',\n",
    " 'tof_4_v62',\n",
    " 'tof_4_v63',\n",
    " 'tof_5_v0',\n",
    " 'tof_5_v1',\n",
    " 'tof_5_v2',\n",
    " 'tof_5_v3',\n",
    " 'tof_5_v4',\n",
    " 'tof_5_v5',\n",
    " 'tof_5_v6',\n",
    " 'tof_5_v7',\n",
    " 'tof_5_v8',\n",
    " 'tof_5_v9',\n",
    " 'tof_5_v10',\n",
    " 'tof_5_v11',\n",
    " 'tof_5_v12',\n",
    " 'tof_5_v13',\n",
    " 'tof_5_v14',\n",
    " 'tof_5_v15',\n",
    " 'tof_5_v16',\n",
    " 'tof_5_v17',\n",
    " 'tof_5_v18',\n",
    " 'tof_5_v19',\n",
    " 'tof_5_v20',\n",
    " 'tof_5_v21',\n",
    " 'tof_5_v22',\n",
    " 'tof_5_v23',\n",
    " 'tof_5_v24',\n",
    " 'tof_5_v25',\n",
    " 'tof_5_v26',\n",
    " 'tof_5_v27',\n",
    " 'tof_5_v28',\n",
    " 'tof_5_v29',\n",
    " 'tof_5_v30',\n",
    " 'tof_5_v31',\n",
    " 'tof_5_v32',\n",
    " 'tof_5_v33',\n",
    " 'tof_5_v34',\n",
    " 'tof_5_v35',\n",
    " 'tof_5_v36',\n",
    " 'tof_5_v37',\n",
    " 'tof_5_v38',\n",
    " 'tof_5_v39',\n",
    " 'tof_5_v40',\n",
    " 'tof_5_v41',\n",
    " 'tof_5_v42',\n",
    " 'tof_5_v43',\n",
    " 'tof_5_v44',\n",
    " 'tof_5_v45',\n",
    " 'tof_5_v46',\n",
    " 'tof_5_v47',\n",
    " 'tof_5_v48',\n",
    " 'tof_5_v49',\n",
    " 'tof_5_v50',\n",
    " 'tof_5_v51',\n",
    " 'tof_5_v52',\n",
    " 'tof_5_v53',\n",
    " 'tof_5_v54',\n",
    " 'tof_5_v55',\n",
    " 'tof_5_v56',\n",
    " 'tof_5_v57',\n",
    " 'tof_5_v58',\n",
    " 'tof_5_v59',\n",
    " 'tof_5_v60',\n",
    " 'tof_5_v61',\n",
    " 'tof_5_v62',\n",
    " 'tof_5_v63']\n",
    "\n",
    "df_labels_columns = ['sequence_id','gesture_encoded']\n",
    "\n",
    "print(len(df_imu_columns), len(df_thermal_columns),len(df_tof_columns),len(df_labels_columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>orientation</th>\n",
       "      <th>behavior</th>\n",
       "      <th>phase</th>\n",
       "      <th>gesture</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574940</th>\n",
       "      <td>SEQ_065531_000048</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>48</td>\n",
       "      <td>SUBJ_039498</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Performs gesture</td>\n",
       "      <td>Gesture</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>3.503906</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574941</th>\n",
       "      <td>SEQ_065531_000049</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>49</td>\n",
       "      <td>SUBJ_039498</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Performs gesture</td>\n",
       "      <td>Gesture</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>3.773438</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574942</th>\n",
       "      <td>SEQ_065531_000050</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>50</td>\n",
       "      <td>SUBJ_039498</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Performs gesture</td>\n",
       "      <td>Gesture</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>3.082031</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574943</th>\n",
       "      <td>SEQ_065531_000051</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>51</td>\n",
       "      <td>SUBJ_039498</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Performs gesture</td>\n",
       "      <td>Gesture</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>3.964844</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574944</th>\n",
       "      <td>SEQ_065531_000052</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>SEQ_065531</td>\n",
       "      <td>52</td>\n",
       "      <td>SUBJ_039498</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Performs gesture</td>\n",
       "      <td>Gesture</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>4.269531</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   row_id sequence_type sequence_id  sequence_counter  \\\n",
       "574940  SEQ_065531_000048    Non-Target  SEQ_065531                48   \n",
       "574941  SEQ_065531_000049    Non-Target  SEQ_065531                49   \n",
       "574942  SEQ_065531_000050    Non-Target  SEQ_065531                50   \n",
       "574943  SEQ_065531_000051    Non-Target  SEQ_065531                51   \n",
       "574944  SEQ_065531_000052    Non-Target  SEQ_065531                52   \n",
       "\n",
       "            subject                      orientation          behavior  \\\n",
       "574940  SUBJ_039498  Seated Lean Non Dom - FACE DOWN  Performs gesture   \n",
       "574941  SUBJ_039498  Seated Lean Non Dom - FACE DOWN  Performs gesture   \n",
       "574942  SUBJ_039498  Seated Lean Non Dom - FACE DOWN  Performs gesture   \n",
       "574943  SUBJ_039498  Seated Lean Non Dom - FACE DOWN  Performs gesture   \n",
       "574944  SUBJ_039498  Seated Lean Non Dom - FACE DOWN  Performs gesture   \n",
       "\n",
       "          phase            gesture     acc_x  ...  tof_5_v54  tof_5_v55  \\\n",
       "574940  Gesture  Write name on leg  3.503906  ...       62.0       65.0   \n",
       "574941  Gesture  Write name on leg  3.773438  ...       71.0       72.0   \n",
       "574942  Gesture  Write name on leg  3.082031  ...       80.0       77.0   \n",
       "574943  Gesture  Write name on leg  3.964844  ...       72.0       77.0   \n",
       "574944  Gesture  Write name on leg  4.269531  ...       -1.0       -1.0   \n",
       "\n",
       "        tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  \\\n",
       "574940       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "574941       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "574942       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "574943       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "574944       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "        tof_5_v62  tof_5_v63  \n",
       "574940       -1.0       71.0  \n",
       "574941       -1.0       -1.0  \n",
       "574942       -1.0       -1.0  \n",
       "574943       -1.0       -1.0  \n",
       "574944       -1.0       -1.0  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_whole_sequences(df_train,df_imu_columns,df_thermal_columns,df_tof_columns,max_steps=400):\n",
    "\n",
    "    nan_columns_X = df_train.columns[df_train.isnull().any()].tolist()\n",
    "    print(\"Columns in X with NaNs Before:\\n\", nan_columns_X)\n",
    "    df_train = df_train.interpolate(method=\"linear\", axis=0)\n",
    "    nan_columns_X = df_train.columns[df_train.isnull().any()].tolist()\n",
    "    print(\"Columns in X with NaNs After:\\n\", nan_columns_X)\n",
    "\n",
    "    df_train.drop([\n",
    "    'row_id',\n",
    "    'sequence_type',\n",
    "    'subject',\n",
    "    'orientation',\n",
    "    'behavior',\n",
    "    'phase'], axis=1, inplace=True)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df_train[\"gesture_encoded\"] = encoder.fit_transform(df_train[\"gesture\"])\n",
    "    class_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "    print(\"Class Mapping:\", class_mapping)\n",
    "\n",
    "    df_train.drop(['gesture'], axis=1, inplace=True)\n",
    "    \n",
    "    df_train = df_train.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "                    ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "    # Drop unnecessary columns early\n",
    "    df_train = df_train.drop(columns=[\"sequence_counter\"])  \n",
    "    \n",
    "    n_imu_features = len(df_imu_columns)\n",
    "    n_thermal_features = len(df_thermal_columns)\n",
    "    n_tof_features = len(df_tof_columns)\n",
    "\n",
    "    \n",
    "    # Find number of unique sequences\n",
    "    sequence_ids = df_train[\"sequence_id\"].unique()\n",
    "    n_sequences = len(sequence_ids)\n",
    "\n",
    "    # Preallocate final arrays\n",
    "    X_imu_train = np.zeros((n_sequences, max_steps, n_imu_features), dtype=np.float32)\n",
    "    X_thermal_train = np.zeros((n_sequences, max_steps, n_thermal_features), dtype=np.float32)\n",
    "    X_tof_train = np.zeros((n_sequences, max_steps, n_tof_features), dtype=np.float32)\n",
    "\n",
    "    Y = np.zeros((n_sequences,), dtype=np.float32)  \n",
    "    for i, seq_id in enumerate(sequence_ids):\n",
    "        if i % 100 ==0:\n",
    "            print(f\"Processing {i}/{n_sequences}\")\n",
    "\n",
    "        #imu\n",
    "        seq = df_train[df_train[\"sequence_id\"] == seq_id][df_imu_columns].values.astype(np.float32)\n",
    "        seq_len = len(seq)\n",
    "        if seq_len > max_steps:\n",
    "            seq = seq[-max_steps:]\n",
    "        X_imu_train[i, :seq_len, :] = seq\n",
    "        \n",
    "        #thermal\n",
    "        seq = df_train[df_train[\"sequence_id\"] == seq_id][df_thermal_columns].values.astype(np.float32)\n",
    "        seq_len = len(seq)\n",
    "        if seq_len > max_steps:\n",
    "            seq = seq[-max_steps:]\n",
    "        X_thermal_train[i, :seq_len, :] = seq\n",
    "\n",
    "\n",
    "        #tof\n",
    "        seq = df_train[df_train[\"sequence_id\"] == seq_id][df_tof_columns].values.astype(np.float32)\n",
    "        seq_len = len(seq)\n",
    "        if seq_len > max_steps:\n",
    "            seq = seq[-max_steps:]\n",
    "        X_tof_train[i, :seq_len, :] = seq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        label_row = df_train[df_train[\"sequence_id\"] == seq_id]['gesture_encoded'].iloc[0]\n",
    "        Y[i] = label_row\n",
    "    \n",
    "    return X_imu_train,X_thermal_train,X_tof_train ,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class Mapping: {'Above ear - pull hair': 0, 'Cheek - pinch skin': 1, 'Drink from bottle/cup': 2, 'Eyebrow - pull hair': 3, 'Eyelash - pull hair': 4, 'Feel around in tray and pull out an object': 5, 'Forehead - pull hairline': 6, 'Forehead - scratch': 7, 'Glasses on/off': 8, 'Neck - pinch skin': 9, 'Neck - scratch': 10, 'Pinch knee/leg skin': 11, 'Pull air toward your face': 12, 'Scratch knee/leg skin': 13, 'Text on phone': 14, 'Wave hello': 15, 'Write name in air': 16, 'Write name on leg': 17}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Above ear - pull hair', 'Cheek - pinch skin',\n",
       "       'Drink from bottle/cup', 'Eyebrow - pull hair',\n",
       "       'Eyelash - pull hair',\n",
       "       'Feel around in tray and pull out an object',\n",
       "       'Forehead - pull hairline', 'Forehead - scratch', 'Glasses on/off',\n",
       "       'Neck - pinch skin', 'Neck - scratch', 'Pinch knee/leg skin',\n",
       "       'Pull air toward your face', 'Scratch knee/leg skin',\n",
       "       'Text on phone', 'Wave hello', 'Write name in air',\n",
       "       'Write name on leg'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classMapping= np.load(\"imu_18_classes.npy\",allow_pickle=True)\n",
    "classMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Above ear - pull hair': 0,\n",
       " 'Cheek - pinch skin': 1,\n",
       " 'Drink from bottle/cup': 2,\n",
       " 'Eyebrow - pull hair': 3,\n",
       " 'Eyelash - pull hair': 4,\n",
       " 'Feel around in tray and pull out an object': 5,\n",
       " 'Forehead - pull hairline': 6,\n",
       " 'Forehead - scratch': 7,\n",
       " 'Glasses on/off': 8,\n",
       " 'Neck - pinch skin': 9,\n",
       " 'Neck - scratch': 10,\n",
       " 'Pinch knee/leg skin': 11,\n",
       " 'Pull air toward your face': 12,\n",
       " 'Scratch knee/leg skin': 13,\n",
       " 'Text on phone': 14,\n",
       " 'Wave hello': 15,\n",
       " 'Write name in air': 16,\n",
       " 'Write name on leg': 17}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_int = {cls: i for i, cls in enumerate(classMapping)}\n",
    "class_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5.0,\n",
       " 1: 5.0,\n",
       " 2: 1.0,\n",
       " 3: 5.0,\n",
       " 4: 5.0,\n",
       " 5: 1.0,\n",
       " 6: 5.0,\n",
       " 7: 5.0,\n",
       " 8: 1.0,\n",
       " 9: 5.0,\n",
       " 10: 5.0,\n",
       " 11: 1.0,\n",
       " 12: 1.0,\n",
       " 13: 1.0,\n",
       " 14: 1.0,\n",
       " 15: 1.0,\n",
       " 16: 1.0,\n",
       " 17: 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_classes = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "\n",
    "# Build class_weight dict\n",
    "n_classes = len(classMapping)\n",
    "class_weight = {\n",
    "    i: 5.0 if classMapping[i] in important_classes else 1.0\n",
    "    for i in range(n_classes)\n",
    "}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found: 'Above ear - pull hair'\n",
      "✅ Found: 'Forehead - pull hairline'\n",
      "✅ Found: 'Forehead - scratch'\n",
      "✅ Found: 'Eyebrow - pull hair'\n",
      "✅ Found: 'Eyelash - pull hair'\n",
      "✅ Found: 'Neck - pinch skin'\n",
      "✅ Found: 'Neck - scratch'\n",
      "✅ Found: 'Cheek - pinch skin'\n"
     ]
    }
   ],
   "source": [
    "for t_class in important_classes:\n",
    "    if t_class not in classMapping:\n",
    "        print(f\"⚠️ Target class NOT found in class_names: '{t_class}'\")\n",
    "    else:\n",
    "        print(f\"✅ Found: '{t_class}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X with NaNs Before:\n",
      " ['rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424233/1628948026.py:8: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_train = df_train.interpolate(method=\"linear\", axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X with NaNs After:\n",
      " []\n",
      "Class Mapping: {'Above ear - pull hair': 0, 'Cheek - pinch skin': 1, 'Drink from bottle/cup': 2, 'Eyebrow - pull hair': 3, 'Eyelash - pull hair': 4, 'Feel around in tray and pull out an object': 5, 'Forehead - pull hairline': 6, 'Forehead - scratch': 7, 'Glasses on/off': 8, 'Neck - pinch skin': 9, 'Neck - scratch': 10, 'Pinch knee/leg skin': 11, 'Pull air toward your face': 12, 'Scratch knee/leg skin': 13, 'Text on phone': 14, 'Wave hello': 15, 'Write name in air': 16, 'Write name on leg': 17}\n",
      "Processing 0/8151\n",
      "Processing 100/8151\n",
      "Processing 200/8151\n",
      "Processing 300/8151\n",
      "Processing 400/8151\n",
      "Processing 500/8151\n",
      "Processing 600/8151\n",
      "Processing 700/8151\n",
      "Processing 800/8151\n",
      "Processing 900/8151\n",
      "Processing 1000/8151\n",
      "Processing 1100/8151\n",
      "Processing 1200/8151\n",
      "Processing 1300/8151\n",
      "Processing 1400/8151\n",
      "Processing 1500/8151\n",
      "Processing 1600/8151\n",
      "Processing 1700/8151\n",
      "Processing 1800/8151\n",
      "Processing 1900/8151\n",
      "Processing 2000/8151\n",
      "Processing 2100/8151\n",
      "Processing 2200/8151\n",
      "Processing 2300/8151\n",
      "Processing 2400/8151\n",
      "Processing 2500/8151\n",
      "Processing 2600/8151\n",
      "Processing 2700/8151\n",
      "Processing 2800/8151\n",
      "Processing 2900/8151\n",
      "Processing 3000/8151\n",
      "Processing 3100/8151\n",
      "Processing 3200/8151\n",
      "Processing 3300/8151\n",
      "Processing 3400/8151\n",
      "Processing 3500/8151\n",
      "Processing 3600/8151\n",
      "Processing 3700/8151\n",
      "Processing 3800/8151\n",
      "Processing 3900/8151\n",
      "Processing 4000/8151\n",
      "Processing 4100/8151\n",
      "Processing 4200/8151\n",
      "Processing 4300/8151\n",
      "Processing 4400/8151\n",
      "Processing 4500/8151\n",
      "Processing 4600/8151\n",
      "Processing 4700/8151\n",
      "Processing 4800/8151\n",
      "Processing 4900/8151\n",
      "Processing 5000/8151\n",
      "Processing 5100/8151\n",
      "Processing 5200/8151\n",
      "Processing 5300/8151\n",
      "Processing 5400/8151\n",
      "Processing 5500/8151\n",
      "Processing 5600/8151\n",
      "Processing 5700/8151\n",
      "Processing 5800/8151\n",
      "Processing 5900/8151\n",
      "Processing 6000/8151\n",
      "Processing 6100/8151\n",
      "Processing 6200/8151\n",
      "Processing 6300/8151\n",
      "Processing 6400/8151\n",
      "Processing 6500/8151\n",
      "Processing 6600/8151\n",
      "Processing 6700/8151\n",
      "Processing 6800/8151\n",
      "Processing 6900/8151\n",
      "Processing 7000/8151\n",
      "Processing 7100/8151\n",
      "Processing 7200/8151\n",
      "Processing 7300/8151\n",
      "Processing 7400/8151\n",
      "Processing 7500/8151\n",
      "Processing 7600/8151\n",
      "Processing 7700/8151\n",
      "Processing 7800/8151\n",
      "Processing 7900/8151\n",
      "Processing 8000/8151\n",
      "Processing 8100/8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8151, 400, 7), (8151, 400, 5), (8151, 400, 320), (8151,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imu_train,X_thermal_train,X_tof_train ,Y = prepare_whole_sequences(df_train,df_imu_columns,df_thermal_columns,df_tof_columns)\n",
    "X_imu_train.shape,X_thermal_train.shape,X_tof_train.shape ,Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mdf_train\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgc\u001b[39;00m \n\u001b[32m      3\u001b[39m gc.collect()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "del df_train\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"X_imu_train X_thermal_train X_tof_train Y unscaled.npz\", X_imu_train=X_imu_train,X_thermal_train=X_thermal_train,X_tof_train=X_tof_train,Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"X_imu_train X_thermal_train X_tof_train Y unscaled.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8151, 400, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imu_train = data[\"X_imu_train\"]\n",
    "X_imu_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8151, 400, 320)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tof_train = data[\"X_tof_train\"]\n",
    "X_tof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8151,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[\"Y\"]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# stratified split train+temp vs test\n",
    "X_train_tof, X_val_tof, y_train_tof, y_val_tof = train_test_split(\n",
    "    X_tof_train, Y, test_size=0.1, stratify=Y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7335, 400, 320), (816, 400, 320), (7335,), (816,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tof.shape, X_val_tof.shape, y_train_tof.shape, y_val_tof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21183"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_tof_train\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization,\n",
    "    GlobalAveragePooling1D, Attention, LayerNormalization,\n",
    "    Masking, Concatenate, MultiHeadAttention\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "\n",
    "\n",
    "\n",
    "def create_single_task_model(\n",
    "    max_len=400,\n",
    "    n_features=320,\n",
    "    n_classes=18\n",
    "):\n",
    "    \"\"\"\n",
    "    Single-task version of the model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(max_len, n_features))\n",
    "    x = Masking(mask_value=0.0)(input_layer)\n",
    "    \n",
    "    # Conv1D blocks\n",
    "    x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(x)\n",
    "    x = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(x)\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    attention_output = MultiHeadAttention(num_heads=8, key_dim=64)(x, x)\n",
    "    x = tf.keras.layers.Add()([x, attention_output])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Global pooling and dense layers\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "\n",
    "    output = Dense(18, activation='softmax', name='gesture_output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "  # # Compile model\n",
    "    model.compile(\n",
    "     optimizer='adam',\n",
    "     loss=SparseCategoricalCrossentropy(),   \n",
    "     metrics=[\n",
    "        'accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/Desktop/ML_DL_Projects/ml_env/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_3' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">61,504</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m320\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m320\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m61,504\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m24,704\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m24,640\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │    \u001b[38;5;34m132,672\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │      \u001b[38;5;34m1,170\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,642</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m410,642\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,130</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m410,130\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">61,504</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m320\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m320\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m61,504\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m24,704\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m24,640\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │    \u001b[38;5;34m132,672\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │      \u001b[38;5;34m1,170\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,642</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m410,642\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,130</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m410,130\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tof_model = create_single_task_model()\n",
    "tof_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.1793 - loss: 7.6023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/Desktop/ML_DL_Projects/ml_env/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_3' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 433ms/step - accuracy: 0.1924 - loss: 7.4337 - val_accuracy: 0.2230 - val_loss: 2.2692\n",
      "Epoch 2/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 426ms/step - accuracy: 0.2245 - loss: 6.8867 - val_accuracy: 0.2525 - val_loss: 2.1696\n",
      "Epoch 3/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 423ms/step - accuracy: 0.2525 - loss: 6.6153 - val_accuracy: 0.2206 - val_loss: 2.7027\n",
      "Epoch 4/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 423ms/step - accuracy: 0.2803 - loss: 6.4120 - val_accuracy: 0.2782 - val_loss: 2.1322\n",
      "Epoch 5/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 421ms/step - accuracy: 0.2890 - loss: 6.2481 - val_accuracy: 0.3248 - val_loss: 1.9185\n",
      "Epoch 6/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 423ms/step - accuracy: 0.3215 - loss: 6.0302 - val_accuracy: 0.3039 - val_loss: 2.0551\n",
      "Epoch 7/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 422ms/step - accuracy: 0.3269 - loss: 5.9374 - val_accuracy: 0.3309 - val_loss: 2.0087\n",
      "Epoch 8/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 421ms/step - accuracy: 0.3423 - loss: 5.6813 - val_accuracy: 0.3762 - val_loss: 1.9735\n",
      "Epoch 9/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 420ms/step - accuracy: 0.3569 - loss: 5.6999 - val_accuracy: 0.3578 - val_loss: 1.8905\n",
      "Epoch 10/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 422ms/step - accuracy: 0.3614 - loss: 5.5004 - val_accuracy: 0.3811 - val_loss: 1.8658\n",
      "Epoch 11/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 420ms/step - accuracy: 0.3665 - loss: 5.3558 - val_accuracy: 0.3566 - val_loss: 1.8563\n",
      "Epoch 12/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 418ms/step - accuracy: 0.3816 - loss: 5.2919 - val_accuracy: 0.3775 - val_loss: 1.8125\n",
      "Epoch 13/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 425ms/step - accuracy: 0.3910 - loss: 5.1863 - val_accuracy: 0.4020 - val_loss: 1.7570\n",
      "Epoch 14/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 413ms/step - accuracy: 0.4128 - loss: 4.9937 - val_accuracy: 0.4093 - val_loss: 1.7792\n",
      "Epoch 15/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 418ms/step - accuracy: 0.4035 - loss: 4.9937 - val_accuracy: 0.4216 - val_loss: 1.7436\n",
      "Epoch 16/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 414ms/step - accuracy: 0.4199 - loss: 4.8251 - val_accuracy: 0.4142 - val_loss: 1.6743\n",
      "Epoch 17/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 414ms/step - accuracy: 0.4350 - loss: 4.7144 - val_accuracy: 0.4350 - val_loss: 1.6610\n",
      "Epoch 18/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 537ms/step - accuracy: 0.4408 - loss: 4.6670 - val_accuracy: 0.4412 - val_loss: 1.6603\n",
      "Epoch 19/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 704ms/step - accuracy: 0.4537 - loss: 4.4912 - val_accuracy: 0.4289 - val_loss: 1.7890\n",
      "Epoch 20/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 693ms/step - accuracy: 0.4620 - loss: 4.4001 - val_accuracy: 0.4216 - val_loss: 1.8354\n",
      "Epoch 21/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 689ms/step - accuracy: 0.4548 - loss: 4.4673 - val_accuracy: 0.4498 - val_loss: 1.5986\n",
      "Epoch 22/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 722ms/step - accuracy: 0.4615 - loss: 4.3750 - val_accuracy: 0.4216 - val_loss: 1.7414\n",
      "Epoch 23/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 695ms/step - accuracy: 0.4750 - loss: 4.2356 - val_accuracy: 0.4044 - val_loss: 1.8797\n",
      "Epoch 24/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 704ms/step - accuracy: 0.4848 - loss: 4.1913 - val_accuracy: 0.4301 - val_loss: 1.7278\n",
      "Epoch 25/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 703ms/step - accuracy: 0.4873 - loss: 4.1185 - val_accuracy: 0.4387 - val_loss: 1.7824\n",
      "Epoch 26/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 705ms/step - accuracy: 0.4945 - loss: 4.0386 - val_accuracy: 0.4571 - val_loss: 1.6471\n",
      "Epoch 27/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 709ms/step - accuracy: 0.4982 - loss: 4.0043 - val_accuracy: 0.4436 - val_loss: 1.6702\n",
      "Epoch 28/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 705ms/step - accuracy: 0.5063 - loss: 3.9395 - val_accuracy: 0.4681 - val_loss: 1.6200\n",
      "Epoch 29/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 710ms/step - accuracy: 0.5085 - loss: 3.9366 - val_accuracy: 0.4547 - val_loss: 1.6635\n",
      "Epoch 30/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 712ms/step - accuracy: 0.5187 - loss: 3.8283 - val_accuracy: 0.4767 - val_loss: 1.6555\n",
      "Epoch 31/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 703ms/step - accuracy: 0.5261 - loss: 3.8075 - val_accuracy: 0.4387 - val_loss: 1.7115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7525a02d7fb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',   # or 'val_accuracy'\n",
    "    patience=10,           # stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True  # roll back to the best epoch\n",
    ")\n",
    "\n",
    "history = tof_model.fit(\n",
    "    X_train_tof, \n",
    "    y_train_tof,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    validation_data=(X_val_tof, y_val_tof),\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "tof_model.save(\"cmi_tof_18_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "tof_latest_best_model = load_model(\"cmi_tof_18_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.4498 - loss: 1.5986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.598624587059021, 0.44975489377975464]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tof_latest_best_model.evaluate(X_val_tof, y_val_tof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "[[2.43044775e-02 1.39242843e-01 4.07723310e-05 1.69528693e-01\n",
      "  9.64054763e-02 2.13218125e-04 2.32471764e-01 2.06635267e-01\n",
      "  1.92442356e-04 5.65579869e-02 7.28068277e-02 2.61368899e-04\n",
      "  6.10996067e-05 2.13510735e-04 4.87679150e-04 7.86122400e-05\n",
      "  3.83386912e-04 1.14615214e-04]\n",
      " [2.01481700e-01 1.46152616e-01 3.88851040e-05 5.27585782e-02\n",
      "  5.26381806e-02 2.47413642e-04 1.03096433e-01 4.79946695e-02\n",
      "  4.29860374e-04 2.18471885e-01 1.72102809e-01 1.97114714e-04\n",
      "  7.38842180e-04 1.51988614e-04 1.33351714e-04 4.44893783e-04\n",
      "  2.68892781e-03 2.31877653e-04]\n",
      " [8.40210181e-04 2.16595475e-02 2.14671317e-07 1.25069097e-01\n",
      "  6.16383739e-02 1.06745183e-05 2.60602087e-01 5.03953874e-01\n",
      "  1.84867758e-07 9.70196538e-03 1.62638463e-02 2.73580536e-05\n",
      "  2.18113470e-07 1.70236544e-05 2.02971598e-04 9.45323563e-07\n",
      "  7.32169201e-06 3.94743711e-06]\n",
      " [5.21582700e-02 1.34324685e-01 2.30057936e-04 1.30784437e-01\n",
      "  1.13180816e-01 1.62713975e-03 1.41161650e-01 1.46082222e-01\n",
      "  6.30161900e-04 1.30941391e-01 1.42667294e-01 1.04244344e-03\n",
      "  2.12946354e-04 6.66625099e-04 2.76840664e-03 2.27745317e-04\n",
      "  5.84475987e-04 7.09244632e-04]\n",
      " [2.29013267e-07 4.57709530e-06 8.47182673e-06 6.15575773e-05\n",
      "  1.28784704e-05 2.69779097e-08 2.26442808e-05 1.35116416e-05\n",
      "  1.82755110e-13 2.59638364e-06 1.12198950e-06 4.73052182e-07\n",
      "  6.52997156e-10 7.12505289e-06 9.99864578e-01 3.88017049e-11\n",
      "  1.42592134e-08 2.39286464e-07]]\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "imu_pred = imu_latest_best_model.predict(X_val_imu[:5])\n",
    "print(imu_pred)\n",
    "imu_pred_i = np.argmax(imu_pred)\n",
    "print(imu_pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 296ms/step\n",
      "Binary F1: 0.923368022705771\n",
      "Macro F1: 0.5221649041567624\n",
      "Contest Score: 0.7227664634312667\n"
     ]
    }
   ],
   "source": [
    "# Convert validation labels to integer indices\n",
    "y_val_indices = y_val_tof.astype(int)\n",
    "\n",
    "# Convert indices to class names\n",
    "y_true_names = [classMapping[i] for i in y_val_indices]\n",
    "\n",
    "# Predict class indices\n",
    "y_pred = tof_latest_best_model.predict(X_val_tof)\n",
    "y_pred_indices = np.argmax(y_pred, axis=1)  # make sure axis=1 for batch\n",
    "y_pred_names = [classMapping[i] for i in y_pred_indices]\n",
    "\n",
    "# Binary labels: 1 if target, 0 if non-target\n",
    "y_true_binary = [1 if name in important_classes else 0 for name in y_true_names]\n",
    "y_pred_binary = [1 if name in important_classes else 0 for name in y_pred_names]\n",
    "\n",
    "# Compute binary F1\n",
    "from sklearn.metrics import f1_score\n",
    "binary_f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "print(\"Binary F1:\", binary_f1)\n",
    "\n",
    "# Collapse non-targets\n",
    "y_true_collapsed = [name if name in important_classes else 'non_target' for name in y_true_names]\n",
    "y_pred_collapsed = [name if name in important_classes else 'non_target' for name in y_pred_names]\n",
    "\n",
    "# Macro F1\n",
    "macro_f1 = f1_score(y_true_collapsed, y_pred_collapsed, average='macro')\n",
    "print(\"Macro F1:\", macro_f1)\n",
    "\n",
    "# Final contest score\n",
    "contest_score = (binary_f1 + macro_f1) / 2\n",
    "print(\"Contest Score:\", contest_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 6., 7., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_imu[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map non-targets to a single label\n",
    "y_true_collapsed = [name if name in target_classes else 'non_target' for name in y_true_names]\n",
    "y_pred_collapsed = [name if name in target_classes else 'non_target' for name in y_pred_names]\n",
    "\n",
    "# Macro F1\n",
    "macro_f1 = f1_score(y_true_collapsed, y_pred_collapsed, average='macro')\n",
    "print(\"Macro F1:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contest_score = (binary_f1 + macro_f1) / 2\n",
    "print(\"Contest Score:\", contest_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = X_val_thermal[0].reshape(1,400,5)\n",
    "# test_data.shape\n",
    "# best_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_data_thermla = np.zeros((1,400,5))\n",
    "# empty_data_thermla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.predict(empty_data_thermla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def safe_predict(model, X):\n",
    "#     # If all input features are zero\n",
    "#     if (X == 0).all():\n",
    "#         return np.zeros((X.shape[0], model.output_shape[-1]))  # all-zero probabilities\n",
    "#     else:\n",
    "#         return model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_predict(best_model,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 17:40:13.516912: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-31 17:40:13.704410: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756642213.771140   77573 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756642213.789132   77573 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756642213.938567   77573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756642213.938588   77573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756642213.938589   77573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756642213.938590   77573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-31 17:40:13.955448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, Conv2D, LSTM, Dense, Dropout, BatchNormalization,\n",
    "    GlobalAveragePooling1D, GlobalAveragePooling2D, LayerNormalization,\n",
    "    Masking, Concatenate, MultiHeadAttention, Reshape, Flatten\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import numpy as np\n",
    "\n",
    "def create_tof_stream(stream_name=\"tof\"):\n",
    "    \"\"\"\n",
    "    ToF Stream: Conv2D + LSTM + Attention + Dense\n",
    "    Input shape: (batch_size, 400, 320)\n",
    "    We'll reshape 320 features as 5 sensors × 8×8 grids\n",
    "    \"\"\"\n",
    "    input_shape=(400, 320)\n",
    "    input_layer = Input(shape=input_shape, name=f'{stream_name}_input')\n",
    "    \n",
    "    # Handle missing ToF data (replace -1 with 0 and mask)\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.where(x == -1, 0.0, x), \n",
    "                               name=f'{stream_name}_handle_missing')(input_layer)\n",
    "    \n",
    "    # Reshape to (batch, time, 5, 8, 8) for 5 sensors with 8x8 grids\n",
    "    x = Reshape((input_shape[0], 5, 8, 8), name=f'{stream_name}_reshape')(x)\n",
    "    \n",
    "    # Process each timestep with Conv2D (via TimeDistributed)\n",
    "    x = tf.keras.layers.TimeDistributed(\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'), \n",
    "        name=f'{stream_name}_conv2d_1'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.TimeDistributed(BatchNormalization(), name=f'{stream_name}_bn1')(x)\n",
    "    x = tf.keras.layers.TimeDistributed(Dropout(0.3), name=f'{stream_name}_dropout1')(x)\n",
    "    \n",
    "    x = tf.keras.layers.TimeDistributed(\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'), \n",
    "        name=f'{stream_name}_conv2d_2'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.TimeDistributed(BatchNormalization(), name=f'{stream_name}_bn2')(x)\n",
    "    x = tf.keras.layers.TimeDistributed(Dropout(0.3), name=f'{stream_name}_dropout2')(x)\n",
    "    \n",
    "    # Flatten spatial dimensions but keep time and features\n",
    "    x = tf.keras.layers.TimeDistributed(\n",
    "        GlobalAveragePooling2D(), \n",
    "        name=f'{stream_name}_global_pool'\n",
    "    )(x)  # Shape: (batch, time, 64)\n",
    "    \n",
    "    # LSTM for temporal modeling\n",
    "    x = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, \n",
    "             name=f'{stream_name}_lstm1')(x)\n",
    "    x = LSTM(32, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, \n",
    "             name=f'{stream_name}_lstm2')(x)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Add Multi-Head Attention\n",
    "    # -------------------------------\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=32, \n",
    "                                     name=f'{stream_name}_mha')(x, x)\n",
    "    x = tf.keras.layers.Add(name=f'{stream_name}_attn_add')([x, attn_output])\n",
    "    x = LayerNormalization(name=f'{stream_name}_attn_norm')(x)\n",
    "\n",
    "    # Global pooling\n",
    "    x = GlobalAveragePooling1D(name=f'{stream_name}_gap')(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = Dense(128, activation='relu', name=f'{stream_name}_dense1')(x)\n",
    "    x = Dropout(0.3, name=f'{stream_name}_dropout_dense1')(x)\n",
    "    x = Dense(64, activation='relu', name=f'{stream_name}_dense2')(x)\n",
    "    x = Dropout(0.3, name=f'{stream_name}_dropout_dense2')(x)\n",
    "\n",
    "\n",
    "    output = Dense(18, activation='softmax', name='gesture_output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "  # # Compile model\n",
    "    model.compile(\n",
    "     optimizer='adam',\n",
    "     loss=SparseCategoricalCrossentropy(),   \n",
    "     metrics=[\n",
    "        'accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 17:40:18.867221: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-08-31 17:40:18.867242: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-08-31 17:40:18.867246: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: ankur-Legion-5-15IRX9\n",
      "2025-08-31 17:40:18.867248: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: ankur-Legion-5-15IRX9\n",
      "2025-08-31 17:40:18.867368: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 575.64.3\n",
      "2025-08-31 17:40:18.867379: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 575.64.3\n",
      "2025-08-31 17:40:18.867380: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 575.64.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tof_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_handle_missing  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_reshape         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_handle_missi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_conv2d_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,336</span> │ tof_reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_bn1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ tof_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_conv2d_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ tof_dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_bn2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ tof_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_global_pool     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_lstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ tof_global_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_lstm2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ tof_lstm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_mha             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> │ tof_lstm2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ tof_lstm2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_attn_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_lstm2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ tof_mha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_attn_norm       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ tof_attn_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_gap             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_attn_norm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ tof_gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout_dense1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ tof_dropout_dens… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout_dense2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tof_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │ tof_dropout_dens… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tof_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m320\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_handle_missing  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m320\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ tof_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_reshape         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ tof_handle_missi… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_conv2d_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │      \u001b[38;5;34m2,336\u001b[0m │ tof_reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_bn1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │        \u001b[38;5;34m128\u001b[0m │ tof_conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ tof_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_conv2d_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │     \u001b[38;5;34m18,496\u001b[0m │ tof_dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_bn2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │        \u001b[38;5;34m256\u001b[0m │ tof_conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ tof_bn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_global_pool     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ tof_dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_lstm1 (\u001b[38;5;33mLSTM\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ tof_global_pool[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_lstm2 (\u001b[38;5;33mLSTM\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │     \u001b[38;5;34m12,416\u001b[0m │ tof_lstm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_mha             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │     \u001b[38;5;34m16,800\u001b[0m │ tof_lstm2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ tof_lstm2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_attn_add (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ tof_lstm2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ tof_mha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_attn_norm       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ tof_attn_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_gap             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ tof_attn_norm[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dense1 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m4,224\u001b[0m │ tof_gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout_dense1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ tof_dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dense2 (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ tof_dropout_dens… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tof_dropout_dense2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ tof_dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │      \u001b[38;5;34m1,170\u001b[0m │ tof_dropout_dens… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,170</span> (379.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,170\u001b[0m (379.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,978</span> (378.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96,978\u001b[0m (378.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tof_model = create_tof_stream()\n",
    "tof_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',   # or 'val_accuracy'\n",
    "    patience=10,           # stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True  # roll back to the best epoch\n",
    ")\n",
    "\n",
    "history = tof_model.fit(\n",
    "    X_train_tof, \n",
    "    y_train_tof, \n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    validation_data=(X_val_tof, y_val_tof),\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Input, Conv1D, Conv2D, LSTM, Dense, Dropout, BatchNormalization,\n",
    "#     GlobalAveragePooling1D, GlobalAveragePooling2D, LayerNormalization,\n",
    "#     Masking, Concatenate, MultiHeadAttention, Reshape, Flatten\n",
    "# )\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# import numpy as np\n",
    "\n",
    "# def create_imu_stream(input_shape, stream_name=\"imu\"):\n",
    "#     \"\"\"\n",
    "#     IMU Stream: Conv1D + LSTM\n",
    "#     Input shape: (batch_size, 400, 7)\n",
    "#     \"\"\"\n",
    "#     input_layer = Input(shape=input_shape, name=f'{stream_name}_input')\n",
    "#     x = Masking(mask_value=0.0, name=f'{stream_name}_masking')(input_layer)\n",
    "    \n",
    "#     # Conv1D blocks for local temporal patterns\n",
    "#     x = Conv1D(64, 3, activation='relu', padding='same', name=f'{stream_name}_conv1')(x)\n",
    "#     x = BatchNormalization(name=f'{stream_name}_bn1')(x)\n",
    "#     x = Dropout(0.3, name=f'{stream_name}_dropout1')(x)\n",
    "    \n",
    "#     x = Conv1D(128, 3, activation='relu', padding='same', name=f'{stream_name}_conv2')(x)\n",
    "#     x = BatchNormalization(name=f'{stream_name}_bn2')(x)\n",
    "#     x = Dropout(0.3, name=f'{stream_name}_dropout2')(x)\n",
    "    \n",
    "#     x = Conv1D(64, 3, activation='relu', padding='same', name=f'{stream_name}_conv3')(x)\n",
    "#     x = BatchNormalization(name=f'{stream_name}_bn3')(x)\n",
    "#     x = Dropout(0.3, name=f'{stream_name}_dropout3')(x)\n",
    "    \n",
    "#     # LSTM layers for temporal modeling\n",
    "#     x = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, name=f'{stream_name}_lstm1')(x)\n",
    "#     x = LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, name=f'{stream_name}_lstm2')(x)\n",
    "    \n",
    "#     return input_layer, x\n",
    "\n",
    "# def create_thermal_stream(input_shape, stream_name=\"thermal\"):\n",
    "#     \"\"\"\n",
    "#     Thermal Stream: Conv1D + LSTM\n",
    "#     Input shape: (batch_size, 400, 5)\n",
    "#     \"\"\"\n",
    "#     input_layer = Input(shape=input_shape, name=f'{stream_name}_input')\n",
    "#     x = Masking(mask_value=0.0, name=f'{stream_name}_masking')(input_layer)\n",
    "    \n",
    "#     # Conv1D blocks for thermal patterns\n",
    "#     x = Conv1D(32, 3, activation='relu', padding='same', name=f'{stream_name}_conv1')(x)\n",
    "#     x = BatchNormalization(name=f'{stream_name}_bn1')(x)\n",
    "#     x = Dropout(0.3, name=f'{stream_name}_dropout1')(x)\n",
    "    \n",
    "#     x = Conv1D(64, 3, activation='relu', padding='same', name=f'{stream_name}_conv2')(x)\n",
    "#     x = BatchNormalization(name=f'{stream_name}_bn2')(x)\n",
    "#     x = Dropout(0.3, name=f'{stream_name}_dropout2')(x)\n",
    "    \n",
    "#     x = Conv1D(32, 3, activation='relu', padding='same', name=f'{stream_name}_conv3')(x)\n",
    "#     x = BatchNormalization(name=f'{stream_name}_bn3')(x)\n",
    "#     x = Dropout(0.3, name=f'{stream_name}_dropout3')(x)\n",
    "    \n",
    "#     # LSTM layers\n",
    "#     x = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, name=f'{stream_name}_lstm1')(x)\n",
    "#     x = LSTM(32, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, name=f'{stream_name}_lstm2')(x)\n",
    "    \n",
    "#     return input_layer, x\n",
    "\n",
    "# def create_tof_stream(input_shape, stream_name=\"tof\"):\n",
    "#     \"\"\"\n",
    "#     ToF Stream: Conv2D + LSTM\n",
    "#     Input shape: (batch_size, 400, 320)\n",
    "#     We'll reshape 320 features as 5 sensors × 8×8 grids\n",
    "#     \"\"\"\n",
    "#     input_layer = Input(shape=input_shape, name=f'{stream_name}_input')\n",
    "    \n",
    "#     # Handle missing ToF data (replace -1 with 0 and mask)\n",
    "#     x = tf.keras.layers.Lambda(lambda x: tf.where(x == -1, 0.0, x), name=f'{stream_name}_handle_missing')(input_layer)\n",
    "    \n",
    "#     # Reshape to (batch, time, 5, 8, 8) for 5 sensors with 8x8 grids\n",
    "#     x = Reshape((input_shape[0], 5, 8, 8), name=f'{stream_name}_reshape')(x)\n",
    "    \n",
    "#     # Process each timestep with Conv2D\n",
    "#     # We'll use TimeDistributed to apply Conv2D across time dimension\n",
    "#     x = tf.keras.layers.TimeDistributed(\n",
    "#         Conv2D(32, (3, 3), activation='relu', padding='same'), \n",
    "#         name=f'{stream_name}_conv2d_1'\n",
    "#     )(x)\n",
    "#     x = tf.keras.layers.TimeDistributed(BatchNormalization(), name=f'{stream_name}_bn1')(x)\n",
    "#     x = tf.keras.layers.TimeDistributed(Dropout(0.3), name=f'{stream_name}_dropout1')(x)\n",
    "    \n",
    "#     x = tf.keras.layers.TimeDistributed(\n",
    "#         Conv2D(64, (3, 3), activation='relu', padding='same'), \n",
    "#         name=f'{stream_name}_conv2d_2'\n",
    "#     )(x)\n",
    "#     x = tf.keras.layers.TimeDistributed(BatchNormalization(), name=f'{stream_name}_bn2')(x)\n",
    "#     x = tf.keras.layers.TimeDistributed(Dropout(0.3), name=f'{stream_name}_dropout2')(x)\n",
    "    \n",
    "#     # Flatten spatial dimensions but keep time and features\n",
    "#     x = tf.keras.layers.TimeDistributed(\n",
    "#         GlobalAveragePooling2D(), \n",
    "#         name=f'{stream_name}_global_pool'\n",
    "#     )(x)  # Now shape is (batch, time, 64)\n",
    "    \n",
    "#     # LSTM for temporal modeling\n",
    "#     x = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, name=f'{stream_name}_lstm1')(x)\n",
    "#     x = LSTM(32, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, name=f'{stream_name}_lstm2')(x)\n",
    "    \n",
    "#     return input_layer, x\n",
    "\n",
    "# def create_multimodal_bfrb_model(\n",
    "#     imu_shape=(400, 7),\n",
    "#     thermal_shape=(400, 5), \n",
    "#     tof_shape=(400, 320),\n",
    "#     n_classes=18,\n",
    "#     fusion_dim=128\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Multi-modal model with IMU, Thermal, and ToF streams\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Create individual sensor streams\n",
    "#     imu_input, imu_features = create_imu_stream(imu_shape, \"imu\")\n",
    "#     thermal_input, thermal_features = create_thermal_stream(thermal_shape, \"thermal\") \n",
    "#     tof_input, tof_features = create_tof_stream(tof_shape, \"tof\")\n",
    "    \n",
    "#     # Feature fusion using attention mechanism\n",
    "#     # Stack features for attention\n",
    "#     stacked_features = tf.keras.layers.Lambda(\n",
    "#         lambda x: tf.stack(x, axis=1), \n",
    "#         name='stack_features'\n",
    "#     )([imu_features, thermal_features, tof_features])\n",
    "    \n",
    "#     # Multi-head attention for feature fusion\n",
    "#     fused_features = MultiHeadAttention(\n",
    "#         num_heads=4, \n",
    "#         key_dim=fusion_dim//4, \n",
    "#         name='fusion_attention'\n",
    "#     )(stacked_features, stacked_features)\n",
    "    \n",
    "#     # Global average pooling across sensor dimension\n",
    "#     fused_features = tf.keras.layers.Lambda(\n",
    "#         lambda x: tf.reduce_mean(x, axis=1), \n",
    "#         name='sensor_pooling'\n",
    "#     )(fused_features)\n",
    "    \n",
    "#     # Final classification layers\n",
    "#     x = Dense(fusion_dim, activation='relu', name='fusion_dense1')(fused_features)\n",
    "#     x = Dropout(0.4, name='fusion_dropout1')(x)\n",
    "#     x = Dense(64, activation='relu', name='fusion_dense2')(x)\n",
    "#     x = Dropout(0.4, name='fusion_dropout2')(x)\n",
    "    \n",
    "#     # Output layer for 18-class classification\n",
    "#     output = Dense(n_classes, activation='softmax', name='gesture_classification')(x)\n",
    "    \n",
    "#     # Create model\n",
    "#     model = Model(\n",
    "#         inputs=[imu_input, thermal_input, tof_input],\n",
    "#         outputs=output,\n",
    "#         name='MultiModal_BFRB_Detector'\n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# def compile_and_train_model(\n",
    "#     model, \n",
    "#     X_train_list, y_train, \n",
    "#     X_val_list, y_val,\n",
    "#     epochs=20,\n",
    "#     batch_size=32,\n",
    "#     learning_rate=0.001\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Compile and train the multi-modal model\n",
    "    \n",
    "#     X_train_list: [X_train_imu, X_train_thermal, X_train_tof]\n",
    "#     X_val_list: [X_val_imu, X_val_thermal, X_val_tof]\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Encode labels to ensure they start from 0\n",
    "#     from sklearn.preprocessing import LabelEncoder\n",
    "#     le = LabelEncoder()\n",
    "#     y_train_encoded = le.fit_transform(y_train)\n",
    "#     y_val_encoded = le.transform(y_val)\n",
    "    \n",
    "#     print(f\"Number of classes: {len(le.classes_)}\")\n",
    "#     print(f\"Class labels: {le.classes_}\")\n",
    "    \n",
    "#     # Compile model\n",
    "#     model.compile(\n",
    "#         optimizer=Adam(learning_rate=learning_rate),\n",
    "#         loss=SparseCategoricalCrossentropy(from_logits=False),\n",
    "#         metrics=['accuracy', 'sparse_top_k_categorical_accuracy']\n",
    "#     )\n",
    "    \n",
    "#     # Callbacks\n",
    "#     from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "    \n",
    "#     callbacks = [\n",
    "#         EarlyStopping(patience=7, restore_best_weights=True, verbose=1),\n",
    "#         ReduceLROnPlateau(patience=3, factor=0.5, verbose=1, min_lr=1e-7),\n",
    "#         ModelCheckpoint('best_multimodal_model.h5', save_best_only=True, verbose=1)\n",
    "#     ]\n",
    "    \n",
    "#     # Train model\n",
    "#     history = model.fit(\n",
    "#         X_train_list,  # List of [IMU, thermal, ToF] arrays\n",
    "#         y_train_encoded,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_data=(X_val_list, y_val_encoded),\n",
    "#         callbacks=callbacks,\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     return model, history, le\n",
    "\n",
    "# # Usage example:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create model\n",
    "#     model = create_multimodal_bfrb_model(\n",
    "#         imu_shape=(400, 7),\n",
    "#         thermal_shape=(400, 5),\n",
    "#         tof_shape=(400, 320),\n",
    "#         n_classes=18\n",
    "#     )\n",
    "    \n",
    "#     model.summary()\n",
    "    \n",
    "#     # Prepare your data as lists\n",
    "#     # X_train_list = [X_train_imu, X_train_thermal, X_train_tof]\n",
    "#     # X_val_list = [X_val_imu, X_val_thermal, X_val_tof]\n",
    "    \n",
    "#     # Train model\n",
    "#     # model, history, label_encoder = compile_and_train_model(\n",
    "#     #     model, \n",
    "#     #     X_train_list, y_train,\n",
    "#     #     X_val_list, y_val,\n",
    "#     #     epochs=20,\n",
    "#     #     batch_size=32\n",
    "#     # )\n",
    "\n",
    "# # For handling missing sensors during inference\n",
    "# def create_robust_inference_model(trained_model, handle_missing_sensors=True):\n",
    "#     \"\"\"\n",
    "#     Wrapper for inference that handles missing thermal/ToF data\n",
    "#     \"\"\"\n",
    "#     def predict_with_missing_handling(imu_data, thermal_data=None, tof_data=None):\n",
    "#         # If sensors are missing, fill with zeros\n",
    "#         if thermal_data is None:\n",
    "#             thermal_data = np.zeros((imu_data.shape[0], 400, 5))\n",
    "#         if tof_data is None:\n",
    "#             tof_data = np.zeros((imu_data.shape[0], 400, 320))\n",
    "        \n",
    "#         return trained_model.predict([imu_data, thermal_data, tof_data])\n",
    "    \n",
    "#     return predict_with_missing_handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
