{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('/home/ankur/Desktop/ML_DL_Projects/data/cmi-detect-behavior-with-sensor-data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\n",
    " 'row_id',\n",
    " 'sequence_type',\n",
    " 'subject',\n",
    " 'orientation',\n",
    " 'behavior',\n",
    " 'phase'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequence_id',\n",
       " 'sequence_counter',\n",
       " 'gesture',\n",
       " 'acc_x',\n",
       " 'acc_y',\n",
       " 'acc_z',\n",
       " 'rot_w',\n",
       " 'rot_x',\n",
       " 'rot_y',\n",
       " 'rot_z',\n",
       " 'thm_1',\n",
       " 'thm_2',\n",
       " 'thm_3',\n",
       " 'thm_4',\n",
       " 'thm_5',\n",
       " 'tof_1_v0',\n",
       " 'tof_1_v1',\n",
       " 'tof_1_v2',\n",
       " 'tof_1_v3',\n",
       " 'tof_1_v4',\n",
       " 'tof_1_v5',\n",
       " 'tof_1_v6',\n",
       " 'tof_1_v7',\n",
       " 'tof_1_v8',\n",
       " 'tof_1_v9',\n",
       " 'tof_1_v10',\n",
       " 'tof_1_v11',\n",
       " 'tof_1_v12',\n",
       " 'tof_1_v13',\n",
       " 'tof_1_v14',\n",
       " 'tof_1_v15',\n",
       " 'tof_1_v16',\n",
       " 'tof_1_v17',\n",
       " 'tof_1_v18',\n",
       " 'tof_1_v19',\n",
       " 'tof_1_v20',\n",
       " 'tof_1_v21',\n",
       " 'tof_1_v22',\n",
       " 'tof_1_v23',\n",
       " 'tof_1_v24',\n",
       " 'tof_1_v25',\n",
       " 'tof_1_v26',\n",
       " 'tof_1_v27',\n",
       " 'tof_1_v28',\n",
       " 'tof_1_v29',\n",
       " 'tof_1_v30',\n",
       " 'tof_1_v31',\n",
       " 'tof_1_v32',\n",
       " 'tof_1_v33',\n",
       " 'tof_1_v34',\n",
       " 'tof_1_v35',\n",
       " 'tof_1_v36',\n",
       " 'tof_1_v37',\n",
       " 'tof_1_v38',\n",
       " 'tof_1_v39',\n",
       " 'tof_1_v40',\n",
       " 'tof_1_v41',\n",
       " 'tof_1_v42',\n",
       " 'tof_1_v43',\n",
       " 'tof_1_v44',\n",
       " 'tof_1_v45',\n",
       " 'tof_1_v46',\n",
       " 'tof_1_v47',\n",
       " 'tof_1_v48',\n",
       " 'tof_1_v49',\n",
       " 'tof_1_v50',\n",
       " 'tof_1_v51',\n",
       " 'tof_1_v52',\n",
       " 'tof_1_v53',\n",
       " 'tof_1_v54',\n",
       " 'tof_1_v55',\n",
       " 'tof_1_v56',\n",
       " 'tof_1_v57',\n",
       " 'tof_1_v58',\n",
       " 'tof_1_v59',\n",
       " 'tof_1_v60',\n",
       " 'tof_1_v61',\n",
       " 'tof_1_v62',\n",
       " 'tof_1_v63',\n",
       " 'tof_2_v0',\n",
       " 'tof_2_v1',\n",
       " 'tof_2_v2',\n",
       " 'tof_2_v3',\n",
       " 'tof_2_v4',\n",
       " 'tof_2_v5',\n",
       " 'tof_2_v6',\n",
       " 'tof_2_v7',\n",
       " 'tof_2_v8',\n",
       " 'tof_2_v9',\n",
       " 'tof_2_v10',\n",
       " 'tof_2_v11',\n",
       " 'tof_2_v12',\n",
       " 'tof_2_v13',\n",
       " 'tof_2_v14',\n",
       " 'tof_2_v15',\n",
       " 'tof_2_v16',\n",
       " 'tof_2_v17',\n",
       " 'tof_2_v18',\n",
       " 'tof_2_v19',\n",
       " 'tof_2_v20',\n",
       " 'tof_2_v21',\n",
       " 'tof_2_v22',\n",
       " 'tof_2_v23',\n",
       " 'tof_2_v24',\n",
       " 'tof_2_v25',\n",
       " 'tof_2_v26',\n",
       " 'tof_2_v27',\n",
       " 'tof_2_v28',\n",
       " 'tof_2_v29',\n",
       " 'tof_2_v30',\n",
       " 'tof_2_v31',\n",
       " 'tof_2_v32',\n",
       " 'tof_2_v33',\n",
       " 'tof_2_v34',\n",
       " 'tof_2_v35',\n",
       " 'tof_2_v36',\n",
       " 'tof_2_v37',\n",
       " 'tof_2_v38',\n",
       " 'tof_2_v39',\n",
       " 'tof_2_v40',\n",
       " 'tof_2_v41',\n",
       " 'tof_2_v42',\n",
       " 'tof_2_v43',\n",
       " 'tof_2_v44',\n",
       " 'tof_2_v45',\n",
       " 'tof_2_v46',\n",
       " 'tof_2_v47',\n",
       " 'tof_2_v48',\n",
       " 'tof_2_v49',\n",
       " 'tof_2_v50',\n",
       " 'tof_2_v51',\n",
       " 'tof_2_v52',\n",
       " 'tof_2_v53',\n",
       " 'tof_2_v54',\n",
       " 'tof_2_v55',\n",
       " 'tof_2_v56',\n",
       " 'tof_2_v57',\n",
       " 'tof_2_v58',\n",
       " 'tof_2_v59',\n",
       " 'tof_2_v60',\n",
       " 'tof_2_v61',\n",
       " 'tof_2_v62',\n",
       " 'tof_2_v63',\n",
       " 'tof_3_v0',\n",
       " 'tof_3_v1',\n",
       " 'tof_3_v2',\n",
       " 'tof_3_v3',\n",
       " 'tof_3_v4',\n",
       " 'tof_3_v5',\n",
       " 'tof_3_v6',\n",
       " 'tof_3_v7',\n",
       " 'tof_3_v8',\n",
       " 'tof_3_v9',\n",
       " 'tof_3_v10',\n",
       " 'tof_3_v11',\n",
       " 'tof_3_v12',\n",
       " 'tof_3_v13',\n",
       " 'tof_3_v14',\n",
       " 'tof_3_v15',\n",
       " 'tof_3_v16',\n",
       " 'tof_3_v17',\n",
       " 'tof_3_v18',\n",
       " 'tof_3_v19',\n",
       " 'tof_3_v20',\n",
       " 'tof_3_v21',\n",
       " 'tof_3_v22',\n",
       " 'tof_3_v23',\n",
       " 'tof_3_v24',\n",
       " 'tof_3_v25',\n",
       " 'tof_3_v26',\n",
       " 'tof_3_v27',\n",
       " 'tof_3_v28',\n",
       " 'tof_3_v29',\n",
       " 'tof_3_v30',\n",
       " 'tof_3_v31',\n",
       " 'tof_3_v32',\n",
       " 'tof_3_v33',\n",
       " 'tof_3_v34',\n",
       " 'tof_3_v35',\n",
       " 'tof_3_v36',\n",
       " 'tof_3_v37',\n",
       " 'tof_3_v38',\n",
       " 'tof_3_v39',\n",
       " 'tof_3_v40',\n",
       " 'tof_3_v41',\n",
       " 'tof_3_v42',\n",
       " 'tof_3_v43',\n",
       " 'tof_3_v44',\n",
       " 'tof_3_v45',\n",
       " 'tof_3_v46',\n",
       " 'tof_3_v47',\n",
       " 'tof_3_v48',\n",
       " 'tof_3_v49',\n",
       " 'tof_3_v50',\n",
       " 'tof_3_v51',\n",
       " 'tof_3_v52',\n",
       " 'tof_3_v53',\n",
       " 'tof_3_v54',\n",
       " 'tof_3_v55',\n",
       " 'tof_3_v56',\n",
       " 'tof_3_v57',\n",
       " 'tof_3_v58',\n",
       " 'tof_3_v59',\n",
       " 'tof_3_v60',\n",
       " 'tof_3_v61',\n",
       " 'tof_3_v62',\n",
       " 'tof_3_v63',\n",
       " 'tof_4_v0',\n",
       " 'tof_4_v1',\n",
       " 'tof_4_v2',\n",
       " 'tof_4_v3',\n",
       " 'tof_4_v4',\n",
       " 'tof_4_v5',\n",
       " 'tof_4_v6',\n",
       " 'tof_4_v7',\n",
       " 'tof_4_v8',\n",
       " 'tof_4_v9',\n",
       " 'tof_4_v10',\n",
       " 'tof_4_v11',\n",
       " 'tof_4_v12',\n",
       " 'tof_4_v13',\n",
       " 'tof_4_v14',\n",
       " 'tof_4_v15',\n",
       " 'tof_4_v16',\n",
       " 'tof_4_v17',\n",
       " 'tof_4_v18',\n",
       " 'tof_4_v19',\n",
       " 'tof_4_v20',\n",
       " 'tof_4_v21',\n",
       " 'tof_4_v22',\n",
       " 'tof_4_v23',\n",
       " 'tof_4_v24',\n",
       " 'tof_4_v25',\n",
       " 'tof_4_v26',\n",
       " 'tof_4_v27',\n",
       " 'tof_4_v28',\n",
       " 'tof_4_v29',\n",
       " 'tof_4_v30',\n",
       " 'tof_4_v31',\n",
       " 'tof_4_v32',\n",
       " 'tof_4_v33',\n",
       " 'tof_4_v34',\n",
       " 'tof_4_v35',\n",
       " 'tof_4_v36',\n",
       " 'tof_4_v37',\n",
       " 'tof_4_v38',\n",
       " 'tof_4_v39',\n",
       " 'tof_4_v40',\n",
       " 'tof_4_v41',\n",
       " 'tof_4_v42',\n",
       " 'tof_4_v43',\n",
       " 'tof_4_v44',\n",
       " 'tof_4_v45',\n",
       " 'tof_4_v46',\n",
       " 'tof_4_v47',\n",
       " 'tof_4_v48',\n",
       " 'tof_4_v49',\n",
       " 'tof_4_v50',\n",
       " 'tof_4_v51',\n",
       " 'tof_4_v52',\n",
       " 'tof_4_v53',\n",
       " 'tof_4_v54',\n",
       " 'tof_4_v55',\n",
       " 'tof_4_v56',\n",
       " 'tof_4_v57',\n",
       " 'tof_4_v58',\n",
       " 'tof_4_v59',\n",
       " 'tof_4_v60',\n",
       " 'tof_4_v61',\n",
       " 'tof_4_v62',\n",
       " 'tof_4_v63',\n",
       " 'tof_5_v0',\n",
       " 'tof_5_v1',\n",
       " 'tof_5_v2',\n",
       " 'tof_5_v3',\n",
       " 'tof_5_v4',\n",
       " 'tof_5_v5',\n",
       " 'tof_5_v6',\n",
       " 'tof_5_v7',\n",
       " 'tof_5_v8',\n",
       " 'tof_5_v9',\n",
       " 'tof_5_v10',\n",
       " 'tof_5_v11',\n",
       " 'tof_5_v12',\n",
       " 'tof_5_v13',\n",
       " 'tof_5_v14',\n",
       " 'tof_5_v15',\n",
       " 'tof_5_v16',\n",
       " 'tof_5_v17',\n",
       " 'tof_5_v18',\n",
       " 'tof_5_v19',\n",
       " 'tof_5_v20',\n",
       " 'tof_5_v21',\n",
       " 'tof_5_v22',\n",
       " 'tof_5_v23',\n",
       " 'tof_5_v24',\n",
       " 'tof_5_v25',\n",
       " 'tof_5_v26',\n",
       " 'tof_5_v27',\n",
       " 'tof_5_v28',\n",
       " 'tof_5_v29',\n",
       " 'tof_5_v30',\n",
       " 'tof_5_v31',\n",
       " 'tof_5_v32',\n",
       " 'tof_5_v33',\n",
       " 'tof_5_v34',\n",
       " 'tof_5_v35',\n",
       " 'tof_5_v36',\n",
       " 'tof_5_v37',\n",
       " 'tof_5_v38',\n",
       " 'tof_5_v39',\n",
       " 'tof_5_v40',\n",
       " 'tof_5_v41',\n",
       " 'tof_5_v42',\n",
       " 'tof_5_v43',\n",
       " 'tof_5_v44',\n",
       " 'tof_5_v45',\n",
       " 'tof_5_v46',\n",
       " 'tof_5_v47',\n",
       " 'tof_5_v48',\n",
       " 'tof_5_v49',\n",
       " 'tof_5_v50',\n",
       " 'tof_5_v51',\n",
       " 'tof_5_v52',\n",
       " 'tof_5_v53',\n",
       " 'tof_5_v54',\n",
       " 'tof_5_v55',\n",
       " 'tof_5_v56',\n",
       " 'tof_5_v57',\n",
       " 'tof_5_v58',\n",
       " 'tof_5_v59',\n",
       " 'tof_5_v60',\n",
       " 'tof_5_v61',\n",
       " 'tof_5_v62',\n",
       " 'tof_5_v63']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X with NaNs Before:\n",
      " ['rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n",
      "Columns in X with NaNs After:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "nan_columns_X = df_train.columns[df_train.isnull().any()].tolist()\n",
    "print(\"Columns in X with NaNs Before:\\n\", nan_columns_X)\n",
    "df_train = df_train.infer_objects(copy=False)\n",
    "df_train[df_train.select_dtypes(include=[\"number\"]).columns] = df_train.select_dtypes(include=[\"number\"]).interpolate(method=\"linear\", axis=0)\n",
    "nan_columns_X = df_train.columns[df_train.isnull().any()].tolist()\n",
    "print(\"Columns in X with NaNs After:\\n\", nan_columns_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drink from bottle/cup',\n",
       " 'Feel around in tray and pull out an object',\n",
       " 'Glasses on/off',\n",
       " 'Pinch knee/leg skin',\n",
       " 'Pull air toward your face',\n",
       " 'Scratch knee/leg skin',\n",
       " 'Text on phone',\n",
       " 'Wave hello',\n",
       " 'Write name in air',\n",
       " 'Write name on leg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "all_classes = np.load(\"imu_18_classes.npy\",allow_pickle=True)\n",
    "target_classes = [\n",
    "    'Above ear - pull hair',\n",
    "    'Forehead - pull hairline',\n",
    "    'Forehead - scratch',\n",
    "    'Eyebrow - pull hair',\n",
    "    'Eyelash - pull hair',\n",
    "    'Neck - pinch skin',\n",
    "    'Neck - scratch',\n",
    "    'Cheek - pinch skin'\n",
    "]\n",
    "non_target_classes = [cls  for cls in all_classes if cls not in target_classes]\n",
    "non_target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260583/904726353.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[\"gesture_class\"] = df_train[\"gesture\"].map(class_map).fillna(8).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gesture_class\n",
       "8    230887\n",
       "6     56619\n",
       "3     44305\n",
       "2     40923\n",
       "1     40802\n",
       "0     40560\n",
       "5     40507\n",
       "4     40218\n",
       "7     40124\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map = {cls: i for i, cls in enumerate(target_classes)}\n",
    "df_train[\"gesture_class\"] = df_train[\"gesture\"].map(class_map).fillna(8).astype(int)\n",
    "\n",
    "df_train['gesture_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260583/37775045.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[\"acc_magnitude\"] = np.sqrt(df_train[\"acc_x\"]**2 + df_train[\"acc_y\"]**2 + df_train[\"acc_z\"]**2)\n"
     ]
    }
   ],
   "source": [
    "df_train[\"acc_magnitude\"] = np.sqrt(df_train[\"acc_x\"]**2 + df_train[\"acc_y\"]**2 + df_train[\"acc_z\"]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "                    ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "df_train[\"jerk_x\"] = df_train[\"acc_x\"].diff()   # difference between consecutive values\n",
    "df_train[\"jerk_y\"] = df_train[\"acc_y\"].diff()\n",
    "df_train[\"jerk_z\"] = df_train[\"acc_z\"].diff()\n",
    "\n",
    "# magnitude of jerk\n",
    "df_train[\"jerk_magnitude\"] = np.sqrt(df_train[\"jerk_x\"]**2 + df_train[\"jerk_y\"]**2 + df_train[\"jerk_z\"]**2)\n",
    "\n",
    "# fill NaN from diff() with 0\n",
    "df_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequence_id',\n",
       " 'sequence_counter',\n",
       " 'gesture',\n",
       " 'acc_x',\n",
       " 'acc_y',\n",
       " 'acc_z',\n",
       " 'rot_w',\n",
       " 'rot_x',\n",
       " 'rot_y',\n",
       " 'rot_z',\n",
       " 'thm_1',\n",
       " 'thm_2',\n",
       " 'thm_3',\n",
       " 'thm_4',\n",
       " 'thm_5',\n",
       " 'tof_1_v0',\n",
       " 'tof_1_v1',\n",
       " 'tof_1_v2',\n",
       " 'tof_1_v3',\n",
       " 'tof_1_v4',\n",
       " 'tof_1_v5',\n",
       " 'tof_1_v6',\n",
       " 'tof_1_v7',\n",
       " 'tof_1_v8',\n",
       " 'tof_1_v9',\n",
       " 'tof_1_v10',\n",
       " 'tof_1_v11',\n",
       " 'tof_1_v12',\n",
       " 'tof_1_v13',\n",
       " 'tof_1_v14',\n",
       " 'tof_1_v15',\n",
       " 'tof_1_v16',\n",
       " 'tof_1_v17',\n",
       " 'tof_1_v18',\n",
       " 'tof_1_v19',\n",
       " 'tof_1_v20',\n",
       " 'tof_1_v21',\n",
       " 'tof_1_v22',\n",
       " 'tof_1_v23',\n",
       " 'tof_1_v24',\n",
       " 'tof_1_v25',\n",
       " 'tof_1_v26',\n",
       " 'tof_1_v27',\n",
       " 'tof_1_v28',\n",
       " 'tof_1_v29',\n",
       " 'tof_1_v30',\n",
       " 'tof_1_v31',\n",
       " 'tof_1_v32',\n",
       " 'tof_1_v33',\n",
       " 'tof_1_v34',\n",
       " 'tof_1_v35',\n",
       " 'tof_1_v36',\n",
       " 'tof_1_v37',\n",
       " 'tof_1_v38',\n",
       " 'tof_1_v39',\n",
       " 'tof_1_v40',\n",
       " 'tof_1_v41',\n",
       " 'tof_1_v42',\n",
       " 'tof_1_v43',\n",
       " 'tof_1_v44',\n",
       " 'tof_1_v45',\n",
       " 'tof_1_v46',\n",
       " 'tof_1_v47',\n",
       " 'tof_1_v48',\n",
       " 'tof_1_v49',\n",
       " 'tof_1_v50',\n",
       " 'tof_1_v51',\n",
       " 'tof_1_v52',\n",
       " 'tof_1_v53',\n",
       " 'tof_1_v54',\n",
       " 'tof_1_v55',\n",
       " 'tof_1_v56',\n",
       " 'tof_1_v57',\n",
       " 'tof_1_v58',\n",
       " 'tof_1_v59',\n",
       " 'tof_1_v60',\n",
       " 'tof_1_v61',\n",
       " 'tof_1_v62',\n",
       " 'tof_1_v63',\n",
       " 'tof_2_v0',\n",
       " 'tof_2_v1',\n",
       " 'tof_2_v2',\n",
       " 'tof_2_v3',\n",
       " 'tof_2_v4',\n",
       " 'tof_2_v5',\n",
       " 'tof_2_v6',\n",
       " 'tof_2_v7',\n",
       " 'tof_2_v8',\n",
       " 'tof_2_v9',\n",
       " 'tof_2_v10',\n",
       " 'tof_2_v11',\n",
       " 'tof_2_v12',\n",
       " 'tof_2_v13',\n",
       " 'tof_2_v14',\n",
       " 'tof_2_v15',\n",
       " 'tof_2_v16',\n",
       " 'tof_2_v17',\n",
       " 'tof_2_v18',\n",
       " 'tof_2_v19',\n",
       " 'tof_2_v20',\n",
       " 'tof_2_v21',\n",
       " 'tof_2_v22',\n",
       " 'tof_2_v23',\n",
       " 'tof_2_v24',\n",
       " 'tof_2_v25',\n",
       " 'tof_2_v26',\n",
       " 'tof_2_v27',\n",
       " 'tof_2_v28',\n",
       " 'tof_2_v29',\n",
       " 'tof_2_v30',\n",
       " 'tof_2_v31',\n",
       " 'tof_2_v32',\n",
       " 'tof_2_v33',\n",
       " 'tof_2_v34',\n",
       " 'tof_2_v35',\n",
       " 'tof_2_v36',\n",
       " 'tof_2_v37',\n",
       " 'tof_2_v38',\n",
       " 'tof_2_v39',\n",
       " 'tof_2_v40',\n",
       " 'tof_2_v41',\n",
       " 'tof_2_v42',\n",
       " 'tof_2_v43',\n",
       " 'tof_2_v44',\n",
       " 'tof_2_v45',\n",
       " 'tof_2_v46',\n",
       " 'tof_2_v47',\n",
       " 'tof_2_v48',\n",
       " 'tof_2_v49',\n",
       " 'tof_2_v50',\n",
       " 'tof_2_v51',\n",
       " 'tof_2_v52',\n",
       " 'tof_2_v53',\n",
       " 'tof_2_v54',\n",
       " 'tof_2_v55',\n",
       " 'tof_2_v56',\n",
       " 'tof_2_v57',\n",
       " 'tof_2_v58',\n",
       " 'tof_2_v59',\n",
       " 'tof_2_v60',\n",
       " 'tof_2_v61',\n",
       " 'tof_2_v62',\n",
       " 'tof_2_v63',\n",
       " 'tof_3_v0',\n",
       " 'tof_3_v1',\n",
       " 'tof_3_v2',\n",
       " 'tof_3_v3',\n",
       " 'tof_3_v4',\n",
       " 'tof_3_v5',\n",
       " 'tof_3_v6',\n",
       " 'tof_3_v7',\n",
       " 'tof_3_v8',\n",
       " 'tof_3_v9',\n",
       " 'tof_3_v10',\n",
       " 'tof_3_v11',\n",
       " 'tof_3_v12',\n",
       " 'tof_3_v13',\n",
       " 'tof_3_v14',\n",
       " 'tof_3_v15',\n",
       " 'tof_3_v16',\n",
       " 'tof_3_v17',\n",
       " 'tof_3_v18',\n",
       " 'tof_3_v19',\n",
       " 'tof_3_v20',\n",
       " 'tof_3_v21',\n",
       " 'tof_3_v22',\n",
       " 'tof_3_v23',\n",
       " 'tof_3_v24',\n",
       " 'tof_3_v25',\n",
       " 'tof_3_v26',\n",
       " 'tof_3_v27',\n",
       " 'tof_3_v28',\n",
       " 'tof_3_v29',\n",
       " 'tof_3_v30',\n",
       " 'tof_3_v31',\n",
       " 'tof_3_v32',\n",
       " 'tof_3_v33',\n",
       " 'tof_3_v34',\n",
       " 'tof_3_v35',\n",
       " 'tof_3_v36',\n",
       " 'tof_3_v37',\n",
       " 'tof_3_v38',\n",
       " 'tof_3_v39',\n",
       " 'tof_3_v40',\n",
       " 'tof_3_v41',\n",
       " 'tof_3_v42',\n",
       " 'tof_3_v43',\n",
       " 'tof_3_v44',\n",
       " 'tof_3_v45',\n",
       " 'tof_3_v46',\n",
       " 'tof_3_v47',\n",
       " 'tof_3_v48',\n",
       " 'tof_3_v49',\n",
       " 'tof_3_v50',\n",
       " 'tof_3_v51',\n",
       " 'tof_3_v52',\n",
       " 'tof_3_v53',\n",
       " 'tof_3_v54',\n",
       " 'tof_3_v55',\n",
       " 'tof_3_v56',\n",
       " 'tof_3_v57',\n",
       " 'tof_3_v58',\n",
       " 'tof_3_v59',\n",
       " 'tof_3_v60',\n",
       " 'tof_3_v61',\n",
       " 'tof_3_v62',\n",
       " 'tof_3_v63',\n",
       " 'tof_4_v0',\n",
       " 'tof_4_v1',\n",
       " 'tof_4_v2',\n",
       " 'tof_4_v3',\n",
       " 'tof_4_v4',\n",
       " 'tof_4_v5',\n",
       " 'tof_4_v6',\n",
       " 'tof_4_v7',\n",
       " 'tof_4_v8',\n",
       " 'tof_4_v9',\n",
       " 'tof_4_v10',\n",
       " 'tof_4_v11',\n",
       " 'tof_4_v12',\n",
       " 'tof_4_v13',\n",
       " 'tof_4_v14',\n",
       " 'tof_4_v15',\n",
       " 'tof_4_v16',\n",
       " 'tof_4_v17',\n",
       " 'tof_4_v18',\n",
       " 'tof_4_v19',\n",
       " 'tof_4_v20',\n",
       " 'tof_4_v21',\n",
       " 'tof_4_v22',\n",
       " 'tof_4_v23',\n",
       " 'tof_4_v24',\n",
       " 'tof_4_v25',\n",
       " 'tof_4_v26',\n",
       " 'tof_4_v27',\n",
       " 'tof_4_v28',\n",
       " 'tof_4_v29',\n",
       " 'tof_4_v30',\n",
       " 'tof_4_v31',\n",
       " 'tof_4_v32',\n",
       " 'tof_4_v33',\n",
       " 'tof_4_v34',\n",
       " 'tof_4_v35',\n",
       " 'tof_4_v36',\n",
       " 'tof_4_v37',\n",
       " 'tof_4_v38',\n",
       " 'tof_4_v39',\n",
       " 'tof_4_v40',\n",
       " 'tof_4_v41',\n",
       " 'tof_4_v42',\n",
       " 'tof_4_v43',\n",
       " 'tof_4_v44',\n",
       " 'tof_4_v45',\n",
       " 'tof_4_v46',\n",
       " 'tof_4_v47',\n",
       " 'tof_4_v48',\n",
       " 'tof_4_v49',\n",
       " 'tof_4_v50',\n",
       " 'tof_4_v51',\n",
       " 'tof_4_v52',\n",
       " 'tof_4_v53',\n",
       " 'tof_4_v54',\n",
       " 'tof_4_v55',\n",
       " 'tof_4_v56',\n",
       " 'tof_4_v57',\n",
       " 'tof_4_v58',\n",
       " 'tof_4_v59',\n",
       " 'tof_4_v60',\n",
       " 'tof_4_v61',\n",
       " 'tof_4_v62',\n",
       " 'tof_4_v63',\n",
       " 'tof_5_v0',\n",
       " 'tof_5_v1',\n",
       " 'tof_5_v2',\n",
       " 'tof_5_v3',\n",
       " 'tof_5_v4',\n",
       " 'tof_5_v5',\n",
       " 'tof_5_v6',\n",
       " 'tof_5_v7',\n",
       " 'tof_5_v8',\n",
       " 'tof_5_v9',\n",
       " 'tof_5_v10',\n",
       " 'tof_5_v11',\n",
       " 'tof_5_v12',\n",
       " 'tof_5_v13',\n",
       " 'tof_5_v14',\n",
       " 'tof_5_v15',\n",
       " 'tof_5_v16',\n",
       " 'tof_5_v17',\n",
       " 'tof_5_v18',\n",
       " 'tof_5_v19',\n",
       " 'tof_5_v20',\n",
       " 'tof_5_v21',\n",
       " 'tof_5_v22',\n",
       " 'tof_5_v23',\n",
       " 'tof_5_v24',\n",
       " 'tof_5_v25',\n",
       " 'tof_5_v26',\n",
       " 'tof_5_v27',\n",
       " 'tof_5_v28',\n",
       " 'tof_5_v29',\n",
       " 'tof_5_v30',\n",
       " 'tof_5_v31',\n",
       " 'tof_5_v32',\n",
       " 'tof_5_v33',\n",
       " 'tof_5_v34',\n",
       " 'tof_5_v35',\n",
       " 'tof_5_v36',\n",
       " 'tof_5_v37',\n",
       " 'tof_5_v38',\n",
       " 'tof_5_v39',\n",
       " 'tof_5_v40',\n",
       " 'tof_5_v41',\n",
       " 'tof_5_v42',\n",
       " 'tof_5_v43',\n",
       " 'tof_5_v44',\n",
       " 'tof_5_v45',\n",
       " 'tof_5_v46',\n",
       " 'tof_5_v47',\n",
       " 'tof_5_v48',\n",
       " 'tof_5_v49',\n",
       " 'tof_5_v50',\n",
       " 'tof_5_v51',\n",
       " 'tof_5_v52',\n",
       " 'tof_5_v53',\n",
       " 'tof_5_v54',\n",
       " 'tof_5_v55',\n",
       " 'tof_5_v56',\n",
       " 'tof_5_v57',\n",
       " 'tof_5_v58',\n",
       " 'tof_5_v59',\n",
       " 'tof_5_v60',\n",
       " 'tof_5_v61',\n",
       " 'tof_5_v62',\n",
       " 'tof_5_v63',\n",
       " 'gesture_class',\n",
       " 'acc_magnitude',\n",
       " 'jerk_x',\n",
       " 'jerk_y',\n",
       " 'jerk_z',\n",
       " 'jerk_magnitude']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_features =  [\n",
    " 'acc_x',\n",
    " 'acc_y',\n",
    " 'acc_z',\n",
    " 'rot_w',\n",
    " 'rot_x',\n",
    " 'rot_y',\n",
    " 'rot_z',\n",
    " 'acc_magnitude',\n",
    " 'jerk_x',\n",
    " 'jerk_y',\n",
    " 'jerk_z',\n",
    " 'jerk_magnitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    " 'acc_x',\n",
    " 'acc_y',\n",
    " 'acc_z',\n",
    " 'rot_w',\n",
    " 'rot_x',\n",
    " 'rot_y',\n",
    " 'rot_z',\n",
    " 'thm_1',\n",
    " 'thm_2',\n",
    " 'thm_3',\n",
    " 'thm_4',\n",
    " 'thm_5',\n",
    " 'tof_1_v0',\n",
    " 'tof_1_v1',\n",
    " 'tof_1_v2',\n",
    " 'tof_1_v3',\n",
    " 'tof_1_v4',\n",
    " 'tof_1_v5',\n",
    " 'tof_1_v6',\n",
    " 'tof_1_v7',\n",
    " 'tof_1_v8',\n",
    " 'tof_1_v9',\n",
    " 'tof_1_v10',\n",
    " 'tof_1_v11',\n",
    " 'tof_1_v12',\n",
    " 'tof_1_v13',\n",
    " 'tof_1_v14',\n",
    " 'tof_1_v15',\n",
    " 'tof_1_v16',\n",
    " 'tof_1_v17',\n",
    " 'tof_1_v18',\n",
    " 'tof_1_v19',\n",
    " 'tof_1_v20',\n",
    " 'tof_1_v21',\n",
    " 'tof_1_v22',\n",
    " 'tof_1_v23',\n",
    " 'tof_1_v24',\n",
    " 'tof_1_v25',\n",
    " 'tof_1_v26',\n",
    " 'tof_1_v27',\n",
    " 'tof_1_v28',\n",
    " 'tof_1_v29',\n",
    " 'tof_1_v30',\n",
    " 'tof_1_v31',\n",
    " 'tof_1_v32',\n",
    " 'tof_1_v33',\n",
    " 'tof_1_v34',\n",
    " 'tof_1_v35',\n",
    " 'tof_1_v36',\n",
    " 'tof_1_v37',\n",
    " 'tof_1_v38',\n",
    " 'tof_1_v39',\n",
    " 'tof_1_v40',\n",
    " 'tof_1_v41',\n",
    " 'tof_1_v42',\n",
    " 'tof_1_v43',\n",
    " 'tof_1_v44',\n",
    " 'tof_1_v45',\n",
    " 'tof_1_v46',\n",
    " 'tof_1_v47',\n",
    " 'tof_1_v48',\n",
    " 'tof_1_v49',\n",
    " 'tof_1_v50',\n",
    " 'tof_1_v51',\n",
    " 'tof_1_v52',\n",
    " 'tof_1_v53',\n",
    " 'tof_1_v54',\n",
    " 'tof_1_v55',\n",
    " 'tof_1_v56',\n",
    " 'tof_1_v57',\n",
    " 'tof_1_v58',\n",
    " 'tof_1_v59',\n",
    " 'tof_1_v60',\n",
    " 'tof_1_v61',\n",
    " 'tof_1_v62',\n",
    " 'tof_1_v63',\n",
    " 'tof_2_v0',\n",
    " 'tof_2_v1',\n",
    " 'tof_2_v2',\n",
    " 'tof_2_v3',\n",
    " 'tof_2_v4',\n",
    " 'tof_2_v5',\n",
    " 'tof_2_v6',\n",
    " 'tof_2_v7',\n",
    " 'tof_2_v8',\n",
    " 'tof_2_v9',\n",
    " 'tof_2_v10',\n",
    " 'tof_2_v11',\n",
    " 'tof_2_v12',\n",
    " 'tof_2_v13',\n",
    " 'tof_2_v14',\n",
    " 'tof_2_v15',\n",
    " 'tof_2_v16',\n",
    " 'tof_2_v17',\n",
    " 'tof_2_v18',\n",
    " 'tof_2_v19',\n",
    " 'tof_2_v20',\n",
    " 'tof_2_v21',\n",
    " 'tof_2_v22',\n",
    " 'tof_2_v23',\n",
    " 'tof_2_v24',\n",
    " 'tof_2_v25',\n",
    " 'tof_2_v26',\n",
    " 'tof_2_v27',\n",
    " 'tof_2_v28',\n",
    " 'tof_2_v29',\n",
    " 'tof_2_v30',\n",
    " 'tof_2_v31',\n",
    " 'tof_2_v32',\n",
    " 'tof_2_v33',\n",
    " 'tof_2_v34',\n",
    " 'tof_2_v35',\n",
    " 'tof_2_v36',\n",
    " 'tof_2_v37',\n",
    " 'tof_2_v38',\n",
    " 'tof_2_v39',\n",
    " 'tof_2_v40',\n",
    " 'tof_2_v41',\n",
    " 'tof_2_v42',\n",
    " 'tof_2_v43',\n",
    " 'tof_2_v44',\n",
    " 'tof_2_v45',\n",
    " 'tof_2_v46',\n",
    " 'tof_2_v47',\n",
    " 'tof_2_v48',\n",
    " 'tof_2_v49',\n",
    " 'tof_2_v50',\n",
    " 'tof_2_v51',\n",
    " 'tof_2_v52',\n",
    " 'tof_2_v53',\n",
    " 'tof_2_v54',\n",
    " 'tof_2_v55',\n",
    " 'tof_2_v56',\n",
    " 'tof_2_v57',\n",
    " 'tof_2_v58',\n",
    " 'tof_2_v59',\n",
    " 'tof_2_v60',\n",
    " 'tof_2_v61',\n",
    " 'tof_2_v62',\n",
    " 'tof_2_v63',\n",
    " 'tof_3_v0',\n",
    " 'tof_3_v1',\n",
    " 'tof_3_v2',\n",
    " 'tof_3_v3',\n",
    " 'tof_3_v4',\n",
    " 'tof_3_v5',\n",
    " 'tof_3_v6',\n",
    " 'tof_3_v7',\n",
    " 'tof_3_v8',\n",
    " 'tof_3_v9',\n",
    " 'tof_3_v10',\n",
    " 'tof_3_v11',\n",
    " 'tof_3_v12',\n",
    " 'tof_3_v13',\n",
    " 'tof_3_v14',\n",
    " 'tof_3_v15',\n",
    " 'tof_3_v16',\n",
    " 'tof_3_v17',\n",
    " 'tof_3_v18',\n",
    " 'tof_3_v19',\n",
    " 'tof_3_v20',\n",
    " 'tof_3_v21',\n",
    " 'tof_3_v22',\n",
    " 'tof_3_v23',\n",
    " 'tof_3_v24',\n",
    " 'tof_3_v25',\n",
    " 'tof_3_v26',\n",
    " 'tof_3_v27',\n",
    " 'tof_3_v28',\n",
    " 'tof_3_v29',\n",
    " 'tof_3_v30',\n",
    " 'tof_3_v31',\n",
    " 'tof_3_v32',\n",
    " 'tof_3_v33',\n",
    " 'tof_3_v34',\n",
    " 'tof_3_v35',\n",
    " 'tof_3_v36',\n",
    " 'tof_3_v37',\n",
    " 'tof_3_v38',\n",
    " 'tof_3_v39',\n",
    " 'tof_3_v40',\n",
    " 'tof_3_v41',\n",
    " 'tof_3_v42',\n",
    " 'tof_3_v43',\n",
    " 'tof_3_v44',\n",
    " 'tof_3_v45',\n",
    " 'tof_3_v46',\n",
    " 'tof_3_v47',\n",
    " 'tof_3_v48',\n",
    " 'tof_3_v49',\n",
    " 'tof_3_v50',\n",
    " 'tof_3_v51',\n",
    " 'tof_3_v52',\n",
    " 'tof_3_v53',\n",
    " 'tof_3_v54',\n",
    " 'tof_3_v55',\n",
    " 'tof_3_v56',\n",
    " 'tof_3_v57',\n",
    " 'tof_3_v58',\n",
    " 'tof_3_v59',\n",
    " 'tof_3_v60',\n",
    " 'tof_3_v61',\n",
    " 'tof_3_v62',\n",
    " 'tof_3_v63',\n",
    " 'tof_4_v0',\n",
    " 'tof_4_v1',\n",
    " 'tof_4_v2',\n",
    " 'tof_4_v3',\n",
    " 'tof_4_v4',\n",
    " 'tof_4_v5',\n",
    " 'tof_4_v6',\n",
    " 'tof_4_v7',\n",
    " 'tof_4_v8',\n",
    " 'tof_4_v9',\n",
    " 'tof_4_v10',\n",
    " 'tof_4_v11',\n",
    " 'tof_4_v12',\n",
    " 'tof_4_v13',\n",
    " 'tof_4_v14',\n",
    " 'tof_4_v15',\n",
    " 'tof_4_v16',\n",
    " 'tof_4_v17',\n",
    " 'tof_4_v18',\n",
    " 'tof_4_v19',\n",
    " 'tof_4_v20',\n",
    " 'tof_4_v21',\n",
    " 'tof_4_v22',\n",
    " 'tof_4_v23',\n",
    " 'tof_4_v24',\n",
    " 'tof_4_v25',\n",
    " 'tof_4_v26',\n",
    " 'tof_4_v27',\n",
    " 'tof_4_v28',\n",
    " 'tof_4_v29',\n",
    " 'tof_4_v30',\n",
    " 'tof_4_v31',\n",
    " 'tof_4_v32',\n",
    " 'tof_4_v33',\n",
    " 'tof_4_v34',\n",
    " 'tof_4_v35',\n",
    " 'tof_4_v36',\n",
    " 'tof_4_v37',\n",
    " 'tof_4_v38',\n",
    " 'tof_4_v39',\n",
    " 'tof_4_v40',\n",
    " 'tof_4_v41',\n",
    " 'tof_4_v42',\n",
    " 'tof_4_v43',\n",
    " 'tof_4_v44',\n",
    " 'tof_4_v45',\n",
    " 'tof_4_v46',\n",
    " 'tof_4_v47',\n",
    " 'tof_4_v48',\n",
    " 'tof_4_v49',\n",
    " 'tof_4_v50',\n",
    " 'tof_4_v51',\n",
    " 'tof_4_v52',\n",
    " 'tof_4_v53',\n",
    " 'tof_4_v54',\n",
    " 'tof_4_v55',\n",
    " 'tof_4_v56',\n",
    " 'tof_4_v57',\n",
    " 'tof_4_v58',\n",
    " 'tof_4_v59',\n",
    " 'tof_4_v60',\n",
    " 'tof_4_v61',\n",
    " 'tof_4_v62',\n",
    " 'tof_4_v63',\n",
    " 'tof_5_v0',\n",
    " 'tof_5_v1',\n",
    " 'tof_5_v2',\n",
    " 'tof_5_v3',\n",
    " 'tof_5_v4',\n",
    " 'tof_5_v5',\n",
    " 'tof_5_v6',\n",
    " 'tof_5_v7',\n",
    " 'tof_5_v8',\n",
    " 'tof_5_v9',\n",
    " 'tof_5_v10',\n",
    " 'tof_5_v11',\n",
    " 'tof_5_v12',\n",
    " 'tof_5_v13',\n",
    " 'tof_5_v14',\n",
    " 'tof_5_v15',\n",
    " 'tof_5_v16',\n",
    " 'tof_5_v17',\n",
    " 'tof_5_v18',\n",
    " 'tof_5_v19',\n",
    " 'tof_5_v20',\n",
    " 'tof_5_v21',\n",
    " 'tof_5_v22',\n",
    " 'tof_5_v23',\n",
    " 'tof_5_v24',\n",
    " 'tof_5_v25',\n",
    " 'tof_5_v26',\n",
    " 'tof_5_v27',\n",
    " 'tof_5_v28',\n",
    " 'tof_5_v29',\n",
    " 'tof_5_v30',\n",
    " 'tof_5_v31',\n",
    " 'tof_5_v32',\n",
    " 'tof_5_v33',\n",
    " 'tof_5_v34',\n",
    " 'tof_5_v35',\n",
    " 'tof_5_v36',\n",
    " 'tof_5_v37',\n",
    " 'tof_5_v38',\n",
    " 'tof_5_v39',\n",
    " 'tof_5_v40',\n",
    " 'tof_5_v41',\n",
    " 'tof_5_v42',\n",
    " 'tof_5_v43',\n",
    " 'tof_5_v44',\n",
    " 'tof_5_v45',\n",
    " 'tof_5_v46',\n",
    " 'tof_5_v47',\n",
    " 'tof_5_v48',\n",
    " 'tof_5_v49',\n",
    " 'tof_5_v50',\n",
    " 'tof_5_v51',\n",
    " 'tof_5_v52',\n",
    " 'tof_5_v53',\n",
    " 'tof_5_v54',\n",
    " 'tof_5_v55',\n",
    " 'tof_5_v56',\n",
    " 'tof_5_v57',\n",
    " 'tof_5_v58',\n",
    " 'tof_5_v59',\n",
    " 'tof_5_v60',\n",
    " 'tof_5_v61',\n",
    " 'tof_5_v62',\n",
    " 'tof_5_v63',\n",
    " 'acc_magnitude',\n",
    " 'jerk_x',\n",
    " 'jerk_y',\n",
    " 'jerk_z',\n",
    " 'jerk_magnitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sensor = df_train[['sequence_id','sequence_counter'] + all_features + ['gesture_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574945, 340)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_whole_sequences(df,columns,max_steps=400):\n",
    "    \n",
    "    df = df.sort_values(by=[\"sequence_id\", \"sequence_counter\"], \n",
    "                    ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "    # Drop unnecessary columns early\n",
    "    df = df.drop(columns=[\"sequence_counter\"])  \n",
    "    \n",
    "    n_features = len(columns)\n",
    "\n",
    "    \n",
    "    # Find number of unique sequences\n",
    "    sequence_ids = df[\"sequence_id\"].unique()\n",
    "    n_sequences = len(sequence_ids)\n",
    "\n",
    "    # Preallocate final arrays\n",
    "    X = np.zeros((n_sequences, max_steps, n_features), dtype=np.float32)\n",
    "    Y = np.zeros((n_sequences,), dtype=np.float32)  \n",
    "    for i, seq_id in enumerate(sequence_ids):\n",
    "        if i % 100 ==0:\n",
    "            print(f\"Processing {i}/{n_sequences}\")\n",
    "\n",
    "        #imu\n",
    "        seq = df[df[\"sequence_id\"] == seq_id][columns].values.astype(np.float32)\n",
    "        seq_len = len(seq)\n",
    "        if seq_len > max_steps:\n",
    "            seq = seq[-max_steps:]\n",
    "        X[i, :seq_len, :] = seq\n",
    "\n",
    "        label_row = df[df[\"sequence_id\"] == seq_id]['gesture_class'].iloc[0]\n",
    "        Y[i] = label_row\n",
    "    \n",
    "    return X ,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/8151\n",
      "Processing 100/8151\n",
      "Processing 200/8151\n",
      "Processing 300/8151\n",
      "Processing 400/8151\n",
      "Processing 500/8151\n",
      "Processing 600/8151\n",
      "Processing 700/8151\n",
      "Processing 800/8151\n",
      "Processing 900/8151\n",
      "Processing 1000/8151\n",
      "Processing 1100/8151\n",
      "Processing 1200/8151\n",
      "Processing 1300/8151\n",
      "Processing 1400/8151\n",
      "Processing 1500/8151\n",
      "Processing 1600/8151\n",
      "Processing 1700/8151\n",
      "Processing 1800/8151\n",
      "Processing 1900/8151\n",
      "Processing 2000/8151\n",
      "Processing 2100/8151\n",
      "Processing 2200/8151\n",
      "Processing 2300/8151\n",
      "Processing 2400/8151\n",
      "Processing 2500/8151\n",
      "Processing 2600/8151\n",
      "Processing 2700/8151\n",
      "Processing 2800/8151\n",
      "Processing 2900/8151\n",
      "Processing 3000/8151\n",
      "Processing 3100/8151\n",
      "Processing 3200/8151\n",
      "Processing 3300/8151\n",
      "Processing 3400/8151\n",
      "Processing 3500/8151\n",
      "Processing 3600/8151\n",
      "Processing 3700/8151\n",
      "Processing 3800/8151\n",
      "Processing 3900/8151\n",
      "Processing 4000/8151\n",
      "Processing 4100/8151\n",
      "Processing 4200/8151\n",
      "Processing 4300/8151\n",
      "Processing 4400/8151\n",
      "Processing 4500/8151\n",
      "Processing 4600/8151\n",
      "Processing 4700/8151\n",
      "Processing 4800/8151\n",
      "Processing 4900/8151\n",
      "Processing 5000/8151\n",
      "Processing 5100/8151\n",
      "Processing 5200/8151\n",
      "Processing 5300/8151\n",
      "Processing 5400/8151\n",
      "Processing 5500/8151\n",
      "Processing 5600/8151\n",
      "Processing 5700/8151\n",
      "Processing 5800/8151\n",
      "Processing 5900/8151\n",
      "Processing 6000/8151\n",
      "Processing 6100/8151\n",
      "Processing 6200/8151\n",
      "Processing 6300/8151\n",
      "Processing 6400/8151\n",
      "Processing 6500/8151\n",
      "Processing 6600/8151\n",
      "Processing 6700/8151\n",
      "Processing 6800/8151\n",
      "Processing 6900/8151\n",
      "Processing 7000/8151\n",
      "Processing 7100/8151\n",
      "Processing 7200/8151\n",
      "Processing 7300/8151\n",
      "Processing 7400/8151\n",
      "Processing 7500/8151\n",
      "Processing 7600/8151\n",
      "Processing 7700/8151\n",
      "Processing 7800/8151\n",
      "Processing 7900/8151\n",
      "Processing 8000/8151\n",
      "Processing 8100/8151\n"
     ]
    }
   ],
   "source": [
    "X_all_sensor,Y = prepare_whole_sequences(df_all_sensor,all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_all_sensor\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# stratified split train+temp vs test\n",
    "X_train_all, X_val_all, y_train_all, y_val_all = train_test_split(\n",
    "    X_all_sensor, Y, test_size=0.1, stratify=Y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7335, 400, 337), (816, 400, 337), (7335,), (816,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.shape, X_val_all.shape, y_train_all.shape, y_val_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del X_all_sensor\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 22:03:25.930096: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-01 22:03:25.930348: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-01 22:03:25.957487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-01 22:03:27.041586: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-01 22:03:27.042002: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization,\n",
    "    GlobalAveragePooling1D, Attention, LayerNormalization,\n",
    "    Masking, Concatenate, MultiHeadAttention\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "\n",
    "\n",
    "\n",
    "def create_single_task_model(\n",
    "    max_len=400,\n",
    "    n_features=337,\n",
    "    n_classes=9\n",
    "):\n",
    "    \"\"\"\n",
    "    Single-task version of the model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(max_len, n_features))\n",
    "    x = Masking(mask_value=0.0)(input_layer)\n",
    "    \n",
    "    # Conv1D blocks\n",
    "    x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(x)\n",
    "    x = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(x)\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    attention_output = MultiHeadAttention(num_heads=8, key_dim=64)(x, x)\n",
    "    x = tf.keras.layers.Add()([x, attention_output])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Global pooling and dense layers\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "\n",
    "    output = Dense(n_classes, activation='softmax', name='gesture_output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "  # # Compile model\n",
    "    model.compile(\n",
    "     optimizer='adam',\n",
    "     loss=SparseCategoricalCrossentropy(),   \n",
    "     metrics=[\n",
    "        'accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 22:04:02.281756: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-09-01 22:04:02.281800: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-09-01 22:04:02.281804: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: ankur-Legion-5-15IRX9\n",
      "2025-09-01 22:04:02.281807: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: ankur-Legion-5-15IRX9\n",
      "2025-09-01 22:04:02.282015: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 575.64.3\n",
      "2025-09-01 22:04:02.282024: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 575.64.3\n",
      "2025-09-01 22:04:02.282025: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 575.64.3\n",
      "/home/ankur/Desktop/ML_DL_Projects/ml_env/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">337</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">337</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,768</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m337\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m337\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m64,768\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m24,704\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m24,640\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │    \u001b[38;5;34m132,672\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │        \u001b[38;5;34m585\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">463,113</span> (1.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m463,113\u001b[0m (1.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,345</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,345\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">337</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">337</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,768</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,672</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m337\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m337\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m64,768\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m24,704\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m49,280\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m24,640\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m49,408\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │    \u001b[38;5;34m132,672\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gesture_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │        \u001b[38;5;34m585\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">463,113</span> (1.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m463,113\u001b[0m (1.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,345</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,345\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_sensor_model = create_single_task_model()\n",
    "all_sensor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/Desktop/ML_DL_Projects/ml_env/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 695ms/step - accuracy: 0.3746 - loss: 1.8045 - val_accuracy: 0.3897 - val_loss: 1.6487\n",
      "Epoch 2/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 498ms/step - accuracy: 0.4059 - loss: 1.6264 - val_accuracy: 0.4191 - val_loss: 1.6308\n",
      "Epoch 3/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 429ms/step - accuracy: 0.4319 - loss: 1.5271 - val_accuracy: 0.4424 - val_loss: 1.4795\n",
      "Epoch 4/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 445ms/step - accuracy: 0.4603 - loss: 1.4471 - val_accuracy: 0.4277 - val_loss: 1.5570\n",
      "Epoch 5/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 447ms/step - accuracy: 0.4911 - loss: 1.3595 - val_accuracy: 0.5123 - val_loss: 1.3165\n",
      "Epoch 6/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 447ms/step - accuracy: 0.5028 - loss: 1.3143 - val_accuracy: 0.5086 - val_loss: 1.2859\n",
      "Epoch 7/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 436ms/step - accuracy: 0.5192 - loss: 1.2625 - val_accuracy: 0.5110 - val_loss: 1.3757\n",
      "Epoch 8/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 444ms/step - accuracy: 0.5318 - loss: 1.2345 - val_accuracy: 0.5270 - val_loss: 1.2699\n",
      "Epoch 9/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 448ms/step - accuracy: 0.5425 - loss: 1.2058 - val_accuracy: 0.5294 - val_loss: 1.2256\n",
      "Epoch 10/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 448ms/step - accuracy: 0.5562 - loss: 1.1525 - val_accuracy: 0.5245 - val_loss: 1.2420\n",
      "Epoch 11/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 448ms/step - accuracy: 0.5596 - loss: 1.1427 - val_accuracy: 0.5368 - val_loss: 1.2619\n",
      "Epoch 12/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 429ms/step - accuracy: 0.5671 - loss: 1.1057 - val_accuracy: 0.5306 - val_loss: 1.2980\n",
      "Epoch 13/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 423ms/step - accuracy: 0.5628 - loss: 1.0814 - val_accuracy: 0.5404 - val_loss: 1.1997\n",
      "Epoch 14/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 424ms/step - accuracy: 0.5746 - loss: 1.0842 - val_accuracy: 0.5674 - val_loss: 1.3310\n",
      "Epoch 15/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 437ms/step - accuracy: 0.5868 - loss: 1.0382 - val_accuracy: 0.5576 - val_loss: 1.2049\n",
      "Epoch 16/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 455ms/step - accuracy: 0.5902 - loss: 1.0290 - val_accuracy: 0.5515 - val_loss: 1.2707\n",
      "Epoch 17/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 446ms/step - accuracy: 0.6153 - loss: 0.9911 - val_accuracy: 0.5527 - val_loss: 1.2348\n",
      "Epoch 18/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 461ms/step - accuracy: 0.6037 - loss: 1.0048 - val_accuracy: 0.5490 - val_loss: 1.1913\n",
      "Epoch 19/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 447ms/step - accuracy: 0.6151 - loss: 0.9644 - val_accuracy: 0.5931 - val_loss: 1.1200\n",
      "Epoch 20/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 445ms/step - accuracy: 0.6339 - loss: 0.9365 - val_accuracy: 0.5858 - val_loss: 1.1703\n",
      "Epoch 21/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 442ms/step - accuracy: 0.6259 - loss: 0.9410 - val_accuracy: 0.5772 - val_loss: 1.2610\n",
      "Epoch 22/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 445ms/step - accuracy: 0.6401 - loss: 0.9064 - val_accuracy: 0.5760 - val_loss: 1.3210\n",
      "Epoch 23/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 441ms/step - accuracy: 0.6446 - loss: 0.8847 - val_accuracy: 0.6042 - val_loss: 1.1713\n",
      "Epoch 24/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 446ms/step - accuracy: 0.6526 - loss: 0.8841 - val_accuracy: 0.5748 - val_loss: 1.1374\n",
      "Epoch 25/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 440ms/step - accuracy: 0.6584 - loss: 0.8604 - val_accuracy: 0.5711 - val_loss: 1.1984\n",
      "Epoch 26/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 425ms/step - accuracy: 0.6547 - loss: 0.8785 - val_accuracy: 0.6042 - val_loss: 1.1706\n",
      "Epoch 27/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 427ms/step - accuracy: 0.6661 - loss: 0.8399 - val_accuracy: 0.6042 - val_loss: 1.1241\n",
      "Epoch 28/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 433ms/step - accuracy: 0.6727 - loss: 0.8379 - val_accuracy: 0.6115 - val_loss: 1.1302\n",
      "Epoch 29/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 451ms/step - accuracy: 0.6808 - loss: 0.8236 - val_accuracy: 0.6176 - val_loss: 1.2590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b4801792c60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',   # or 'val_accuracy'\n",
    "    patience=10,           # stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True  # roll back to the best epoch\n",
    ")\n",
    "\n",
    "history = all_sensor_model.fit(\n",
    "    X_train_all, \n",
    "    y_train_all,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    validation_data=(X_val_all, y_val_all),\n",
    "    verbose=1\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "all_sensor_model.save(\"all_sensor_model_9_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/Desktop/ML_DL_Projects/ml_env/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.5931 - loss: 1.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1200491189956665, 0.593137264251709]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "all_sensor_model = load_model(\"all_sensor_model_9_1.h5\")\n",
    "all_sensor_model.evaluate(X_val_all, y_val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "[[0.04707842 0.0388799  0.02013162 0.1783331  0.26088795 0.14250195\n",
      "  0.0921374  0.21817918 0.00187043]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "pred_prob = imuex_model_best.predict(X_val_imuex[1].reshape(1,400,12))\n",
    "print(pred_prob)\n",
    "pred_cls = np.argmax(pred_prob,axis=1)\n",
    "print(pred_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eyelash - pull hair'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_classes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
